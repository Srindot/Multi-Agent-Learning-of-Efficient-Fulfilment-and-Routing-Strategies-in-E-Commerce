{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project \n",
    "### Topics In Applied Optimization\n",
    "#### B Srinath Dhatre\n",
    "#### GV Dheeraj Sai\n",
    "#### SriRama Ratan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Importing Modules\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, BatchNorm\n",
    "import numpy as np\n",
    "\n",
    "class GAE(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels=2, hidden_dim=64, dropout=0.5):\n",
    "        super(GAE, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_dim)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, out_channels)\n",
    "        self.bn2 = BatchNorm(out_channels)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.decoder = nn.Linear(out_channels, in_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(self.conv2(x, edge_index))\n",
    "        print(\"Size of input data:\", x.size())\n",
    "        print(\"Size of embeddings:\", x.size())\n",
    "        print(\"Embeddings:\", x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encode(data.x, data.edge_index)\n",
    "        return self.decoder(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[-0.4157, -0.6155],\n",
      "        [-0.0171, -1.1318],\n",
      "        [ 0.4697,  0.2884],\n",
      "        [-0.1482,  1.0650],\n",
      "        [ 1.5319, -1.1994],\n",
      "        [ 1.2675, -0.2206],\n",
      "        [-1.3428,  1.4338],\n",
      "        [-1.2118,  1.5321],\n",
      "        [-1.1508, -1.1087],\n",
      "        [ 1.0172, -0.0432]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 1, Loss: 0.9577827453613281\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8467,  1.3696],\n",
      "        [ 2.1442,  0.4895],\n",
      "        [ 1.0111,  0.9895],\n",
      "        [-0.7456,  0.3518],\n",
      "        [-0.8568, -1.5593],\n",
      "        [ 0.0501, -1.3611],\n",
      "        [-0.3124, -0.7506],\n",
      "        [-1.0800,  0.2225],\n",
      "        [-0.0818,  0.9973],\n",
      "        [-0.5756, -0.3492]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 2, Loss: 0.6365988254547119\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.2675,  0.7545],\n",
      "        [ 0.5092,  0.5622],\n",
      "        [ 1.3833,  1.2190],\n",
      "        [-0.2284,  0.7636],\n",
      "        [-1.0815, -1.5266],\n",
      "        [-0.9168, -1.3195],\n",
      "        [-1.3896, -0.5032],\n",
      "        [ 0.1753,  0.4504],\n",
      "        [ 0.8218,  0.8983],\n",
      "        [ 0.2556, -0.5028]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 3, Loss: 0.4823227524757385\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.0874,  1.0953],\n",
      "        [-0.1471,  0.5491],\n",
      "        [ 1.1836,  0.9668],\n",
      "        [ 0.0421,  0.6188],\n",
      "        [-1.5396, -1.3274],\n",
      "        [-0.9070, -1.2740],\n",
      "        [-0.3139, -0.7491],\n",
      "        [ 1.0857,  0.4272],\n",
      "        [ 0.9043,  0.9832],\n",
      "        [-0.2101, -0.1055]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 4, Loss: 0.36812666058540344\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.9154,  0.9499],\n",
      "        [-0.0946,  0.4975],\n",
      "        [ 1.1489,  1.0063],\n",
      "        [ 0.1566,  0.7623],\n",
      "        [-1.4149, -1.3220],\n",
      "        [-0.9115, -1.1569],\n",
      "        [-0.3372, -0.5048],\n",
      "        [ 1.0321,  0.4860],\n",
      "        [ 1.1009,  1.0174],\n",
      "        [-0.0322, -0.1724]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 5, Loss: 0.2793203592300415\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.4285,  1.1780],\n",
      "        [-0.2896,  0.7004],\n",
      "        [ 0.9938,  0.9105],\n",
      "        [-0.4926,  0.3941],\n",
      "        [-1.1824, -1.0949],\n",
      "        [-0.4545, -1.1012],\n",
      "        [-0.1583, -0.5845],\n",
      "        [ 1.1390,  0.3048],\n",
      "        [ 0.8225,  1.0939],\n",
      "        [ 0.1199,  0.1287]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 6, Loss: 0.22605086863040924\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.0902,  1.0355],\n",
      "        [-0.1339,  0.4023],\n",
      "        [ 1.2078,  1.0114],\n",
      "        [-0.1573,  0.7127],\n",
      "        [-1.2960, -1.1438],\n",
      "        [-0.3984, -0.9147],\n",
      "        [-0.1669, -0.2673],\n",
      "        [ 1.0855,  0.6162],\n",
      "        [ 0.9251,  1.0569],\n",
      "        [ 0.1147, -0.2273]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 7, Loss: 0.1639133244752884\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.2190,  1.1048],\n",
      "        [ 0.4151,  0.6007],\n",
      "        [ 1.1223,  0.9862],\n",
      "        [-0.1661,  0.4623],\n",
      "        [-1.0901, -0.9818],\n",
      "        [-0.5542, -0.9255],\n",
      "        [-0.2498, -0.3283],\n",
      "        [ 0.7806,  0.5575],\n",
      "        [ 1.0920,  1.0959],\n",
      "        [ 0.0260,  0.0474]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 8, Loss: 0.1388840675354004\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6973,  0.9390],\n",
      "        [ 0.1606,  0.5570],\n",
      "        [ 0.8126,  0.8797],\n",
      "        [ 0.1040,  0.6936],\n",
      "        [-1.0741, -0.8426],\n",
      "        [-0.5862, -0.8982],\n",
      "        [ 0.3497, -0.1058],\n",
      "        [ 1.1864,  0.5602],\n",
      "        [ 1.3590,  1.2853],\n",
      "        [-0.1135, -0.1268]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 9, Loss: 0.11884588748216629\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.0871,  0.9557],\n",
      "        [ 0.1994,  0.5645],\n",
      "        [ 1.3354,  0.6975],\n",
      "        [ 0.1720,  0.8577],\n",
      "        [-1.0229, -0.9628],\n",
      "        [-0.3466, -0.6743],\n",
      "        [ 0.0550,  0.2028],\n",
      "        [ 0.8435,  0.6700],\n",
      "        [ 0.9761,  1.1755],\n",
      "        [-0.1266, -0.2382]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 10, Loss: 0.09842285513877869\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8537,  0.9992],\n",
      "        [ 0.0500,  0.4704],\n",
      "        [ 1.3560,  0.7471],\n",
      "        [-0.1685,  0.5058],\n",
      "        [-0.8181, -0.6450],\n",
      "        [-0.1769, -0.8781],\n",
      "        [ 0.1141,  0.0616],\n",
      "        [ 1.1278,  0.8388],\n",
      "        [ 1.0753,  1.2962],\n",
      "        [ 0.0109,  0.1452]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 11, Loss: 0.0913548618555069\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6692,  0.9314],\n",
      "        [ 0.5995,  0.6223],\n",
      "        [ 1.1000,  0.9371],\n",
      "        [ 0.7555,  0.8932],\n",
      "        [-0.8650, -0.7375],\n",
      "        [-0.2851, -0.5595],\n",
      "        [ 0.2276,  0.0204],\n",
      "        [ 0.7973,  0.6745],\n",
      "        [ 1.1367,  1.1355],\n",
      "        [-0.4847, -0.0966]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 12, Loss: 0.09327580034732819\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.4051,  1.0345],\n",
      "        [ 0.3774,  0.4634],\n",
      "        [ 1.2806,  0.8841],\n",
      "        [-0.0827,  0.8735],\n",
      "        [-0.7766, -0.6917],\n",
      "        [ 0.0267, -0.5849],\n",
      "        [ 0.0325,  0.0780],\n",
      "        [ 0.7812,  0.8773],\n",
      "        [ 0.7509,  1.0281],\n",
      "        [ 0.0581,  0.1248]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 13, Loss: 0.09025759994983673\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.1068,  1.1414],\n",
      "        [ 0.3145,  0.3633],\n",
      "        [ 1.2134,  0.8250],\n",
      "        [ 0.2103,  0.7619],\n",
      "        [-0.7352, -0.6534],\n",
      "        [-0.2607, -0.4716],\n",
      "        [ 0.0392,  0.2302],\n",
      "        [ 0.9512,  1.0220],\n",
      "        [ 1.0486,  1.0190],\n",
      "        [ 0.1440,  0.1038]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 14, Loss: 0.08602138608694077\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.9470,  0.7619],\n",
      "        [ 0.2067,  0.4738],\n",
      "        [ 1.2738,  0.8891],\n",
      "        [ 0.1976,  1.1292],\n",
      "        [-0.6718, -0.5089],\n",
      "        [-0.1298, -0.4858],\n",
      "        [-0.0144,  0.3085],\n",
      "        [ 1.0742,  0.8672],\n",
      "        [ 1.0660,  1.1428],\n",
      "        [ 0.2395,  0.0067]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 15, Loss: 0.08557073771953583\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.2580,  1.0194],\n",
      "        [ 0.1828,  0.2830],\n",
      "        [ 1.2474,  1.0100],\n",
      "        [-0.1344,  0.9224],\n",
      "        [-0.5354, -0.5195],\n",
      "        [-0.0168, -0.3495],\n",
      "        [ 0.0356,  0.1958],\n",
      "        [ 0.9483,  1.0472],\n",
      "        [ 0.8838,  1.0076],\n",
      "        [ 0.4553,  0.1995]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 16, Loss: 0.08686739951372147\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.9836,  1.0455],\n",
      "        [ 0.3477,  0.4095],\n",
      "        [ 1.1263,  0.8632],\n",
      "        [ 0.1607,  0.7744],\n",
      "        [-0.5407, -0.4835],\n",
      "        [-0.2037, -0.3509],\n",
      "        [ 0.2756,  0.4088],\n",
      "        [ 0.9993,  1.1185],\n",
      "        [ 1.2349,  1.1173],\n",
      "        [ 0.0589,  0.1333]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 17, Loss: 0.08402612060308456\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.0133e+00,  1.0917e+00],\n",
      "        [ 1.1883e-01,  5.4208e-01],\n",
      "        [ 1.2500e+00,  9.4542e-01],\n",
      "        [ 2.7590e-01,  8.1468e-01],\n",
      "        [-5.9929e-01, -4.9729e-01],\n",
      "        [-6.5809e-04, -2.9648e-01],\n",
      "        [ 1.7677e-01,  2.5024e-01],\n",
      "        [ 1.1354e+00,  9.1868e-01],\n",
      "        [ 9.2607e-01,  1.1655e+00],\n",
      "        [ 2.4776e-01,  3.1029e-01]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 18, Loss: 0.08514655381441116\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8029,  0.9202],\n",
      "        [ 0.3032,  0.4594],\n",
      "        [ 1.2323,  0.8042],\n",
      "        [ 0.2801,  0.9541],\n",
      "        [-0.6197, -0.3803],\n",
      "        [-0.0154, -0.3025],\n",
      "        [ 0.3597,  0.6745],\n",
      "        [ 1.2298,  1.1011],\n",
      "        [ 0.9289,  1.1501],\n",
      "        [ 0.1296,  0.0607]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 19, Loss: 0.0821971446275711\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8217,  1.1034],\n",
      "        [ 0.2018,  0.4724],\n",
      "        [ 1.2493,  0.9625],\n",
      "        [ 0.3765,  0.8670],\n",
      "        [-0.4891, -0.4353],\n",
      "        [-0.0066, -0.1649],\n",
      "        [ 0.2381,  0.4841],\n",
      "        [ 1.2105,  1.0127],\n",
      "        [ 1.0074,  1.1556],\n",
      "        [ 0.0974,  0.1683]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 20, Loss: 0.08214982599020004\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.9849,  1.0263],\n",
      "        [ 0.0861,  0.3965],\n",
      "        [ 1.3369,  0.8322],\n",
      "        [ 0.0149,  0.9721],\n",
      "        [-0.3977, -0.4136],\n",
      "        [ 0.2489, -0.1156],\n",
      "        [ 0.2835,  0.5575],\n",
      "        [ 1.1990,  1.2037],\n",
      "        [ 0.7853,  1.1110],\n",
      "        [ 0.2309,  0.2273]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 21, Loss: 0.0801353007555008\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8552,  0.9776],\n",
      "        [ 0.0180,  0.2583],\n",
      "        [ 1.2071,  0.8460],\n",
      "        [ 0.1234,  0.8395],\n",
      "        [-0.4000, -0.3188],\n",
      "        [ 0.1105, -0.1305],\n",
      "        [ 0.3014,  0.7099],\n",
      "        [ 1.1884,  1.3286],\n",
      "        [ 1.0667,  1.1243],\n",
      "        [ 0.3601,  0.3197]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 22, Loss: 0.07937296479940414\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.0355,  1.0198],\n",
      "        [-0.2329,  0.2330],\n",
      "        [ 1.1194,  0.6940],\n",
      "        [-0.0824,  0.9130],\n",
      "        [-0.0254, -0.3330],\n",
      "        [ 0.1721, -0.0543],\n",
      "        [ 0.2212,  0.7551],\n",
      "        [ 1.3043,  1.3532],\n",
      "        [ 0.7869,  1.1033],\n",
      "        [ 0.5841,  0.4135]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 23, Loss: 0.08103100955486298\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6825,  1.0217],\n",
      "        [-0.3868,  0.3620],\n",
      "        [ 0.9737,  0.9383],\n",
      "        [ 0.3059,  0.8974],\n",
      "        [-0.2622, -0.2352],\n",
      "        [ 0.4547, -0.1466],\n",
      "        [ 0.7063,  0.4086],\n",
      "        [ 1.4072,  1.3503],\n",
      "        [ 0.7980,  1.1043],\n",
      "        [ 0.2508,  0.5242]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 24, Loss: 0.08502306044101715\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6721,  0.9736],\n",
      "        [-0.0250,  0.3122],\n",
      "        [ 1.1045,  0.8920],\n",
      "        [ 0.3922,  0.9463],\n",
      "        [-0.2416, -0.1910],\n",
      "        [-0.0747, -0.1628],\n",
      "        [ 0.2920,  0.5216],\n",
      "        [ 1.3231,  1.3240],\n",
      "        [ 1.0839,  1.1885],\n",
      "        [ 0.4474,  0.5324]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 25, Loss: 0.08281940221786499\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6949,  0.8587],\n",
      "        [ 0.0481,  0.3018],\n",
      "        [ 0.9922,  0.8402],\n",
      "        [ 0.3166,  1.1664],\n",
      "        [-0.3856, -0.1419],\n",
      "        [ 0.1590, -0.0634],\n",
      "        [ 0.5616,  0.7091],\n",
      "        [ 1.2988,  1.3077],\n",
      "        [ 1.1480,  1.1851],\n",
      "        [ 0.1819,  0.2689]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 26, Loss: 0.08144792169332504\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6733,  0.8637],\n",
      "        [-0.1481,  0.2984],\n",
      "        [ 1.3027,  0.9492],\n",
      "        [ 0.4260,  1.1452],\n",
      "        [-0.3539, -0.2067],\n",
      "        [ 0.3623,  0.0342],\n",
      "        [ 0.4924,  0.6994],\n",
      "        [ 1.2583,  1.2549],\n",
      "        [ 0.7668,  1.2077],\n",
      "        [ 0.2758,  0.2667]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 27, Loss: 0.08437936007976532\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.5765,  1.1093],\n",
      "        [-0.0533,  0.4398],\n",
      "        [ 1.1523,  0.8113],\n",
      "        [-0.2186,  0.8372],\n",
      "        [-0.1138, -0.1469],\n",
      "        [ 0.5443, -0.1487],\n",
      "        [ 0.6483,  0.7052],\n",
      "        [ 1.3290,  1.3148],\n",
      "        [ 0.8860,  1.2303],\n",
      "        [ 0.3437,  0.4245]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 28, Loss: 0.08170218020677567\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7693,  0.8789],\n",
      "        [ 0.0449,  0.3141],\n",
      "        [ 1.3344,  0.7447],\n",
      "        [ 0.2523,  1.0891],\n",
      "        [-0.2047, -0.1443],\n",
      "        [ 0.1616, -0.0626],\n",
      "        [ 0.2685,  0.8090],\n",
      "        [ 1.2892,  1.3462],\n",
      "        [ 0.8788,  1.2293],\n",
      "        [ 0.3376,  0.4216]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 29, Loss: 0.08218811452388763\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.3554,  0.8773],\n",
      "        [ 0.0162,  0.2330],\n",
      "        [ 0.9972,  0.8660],\n",
      "        [ 0.5088,  1.1196],\n",
      "        [-0.2233, -0.1170],\n",
      "        [ 0.2181,  0.0501],\n",
      "        [ 0.5246,  0.7632],\n",
      "        [ 1.4864,  1.4304],\n",
      "        [ 1.0675,  1.1180],\n",
      "        [ 0.2177,  0.3210]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 30, Loss: 0.08178184926509857\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8077,  0.8358],\n",
      "        [-0.2041,  0.0224],\n",
      "        [ 0.9248,  0.5408],\n",
      "        [-0.0753,  1.0088],\n",
      "        [-0.0061,  0.0275],\n",
      "        [ 0.2863,  0.1167],\n",
      "        [ 0.4261,  1.1020],\n",
      "        [ 1.4290,  1.5064],\n",
      "        [ 0.8827,  1.0602],\n",
      "        [ 0.7327,  0.4640]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 31, Loss: 0.0817597359418869\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6764,  0.7910],\n",
      "        [-0.0459,  0.0192],\n",
      "        [ 0.9465,  0.8340],\n",
      "        [ 0.1360,  1.1481],\n",
      "        [-0.2293,  0.0252],\n",
      "        [ 0.2548,  0.0724],\n",
      "        [ 0.3689,  0.7664],\n",
      "        [ 1.3106,  1.5174],\n",
      "        [ 1.2305,  1.0471],\n",
      "        [ 0.5887,  0.4761]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 32, Loss: 0.07980374246835709\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8132,  0.8191],\n",
      "        [-0.3457, -0.1182],\n",
      "        [ 1.0363,  0.7808],\n",
      "        [-0.0190,  0.9734],\n",
      "        [ 0.1706,  0.0152],\n",
      "        [ 0.5589,  0.2859],\n",
      "        [ 0.3280,  1.0387],\n",
      "        [ 1.4423,  1.5598],\n",
      "        [ 0.5190,  0.9196],\n",
      "        [ 0.7649,  0.4256]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 33, Loss: 0.08419948816299438\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7616,  1.1997],\n",
      "        [ 0.0058,  0.5028],\n",
      "        [ 1.0811,  0.8624],\n",
      "        [-0.1142,  0.8814],\n",
      "        [-0.2061, -0.1841],\n",
      "        [ 0.5921, -0.1136],\n",
      "        [ 0.6236,  0.6418],\n",
      "        [ 1.3665,  1.2597],\n",
      "        [ 0.8727,  1.1746],\n",
      "        [ 0.3143,  0.4712]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 34, Loss: 0.0796346366405487\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6221,  0.6265],\n",
      "        [-0.3696,  0.1771],\n",
      "        [ 1.0479,  0.6628],\n",
      "        [ 0.1392,  1.1937],\n",
      "        [ 0.0614,  0.0542],\n",
      "        [ 0.4802,  0.1031],\n",
      "        [ 0.6524,  1.0271],\n",
      "        [ 1.4629,  1.4254],\n",
      "        [ 0.8509,  1.1878],\n",
      "        [ 0.3753,  0.2283]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 35, Loss: 0.08075455576181412\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.1155,  0.9423],\n",
      "        [ 0.0502,  0.1487],\n",
      "        [ 1.3262,  0.6935],\n",
      "        [ 0.2308,  1.0876],\n",
      "        [-0.1352, -0.1599],\n",
      "        [ 0.2793,  0.1580],\n",
      "        [ 0.0236,  0.8186],\n",
      "        [ 1.1329,  1.5096],\n",
      "        [ 0.7774,  1.0378],\n",
      "        [ 0.5441,  0.4363]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 36, Loss: 0.08103570342063904\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.4545,  0.6704],\n",
      "        [-0.4191, -0.1545],\n",
      "        [ 1.0962,  0.5469],\n",
      "        [ 0.3288,  1.0642],\n",
      "        [ 0.0735,  0.1633],\n",
      "        [ 0.8492,  0.2952],\n",
      "        [ 0.7686,  1.0708],\n",
      "        [ 1.3663,  1.5970],\n",
      "        [ 0.6838,  0.9564],\n",
      "        [ 0.1609,  0.4468]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 37, Loss: 0.07447454333305359\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.3291,  0.9002],\n",
      "        [-0.1073,  0.3263],\n",
      "        [ 1.1886,  0.9603],\n",
      "        [ 0.6198,  1.0995],\n",
      "        [-0.0828, -0.1716],\n",
      "        [ 0.6214,  0.0703],\n",
      "        [ 0.7945,  0.6481],\n",
      "        [ 1.2345,  1.4552],\n",
      "        [ 0.9510,  1.0560],\n",
      "        [-0.1723,  0.2949]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 38, Loss: 0.07827382534742355\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7572,  0.8884],\n",
      "        [-0.1184,  0.0446],\n",
      "        [ 0.8036,  0.5570],\n",
      "        [-0.0076,  0.9623],\n",
      "        [ 0.0459, -0.0189],\n",
      "        [ 0.2526,  0.1373],\n",
      "        [ 0.3720,  0.9146],\n",
      "        [ 1.4447,  1.5776],\n",
      "        [ 1.2485,  1.1179],\n",
      "        [ 0.5874,  0.4416]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 39, Loss: 0.07527750730514526\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.0457,  0.7713],\n",
      "        [-0.0535, -0.2229],\n",
      "        [ 1.0113,  0.6874],\n",
      "        [ 0.0578,  1.0456],\n",
      "        [ 0.2744,  0.2644],\n",
      "        [ 1.0796,  0.0841],\n",
      "        [ 1.0266,  0.8585],\n",
      "        [ 1.2506,  1.6248],\n",
      "        [ 0.7503,  0.8834],\n",
      "        [-0.0516,  0.6094]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 40, Loss: 0.07185984402894974\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.5240,  0.7199],\n",
      "        [ 0.4685, -0.0426],\n",
      "        [ 1.2030,  0.9922],\n",
      "        [ 0.5877,  1.1325],\n",
      "        [-0.2921,  0.0253],\n",
      "        [ 0.0641,  0.1701],\n",
      "        [ 0.2930,  0.8295],\n",
      "        [ 0.9897,  1.5011],\n",
      "        [ 1.4219,  0.9943],\n",
      "        [ 0.1329,  0.2685]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 41, Loss: 0.07627536356449127\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7385,  0.8256],\n",
      "        [ 0.1285, -0.0819],\n",
      "        [ 1.2747,  0.6179],\n",
      "        [ 0.1462,  1.1563],\n",
      "        [-0.3300,  0.0085],\n",
      "        [ 0.5048,  0.2711],\n",
      "        [ 0.4277,  1.0422],\n",
      "        [ 1.2350,  1.5350],\n",
      "        [ 1.0934,  0.9007],\n",
      "        [ 0.1715,  0.3018]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 42, Loss: 0.06626603752374649\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7739,  0.8713],\n",
      "        [-0.2087,  0.0697],\n",
      "        [ 1.3798,  0.9097],\n",
      "        [ 0.1434,  1.1385],\n",
      "        [ 0.0360, -0.1684],\n",
      "        [ 0.3412,  0.0642],\n",
      "        [ 0.1291,  0.7056],\n",
      "        [ 1.2631,  1.4653],\n",
      "        [ 0.9486,  1.0131],\n",
      "        [ 0.5790,  0.4964]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 43, Loss: 0.0721583440899849\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6942,  0.7381],\n",
      "        [ 0.1682, -0.0475],\n",
      "        [ 1.3993,  0.4940],\n",
      "        [ 0.3297,  1.1691],\n",
      "        [-0.1317,  0.0257],\n",
      "        [ 0.0220,  0.2313],\n",
      "        [ 0.1570,  1.0804],\n",
      "        [ 1.1423,  1.5791],\n",
      "        [ 1.2221,  0.9219],\n",
      "        [ 0.3750,  0.3625]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 44, Loss: 0.07137107849121094\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.3816,  1.0090],\n",
      "        [-0.0140, -0.2478],\n",
      "        [ 1.0509,  0.7034],\n",
      "        [ 0.1240,  0.8850],\n",
      "        [-0.1800,  0.0615],\n",
      "        [ 0.8225,  0.2703],\n",
      "        [ 1.0910,  0.9132],\n",
      "        [ 1.2274,  1.6672],\n",
      "        [ 0.9508,  0.6824],\n",
      "        [-0.0851,  0.6013]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 45, Loss: 0.06563668698072433\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.1763,  0.6603],\n",
      "        [ 0.1849, -0.2538],\n",
      "        [ 1.0891,  0.3856],\n",
      "        [-0.0629,  0.8945],\n",
      "        [-0.0704,  0.2735],\n",
      "        [ 0.1680,  0.4315],\n",
      "        [-0.0915,  1.2449],\n",
      "        [ 0.9934,  1.5994],\n",
      "        [ 1.1036,  0.9935],\n",
      "        [ 0.8688,  0.3076]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 46, Loss: 0.08484609425067902\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.2836,  0.8642],\n",
      "        [ 0.3739, -0.1088],\n",
      "        [ 1.0007,  0.3321],\n",
      "        [ 0.4878,  0.9631],\n",
      "        [-0.1934,  0.1441],\n",
      "        [ 0.4285,  0.1186],\n",
      "        [ 1.0809,  1.0830],\n",
      "        [ 1.0936,  1.6061],\n",
      "        [ 1.1920,  1.0570],\n",
      "        [-0.3986,  0.4694]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 47, Loss: 0.06505540758371353\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.5142,  0.5532],\n",
      "        [ 0.3940, -0.3842],\n",
      "        [ 1.4050,  0.5886],\n",
      "        [ 0.5168,  1.1333],\n",
      "        [-0.0308,  0.2365],\n",
      "        [ 0.1000,  0.5558],\n",
      "        [ 0.0906,  1.1220],\n",
      "        [ 0.7998,  1.6113],\n",
      "        [ 1.5238,  0.6806],\n",
      "        [ 0.0262,  0.4234]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 48, Loss: 0.06993833184242249\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.9610,  1.0735],\n",
      "        [ 0.5500, -0.0847],\n",
      "        [ 1.2475,  0.6245],\n",
      "        [ 0.2235,  0.8800],\n",
      "        [-0.4506, -0.0143],\n",
      "        [-0.0063,  0.1228],\n",
      "        [ 0.1848,  1.0634],\n",
      "        [ 0.9989,  1.5902],\n",
      "        [ 1.1839,  0.9291],\n",
      "        [ 0.4381,  0.3271]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 49, Loss: 0.06779714673757553\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8536,  0.7825],\n",
      "        [ 0.1436,  0.0773],\n",
      "        [ 0.8483,  0.6298],\n",
      "        [-0.0894,  1.1930],\n",
      "        [-0.3679,  0.0438],\n",
      "        [ 0.4318,  0.0790],\n",
      "        [ 0.6658,  0.9213],\n",
      "        [ 1.4098,  1.4679],\n",
      "        [ 1.1783,  1.2400],\n",
      "        [ 0.2493,  0.0668]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 50, Loss: 0.06716417521238327\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.4832,  0.6575],\n",
      "        [ 0.3972,  0.1583],\n",
      "        [ 1.5182,  0.9913],\n",
      "        [-0.0582,  1.3313],\n",
      "        [-0.3586, -0.0595],\n",
      "        [ 0.6986, -0.1455],\n",
      "        [ 0.5401,  0.5147],\n",
      "        [ 0.8462,  1.3892],\n",
      "        [ 1.1722,  1.1559],\n",
      "        [ 0.0783,  0.4968]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 51, Loss: 0.0562007911503315\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.0845,  0.8735],\n",
      "        [ 0.1266, -0.2815],\n",
      "        [ 1.3130,  0.5017],\n",
      "        [ 0.0108,  0.8213],\n",
      "        [-0.4028,  0.0892],\n",
      "        [ 0.3413,  0.1393],\n",
      "        [ 0.3428,  1.0825],\n",
      "        [ 1.2429,  1.6588],\n",
      "        [ 0.8251,  0.9135],\n",
      "        [ 0.4306,  0.6853]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 52, Loss: 0.06175429746508598\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7307,  1.0409],\n",
      "        [-0.1616, -0.1510],\n",
      "        [ 1.0708,  0.7936],\n",
      "        [-0.3215,  0.8954],\n",
      "        [-0.1512,  0.0736],\n",
      "        [ 0.7824, -0.0135],\n",
      "        [ 0.7998,  0.4728],\n",
      "        [ 1.3364,  1.6630],\n",
      "        [ 0.8576,  1.0140],\n",
      "        [ 0.3698,  0.6874]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 53, Loss: 0.06480380892753601\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.4316,  0.7363],\n",
      "        [ 0.1791,  0.0825],\n",
      "        [ 1.3063,  0.4047],\n",
      "        [-0.0591,  1.3135],\n",
      "        [-0.2523,  0.0506],\n",
      "        [ 0.8838,  0.0166],\n",
      "        [ 0.4875,  0.9758],\n",
      "        [ 1.4215,  1.3733],\n",
      "        [ 0.8531,  1.3125],\n",
      "        [ 0.0603,  0.2024]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 54, Loss: 0.056502629071474075\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7125,  0.4880],\n",
      "        [ 0.3030, -0.1716],\n",
      "        [ 1.3600,  0.5583],\n",
      "        [ 0.4377,  1.3253],\n",
      "        [-0.4619,  0.0402],\n",
      "        [ 0.0628,  0.2738],\n",
      "        [ 0.2060,  1.1352],\n",
      "        [ 1.1972,  1.5024],\n",
      "        [ 1.1570,  0.9982],\n",
      "        [ 0.3368,  0.3098]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 55, Loss: 0.06422260403633118\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6656,  0.7253],\n",
      "        [ 0.2170, -0.0205],\n",
      "        [ 1.5309,  0.4152],\n",
      "        [ 0.3151,  1.0750],\n",
      "        [-0.1974, -0.0638],\n",
      "        [ 0.3109,  0.1987],\n",
      "        [ 0.4352,  1.1747],\n",
      "        [ 1.0853,  1.5495],\n",
      "        [ 1.1528,  1.1481],\n",
      "        [-0.2051,  0.2482]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 56, Loss: 0.05319886654615402\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 6.0113e-01,  6.7781e-01],\n",
      "        [ 7.2023e-01, -1.2923e-01],\n",
      "        [ 1.3389e+00,  6.2182e-01],\n",
      "        [ 2.9310e-01,  1.2398e+00],\n",
      "        [-4.6354e-01,  8.9567e-04],\n",
      "        [ 1.8189e-01,  1.8778e-01],\n",
      "        [ 7.8198e-02,  1.1357e+00],\n",
      "        [ 1.0735e+00,  1.5440e+00],\n",
      "        [ 1.2736e+00,  9.5677e-01],\n",
      "        [ 2.1265e-01,  2.0533e-01]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 57, Loss: 0.05650783330202103\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 3.1617e-01,  8.0487e-01],\n",
      "        [ 3.6846e-01, -7.6335e-02],\n",
      "        [ 1.5345e+00,  1.0396e+00],\n",
      "        [-8.3433e-04,  1.1607e+00],\n",
      "        [-6.8684e-02, -1.2056e-01],\n",
      "        [ 7.8346e-01,  4.0772e-02],\n",
      "        [ 4.6894e-01,  6.6762e-01],\n",
      "        [ 3.9852e-01,  1.6447e+00],\n",
      "        [ 1.5068e+00,  7.3451e-01],\n",
      "        [ 1.3683e-03,  5.3494e-01]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 58, Loss: 0.048096105456352234\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8654,  0.9569],\n",
      "        [ 0.0141, -0.1237],\n",
      "        [ 1.1247,  0.7936],\n",
      "        [-0.4153,  0.9967],\n",
      "        [-0.2313, -0.0298],\n",
      "        [ 0.7843, -0.0265],\n",
      "        [ 0.3114,  0.6771],\n",
      "        [ 1.0422,  1.6005],\n",
      "        [ 1.2301,  1.1489],\n",
      "        [ 0.5821,  0.4267]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 59, Loss: 0.05400318279862404\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8384,  0.6636],\n",
      "        [ 0.3210, -0.2842],\n",
      "        [ 1.3307,  0.6201],\n",
      "        [ 0.0361,  1.1847],\n",
      "        [-0.4212,  0.0998],\n",
      "        [ 0.1796,  0.2129],\n",
      "        [ 0.1438,  1.0555],\n",
      "        [ 1.0742,  1.6170],\n",
      "        [ 1.3113,  0.9510],\n",
      "        [ 0.4919,  0.2899]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 60, Loss: 0.057293981313705444\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6738,  0.7664],\n",
      "        [ 0.7972,  0.0387],\n",
      "        [ 1.5880,  0.3260],\n",
      "        [ 0.1294,  0.9665],\n",
      "        [-0.1870, -0.0496],\n",
      "        [ 0.3069,  0.1188],\n",
      "        [-0.0952,  1.2284],\n",
      "        [ 0.7070,  1.5805],\n",
      "        [ 1.2966,  1.1698],\n",
      "        [ 0.0868,  0.2546]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 61, Loss: 0.05238061398267746\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.1358,  0.5962],\n",
      "        [ 0.4415, -0.2191],\n",
      "        [ 1.5528,  0.3522],\n",
      "        [-0.1526,  1.0473],\n",
      "        [ 0.2551,  0.1570],\n",
      "        [ 1.4414,  0.2050],\n",
      "        [ 0.4409,  1.2217],\n",
      "        [ 0.3891,  1.6643],\n",
      "        [ 0.9140,  1.0008],\n",
      "        [-0.1179,  0.3646]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 62, Loss: 0.04869648441672325\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.5744,  0.9931],\n",
      "        [-0.2997, -0.3725],\n",
      "        [ 1.1733,  0.6903],\n",
      "        [-0.1664,  0.9445],\n",
      "        [-0.2081,  0.0757],\n",
      "        [ 0.8447,  0.0824],\n",
      "        [ 0.8189,  0.8317],\n",
      "        [ 1.4625,  1.6490],\n",
      "        [ 0.6589,  0.9234],\n",
      "        [ 0.4371,  0.5626]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 63, Loss: 0.060900166630744934\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.5400,  0.8654],\n",
      "        [ 0.0132,  0.0743],\n",
      "        [ 1.1557,  0.8338],\n",
      "        [ 0.0586,  1.0774],\n",
      "        [-0.2943, -0.2098],\n",
      "        [ 0.4946, -0.1203],\n",
      "        [ 0.6284,  0.7816],\n",
      "        [ 1.4325,  1.5178],\n",
      "        [ 1.2765,  1.1649],\n",
      "        [-0.0153,  0.3860]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 64, Loss: 0.051857735961675644\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.9412,  0.9682],\n",
      "        [ 0.6645,  0.3123],\n",
      "        [ 1.4488,  0.7752],\n",
      "        [ 0.1419,  1.0773],\n",
      "        [-0.2952, -0.3715],\n",
      "        [ 0.0770, -0.1718],\n",
      "        [-0.1300,  0.6771],\n",
      "        [ 0.6737,  1.3652],\n",
      "        [ 1.3814,  1.2601],\n",
      "        [ 0.3794,  0.4701]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 65, Loss: 0.053856804966926575\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7096,  1.1057],\n",
      "        [ 0.5018,  0.3124],\n",
      "        [ 1.3973,  0.9739],\n",
      "        [ 0.2154,  1.0707],\n",
      "        [-0.6406, -0.1476],\n",
      "        [ 0.4549, -0.2582],\n",
      "        [ 0.3956,  0.4922],\n",
      "        [ 1.1824,  1.4139],\n",
      "        [ 1.0778,  1.1364],\n",
      "        [-0.0196,  0.2545]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 66, Loss: 0.050924137234687805\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.0325,  0.8750],\n",
      "        [-0.0370,  0.0293],\n",
      "        [ 1.0957,  0.4877],\n",
      "        [-0.4880,  1.1712],\n",
      "        [-0.1661, -0.1587],\n",
      "        [ 0.7870, -0.0402],\n",
      "        [ 0.6702,  0.9638],\n",
      "        [ 1.4054,  1.5007],\n",
      "        [ 0.6729,  1.1906],\n",
      "        [ 0.2926,  0.3267]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 67, Loss: 0.06830314546823502\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8681,  1.0830],\n",
      "        [ 0.7628, -0.1306],\n",
      "        [ 1.1870,  0.5382],\n",
      "        [ 0.3546,  0.8895],\n",
      "        [-0.7129, -0.0617],\n",
      "        [ 0.2539, -0.0609],\n",
      "        [ 0.4579,  1.0488],\n",
      "        [ 1.0628,  1.5708],\n",
      "        [ 1.1542,  1.0487],\n",
      "        [-0.1340,  0.4132]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 68, Loss: 0.04631677269935608\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6590,  0.9558],\n",
      "        [ 0.8340,  0.1390],\n",
      "        [ 1.5053,  0.9259],\n",
      "        [ 0.5676,  1.1528],\n",
      "        [-0.3814, -0.2471],\n",
      "        [ 0.0891, -0.1181],\n",
      "        [ 0.0599,  0.5150],\n",
      "        [ 0.5731,  1.4985],\n",
      "        [ 1.3932,  1.1312],\n",
      "        [-0.0565,  0.3793]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 69, Loss: 0.04810480400919914\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.5639,  0.7796],\n",
      "        [ 0.4343, -0.3032],\n",
      "        [ 1.5640,  0.5651],\n",
      "        [ 0.3925,  1.0505],\n",
      "        [-0.4396, -0.0229],\n",
      "        [ 0.0936,  0.2803],\n",
      "        [ 0.2579,  1.1699],\n",
      "        [ 0.9308,  1.7042],\n",
      "        [ 1.3864,  0.7211],\n",
      "        [ 0.0476,  0.3809]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 70, Loss: 0.04670724272727966\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.1459,  0.9452],\n",
      "        [ 0.2105, -0.4916],\n",
      "        [ 1.4761,  0.3010],\n",
      "        [-0.3217,  0.9341],\n",
      "        [-0.1217,  0.2006],\n",
      "        [ 0.4090,  0.2724],\n",
      "        [ 0.2761,  1.0622],\n",
      "        [ 1.0694,  1.6550],\n",
      "        [ 1.0682,  0.8535],\n",
      "        [ 0.0077,  0.5869]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 71, Loss: 0.04520518332719803\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8923,  0.8159],\n",
      "        [ 0.5033, -0.3053],\n",
      "        [ 1.4863,  0.7041],\n",
      "        [ 0.1876,  1.1833],\n",
      "        [-0.4913, -0.0618],\n",
      "        [ 0.1603,  0.1798],\n",
      "        [ 0.4415,  0.7391],\n",
      "        [ 0.8753,  1.7500],\n",
      "        [ 1.2865,  0.7328],\n",
      "        [-0.1343,  0.5749]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 72, Loss: 0.045439109206199646\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7147,  1.3866],\n",
      "        [ 0.3208,  0.0774],\n",
      "        [ 1.3379,  0.7920],\n",
      "        [-0.0798,  0.7704],\n",
      "        [-0.3192, -0.2659],\n",
      "        [ 0.0645, -0.1046],\n",
      "        [ 0.3998,  0.5414],\n",
      "        [ 1.1670,  1.4903],\n",
      "        [ 1.4675,  1.0618],\n",
      "        [ 0.1225,  0.5570]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 73, Loss: 0.04803730547428131\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.2244,  0.8167],\n",
      "        [ 0.6223, -0.2786],\n",
      "        [ 1.3622,  0.4337],\n",
      "        [ 0.2975,  0.8774],\n",
      "        [-0.3986,  0.0639],\n",
      "        [ 0.3544, -0.0586],\n",
      "        [ 0.7047,  1.0366],\n",
      "        [ 1.1041,  1.7153],\n",
      "        [ 1.3001,  0.9858],\n",
      "        [-0.3862,  0.7074]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 74, Loss: 0.04075757414102554\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.3597,  0.8538],\n",
      "        [ 0.5052, -0.0841],\n",
      "        [ 1.5244,  0.9540],\n",
      "        [ 0.5568,  1.2581],\n",
      "        [-0.5504, -0.1825],\n",
      "        [ 0.4237, -0.0571],\n",
      "        [ 0.2861,  0.7131],\n",
      "        [ 1.0681,  1.3760],\n",
      "        [ 1.2112,  1.2211],\n",
      "        [-0.2100,  0.2403]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 75, Loss: 0.03988977149128914\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.2571,  0.8896],\n",
      "        [ 0.4832, -0.3883],\n",
      "        [ 0.9368,  0.1154],\n",
      "        [-0.1385,  1.0816],\n",
      "        [-0.5029,  0.2776],\n",
      "        [ 0.7558,  0.3017],\n",
      "        [ 0.7568,  0.8884],\n",
      "        [ 1.3039,  1.7518],\n",
      "        [ 1.3982,  0.9545],\n",
      "        [-0.0847,  0.4129]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 76, Loss: 0.03951391577720642\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7348,  0.5274],\n",
      "        [ 0.2802, -0.4343],\n",
      "        [ 1.5530,  0.5474],\n",
      "        [ 0.3961,  1.3620],\n",
      "        [-0.6099,  0.1573],\n",
      "        [ 0.2241,  0.1193],\n",
      "        [ 0.2498,  0.9740],\n",
      "        [ 1.2005,  1.5883],\n",
      "        [ 1.0766,  0.9273],\n",
      "        [ 0.0527,  0.5084]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 77, Loss: 0.04595722630620003\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.2791,  1.0022],\n",
      "        [-0.1255, -0.1016],\n",
      "        [ 1.0708,  0.8640],\n",
      "        [-0.0392,  1.1225],\n",
      "        [-0.2616,  0.0165],\n",
      "        [ 1.1766, -0.2967],\n",
      "        [ 0.8839,  0.3652],\n",
      "        [ 1.4207,  1.5749],\n",
      "        [ 0.8819,  1.0392],\n",
      "        [-0.1350,  0.6823]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 78, Loss: 0.06269770115613937\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.3530,  1.1003],\n",
      "        [ 0.7000, -0.0875],\n",
      "        [ 1.3247,  0.6897],\n",
      "        [ 0.0086,  1.1582],\n",
      "        [-0.6470, -0.1638],\n",
      "        [ 0.6144, -0.1731],\n",
      "        [ 0.6827,  0.7522],\n",
      "        [ 0.8354,  1.5983],\n",
      "        [ 1.3976,  0.9280],\n",
      "        [-0.1227,  0.4571]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 79, Loss: 0.03438776358962059\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.4645,  0.7291],\n",
      "        [ 0.3285, -0.0411],\n",
      "        [ 1.3822,  0.6492],\n",
      "        [ 0.1625,  1.4055],\n",
      "        [-0.7278, -0.1426],\n",
      "        [ 0.6383, -0.1008],\n",
      "        [ 0.6341,  0.8369],\n",
      "        [ 1.2761,  1.4245],\n",
      "        [ 1.0388,  1.2425],\n",
      "        [-0.0540,  0.2464]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 80, Loss: 0.045140910893678665\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.5692,  0.6652],\n",
      "        [ 0.6728, -0.0661],\n",
      "        [ 1.5288,  0.7991],\n",
      "        [ 0.4073,  1.3137],\n",
      "        [-0.6597, -0.1360],\n",
      "        [ 0.2303, -0.1621],\n",
      "        [ 0.1737,  0.7989],\n",
      "        [ 1.0014,  1.5575],\n",
      "        [ 1.2343,  1.1262],\n",
      "        [-0.0168,  0.3430]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 81, Loss: 0.03960547596216202\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6253,  1.0934],\n",
      "        [ 0.8187, -0.1776],\n",
      "        [ 1.7236,  0.5573],\n",
      "        [ 0.3130,  0.8784],\n",
      "        [-0.2840, -0.1643],\n",
      "        [-0.1034, -0.0839],\n",
      "        [ 0.0564,  0.8589],\n",
      "        [ 0.6591,  1.7237],\n",
      "        [ 1.2977,  0.9649],\n",
      "        [ 0.0341,  0.5780]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 82, Loss: 0.046239156275987625\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 7.9415e-01,  1.1631e+00],\n",
      "        [ 4.5946e-01, -1.1292e-03],\n",
      "        [ 1.4716e+00,  6.9797e-01],\n",
      "        [ 7.0174e-02,  8.2544e-01],\n",
      "        [-5.6335e-01, -1.2042e-01],\n",
      "        [ 6.2731e-02, -3.6987e-01],\n",
      "        [ 1.4878e-01,  5.6857e-01],\n",
      "        [ 1.1164e+00,  1.5790e+00],\n",
      "        [ 1.2945e+00,  1.1363e+00],\n",
      "        [ 2.8643e-01,  7.3914e-01]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 83, Loss: 0.04096277058124542\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 1.0042,  0.9771],\n",
      "        [ 0.3327, -0.4693],\n",
      "        [ 1.5260,  0.7404],\n",
      "        [-0.0456,  0.8085],\n",
      "        [-0.3099, -0.1117],\n",
      "        [-0.0486,  0.1286],\n",
      "        [-0.0963,  0.8156],\n",
      "        [ 0.9661,  1.7288],\n",
      "        [ 1.2548,  0.7056],\n",
      "        [ 0.5587,  0.8835]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 84, Loss: 0.05103294178843498\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8853,  1.0248],\n",
      "        [ 0.5213, -0.3685],\n",
      "        [ 1.6374,  0.4854],\n",
      "        [ 0.2711,  0.9507],\n",
      "        [-0.5571, -0.0684],\n",
      "        [ 0.1665,  0.2372],\n",
      "        [-0.1223,  1.2040],\n",
      "        [ 0.9297,  1.7059],\n",
      "        [ 1.1324,  0.7124],\n",
      "        [ 0.2796,  0.3131]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 85, Loss: 0.04736645519733429\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7059,  0.8662],\n",
      "        [ 0.7965, -0.4490],\n",
      "        [ 1.5821,  0.2315],\n",
      "        [ 0.4399,  0.8774],\n",
      "        [-0.1318,  0.0083],\n",
      "        [-0.0479,  0.3456],\n",
      "        [-0.3824,  1.1517],\n",
      "        [ 0.3453,  1.7724],\n",
      "        [ 1.4618,  0.8420],\n",
      "        [ 0.3771,  0.5401]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 86, Loss: 0.06484118103981018\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.8226,  0.5596],\n",
      "        [ 0.9662,  0.2571],\n",
      "        [ 1.5174,  0.7681],\n",
      "        [ 0.1226,  1.5163],\n",
      "        [-0.1835, -0.2359],\n",
      "        [-0.0943, -0.1142],\n",
      "        [-0.2835,  0.9062],\n",
      "        [ 0.4535,  1.2378],\n",
      "        [ 1.3914,  1.2945],\n",
      "        [ 0.4369, -0.0132]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 87, Loss: 0.06899525970220566\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7477,  1.0164],\n",
      "        [ 0.9343, -0.3046],\n",
      "        [ 1.6920,  0.4625],\n",
      "        [ 0.2237,  0.9668],\n",
      "        [-0.2207, -0.0672],\n",
      "        [ 0.6169, -0.1293],\n",
      "        [-0.2605,  0.9361],\n",
      "        [ 0.3435,  1.6758],\n",
      "        [ 1.1826,  1.0101],\n",
      "        [-0.1069,  0.6005]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 88, Loss: 0.03677661716938019\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.9055,  0.9345],\n",
      "        [ 1.0435, -0.0643],\n",
      "        [ 1.2685,  0.4170],\n",
      "        [-0.0739,  1.0207],\n",
      "        [-0.1491, -0.1735],\n",
      "        [ 0.2371, -0.0456],\n",
      "        [-0.2791,  1.1252],\n",
      "        [ 0.1517,  1.5904],\n",
      "        [ 1.5499,  1.1834],\n",
      "        [ 0.5016,  0.1705]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 89, Loss: 0.0578748993575573\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.9288,  0.5688],\n",
      "        [ 0.3462, -0.1542],\n",
      "        [ 1.5231,  0.5350],\n",
      "        [-0.0846,  1.2964],\n",
      "        [-0.3083, -0.1001],\n",
      "        [ 0.3186, -0.0785],\n",
      "        [-0.0480,  1.0622],\n",
      "        [ 0.9978,  1.5952],\n",
      "        [ 1.3472,  1.1090],\n",
      "        [ 0.1380,  0.3171]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 90, Loss: 0.04322124645113945\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7678,  0.9478],\n",
      "        [ 0.3978, -0.0242],\n",
      "        [ 1.4876,  0.7850],\n",
      "        [ 0.1780,  1.1459],\n",
      "        [-0.4306, -0.3231],\n",
      "        [-0.0079, -0.1173],\n",
      "        [-0.0137,  0.8609],\n",
      "        [ 0.9836,  1.4445],\n",
      "        [ 1.4270,  1.2266],\n",
      "        [ 0.3708,  0.1983]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 91, Loss: 0.04808606579899788\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[-0.2728,  0.8283],\n",
      "        [ 0.6863, -0.1953],\n",
      "        [ 1.2932,  0.4270],\n",
      "        [ 0.6401,  1.1772],\n",
      "        [-0.2892, -0.0575],\n",
      "        [ 0.9154, -0.0183],\n",
      "        [ 0.7080,  1.1197],\n",
      "        [ 0.7447,  1.6562],\n",
      "        [ 1.2129,  0.9825],\n",
      "        [-0.4774,  0.2196]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 92, Loss: 0.03723603114485741\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.2722,  1.0810],\n",
      "        [ 0.1854, -0.3470],\n",
      "        [ 1.0920,  0.6110],\n",
      "        [-0.2130,  0.8626],\n",
      "        [-0.3087,  0.0351],\n",
      "        [ 1.2016, -0.1708],\n",
      "        [ 1.0230,  0.8077],\n",
      "        [ 1.1579,  1.7149],\n",
      "        [ 0.9815,  0.9695],\n",
      "        [-0.2313,  0.5719]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 93, Loss: 0.04607367143034935\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.7968,  1.0887],\n",
      "        [ 0.0329, -0.0074],\n",
      "        [ 1.4034,  0.7775],\n",
      "        [ 0.0859,  0.9863],\n",
      "        [-0.2392, -0.3341],\n",
      "        [ 0.0529, -0.1826],\n",
      "        [-0.0282,  0.6889],\n",
      "        [ 1.1350,  1.5853],\n",
      "        [ 1.4425,  1.0995],\n",
      "        [ 0.4769,  0.4316]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 94, Loss: 0.05008901283144951\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6848,  0.7900],\n",
      "        [ 0.0825, -0.0534],\n",
      "        [ 1.5136,  0.9203],\n",
      "        [ 0.2251,  1.0972],\n",
      "        [-0.4686, -0.2627],\n",
      "        [ 0.4604, -0.2080],\n",
      "        [ 0.3708,  0.6083],\n",
      "        [ 1.1259,  1.6375],\n",
      "        [ 1.2596,  1.0868],\n",
      "        [-0.0985,  0.5168]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 95, Loss: 0.038528889417648315\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.6551,  0.5229],\n",
      "        [ 0.5084, -0.1566],\n",
      "        [ 1.2494,  0.7268],\n",
      "        [ 0.1179,  1.4166],\n",
      "        [-0.6088, -0.1040],\n",
      "        [ 0.2034, -0.1698],\n",
      "        [ 0.3812,  0.6298],\n",
      "        [ 1.1254,  1.5279],\n",
      "        [ 1.4661,  1.1663],\n",
      "        [ 0.0531,  0.5734]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 96, Loss: 0.04269211366772652\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.5781,  0.4519],\n",
      "        [ 0.5383,  0.0440],\n",
      "        [ 1.2649,  0.6395],\n",
      "        [ 0.3887,  1.5265],\n",
      "        [-0.5605, -0.0336],\n",
      "        [ 0.1999, -0.2482],\n",
      "        [ 0.3161,  0.8754],\n",
      "        [ 1.1180,  1.3730],\n",
      "        [ 1.4579,  1.2554],\n",
      "        [-0.1556,  0.2506]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 97, Loss: 0.041375670582056046\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.3948,  1.2017],\n",
      "        [ 0.0378, -0.2589],\n",
      "        [ 1.3685,  0.3288],\n",
      "        [ 0.2654,  0.7642],\n",
      "        [-0.4052, -0.1952],\n",
      "        [ 0.6512,  0.0904],\n",
      "        [ 0.7039,  1.0479],\n",
      "        [ 1.3371,  1.6213],\n",
      "        [ 1.0795,  1.0424],\n",
      "        [-0.2933,  0.4937]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 98, Loss: 0.039624445140361786\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[-0.1389,  0.9824],\n",
      "        [ 0.1980,  0.2561],\n",
      "        [ 1.0082,  0.6382],\n",
      "        [ 0.1039,  1.2679],\n",
      "        [ 0.1820, -0.3520],\n",
      "        [ 1.0567, -0.3132],\n",
      "        [ 1.0941,  0.6224],\n",
      "        [ 1.1987,  1.3140],\n",
      "        [ 1.0077,  1.3376],\n",
      "        [-0.5770,  0.3849]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 99, Loss: 0.07782482355833054\n",
      "Early stopping triggered.\n",
      "Size of input data: torch.Size([10, 2])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.4878,  1.1302],\n",
      "        [ 0.4034,  0.1952],\n",
      "        [ 1.2823,  0.8240],\n",
      "        [ 0.4616,  1.1013],\n",
      "        [-0.2234, -0.0884],\n",
      "        [ 0.3721, -0.0420],\n",
      "        [ 0.4060,  0.7955],\n",
      "        [ 1.0208,  1.5253],\n",
      "        [ 1.2324,  1.2027],\n",
      "        [ 0.0578,  0.5493]], device='cuda:0')\n",
      "Original Node Features:\n",
      "tensor([[5.4903e-01, 2.5007e-01, 8.6995e-01],\n",
      "        [9.3275e-01, 4.9941e-01, 2.7740e-04],\n",
      "        [9.2514e-01, 8.8184e-01, 5.6211e-01],\n",
      "        [4.8731e-01, 5.9435e-03, 7.4955e-01],\n",
      "        [1.7464e-01, 3.2527e-01, 1.8286e-01],\n",
      "        [9.0020e-01, 9.3631e-01, 4.7095e-01],\n",
      "        [2.7655e-01, 1.5860e-01, 5.3497e-01],\n",
      "        [1.1522e-01, 5.0392e-01, 7.3851e-01],\n",
      "        [9.8015e-01, 8.5043e-01, 9.7354e-01],\n",
      "        [1.9060e-01, 1.6310e-01, 3.0143e-01]], device='cuda:0')\n",
      "\n",
      "Reconstructed Node Features:\n",
      "tensor([[0.3864, 0.3128, 0.7098],\n",
      "        [0.6337, 0.5264, 0.3871],\n",
      "        [0.7972, 0.7185, 0.6960],\n",
      "        [0.3846, 0.3097, 0.6972],\n",
      "        [0.4676, 0.3457, 0.2219],\n",
      "        [0.6925, 0.5766, 0.3041],\n",
      "        [0.4542, 0.3682, 0.5885],\n",
      "        [0.4814, 0.4256, 0.9018],\n",
      "        [0.6632, 0.5976, 0.8174],\n",
      "        [0.3886, 0.2913, 0.4671]], device='cuda:0')\n",
      "Size of input data: torch.Size([10, 3])\n",
      "Size of embeddings: torch.Size([10, 2])\n",
      "Embeddings: tensor([[ 0.4878,  1.1302],\n",
      "        [ 0.4034,  0.1952],\n",
      "        [ 1.2823,  0.8240],\n",
      "        [ 0.4616,  1.1013],\n",
      "        [-0.2234, -0.0884],\n",
      "        [ 0.3721, -0.0420],\n",
      "        [ 0.4060,  0.7955],\n",
      "        [ 1.0208,  1.5253],\n",
      "        [ 1.2324,  1.2027],\n",
      "        [ 0.0578,  0.5493]], device='cuda:0')\n",
      "RMSE =  0.2055557668209076\n"
     ]
    }
   ],
   "source": [
    "def train_gae_with_early_stopping(node_features, adj_matrix, epochs=700, lr=0.04, weight_decay=5e-4, patience=20):\n",
    "    in_channels = node_features.shape[1]\n",
    "    \n",
    "    # Define the model inside the training function\n",
    "    model = GAE(in_channels=in_channels, hidden_dim=64, dropout=0.4).to(device)\n",
    "    \n",
    "    edge_index = torch.tensor(np.array(adj_matrix.nonzero()), dtype=torch.long).to(device)\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float).to(device)\n",
    "    data = Data(x=node_features, edge_index=edge_index).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        reconstructed = model.decoder(z)\n",
    "        \n",
    "        loss = criterion(reconstructed, data.x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    \n",
    "    return model, data\n",
    "\n",
    "def calculate_mse(original, reconstructed):\n",
    "    mse = nn.MSELoss()\n",
    "    return mse(reconstructed, original).item()\n",
    "\n",
    "# Set the device to CUDA if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Example usage\n",
    "node_features = np.random.rand(10, 3)\n",
    "adj_matrix = np.array([\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 0, 0, 0, 1, 0, 1],\n",
    "    [0, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model, data = train_gae_with_early_stopping(node_features, adj_matrix, epochs=700, lr=0.04, weight_decay=1e-4, patience=20)\n",
    "\n",
    "# Perform a forward pass and calculate RMSE\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model.encode(data.x, data.edge_index)\n",
    "    reconstructed = model.decoder(embeddings)\n",
    "    \n",
    "    print(\"Original Node Features:\")\n",
    "    print(data.x)\n",
    "    print(\"\\nReconstructed Node Features:\")\n",
    "    print(reconstructed)\n",
    "    print(\"Size of input data:\", data.x.size())\n",
    "    print(\"Size of embeddings:\", embeddings.size())\n",
    "    print(\"Embeddings:\", embeddings)\n",
    "\n",
    "    rmse_value = torch.sqrt(torch.tensor(calculate_mse(data.x.cpu(), reconstructed.cpu()))).item()\n",
    "    print(\"RMSE = \", rmse_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c2s \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the DQN model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim=19, hidden_dims=[76, 38], output_dim=5):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        self.fc3 = nn.Linear(hidden_dims[1], output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tanh(self.fc1(x))\n",
    "        x = self.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)  # Linear activation for the output layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Experience Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity=100000):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (state, action, reward, next_state, done)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_c2s_action_space(customers, noof_warehouses):\n",
    "    # Ensure customers and noof_warehouses are defined and populated correctly\n",
    "    actions = []\n",
    "    if not customers or noof_warehouses <= 0:\n",
    "        print(\"Error: No customers or warehouses provided.\")\n",
    "        return actions\n",
    "\n",
    "    for customer in customers:\n",
    "        for warehouse_id in range(noof_warehouses):\n",
    "            actions.append((customer.customer_id, warehouse_id, 0))  # Assign to warehouse\n",
    "        actions.append((customer.customer_id, -1, 1))  # Defer customer\n",
    "    return actions\n",
    "\n",
    "\n",
    "def train_c2s_agent(env, gae_model, dqn_model, replay_buffer, epochs=1000, batch_size=512, discount_factor=0.9):\n",
    "    optimizer = optim.Adam(dqn_model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if len(replay_buffer) < batch_size:\n",
    "            continue\n",
    "        \n",
    "        env.reset()\n",
    "        feature_matrix, adjacency_matrix = env.create_graph_matrices()\n",
    "        feature_matrix = torch.tensor(feature_matrix, dtype=torch.float).to(device)\n",
    "        adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.long).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embeddings = gae_model.encode(feature_matrix, adjacency_matrix)\n",
    "        state = embeddings.flatten().cpu().numpy()\n",
    "\n",
    "        for t in range(100):  # Assume each episode has max length of 100 steps\n",
    "            action_space = get_c2s_action_space(env.customers, env.noof_warehouses)\n",
    "            action_index = dqn_model(torch.tensor(state, dtype=torch.float).unsqueeze(0).to(device)).argmax().item()\n",
    "            action = action_space[action_index]\n",
    "            reward = env.c2s_rewards(action)\n",
    "            \n",
    "            next_feature_matrix, next_adjacency_matrix = env.create_graph_matrices()\n",
    "            next_feature_matrix = torch.tensor(next_feature_matrix, dtype=torch.float).to(device)\n",
    "            next_adjacency_matrix = torch.tensor(next_adjacency_matrix, dtype=torch.long).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                next_embeddings = gae_model.encode(next_feature_matrix, next_adjacency_matrix)\n",
    "            next_state = next_embeddings.flatten().cpu().numpy()\n",
    "            \n",
    "            done = np.random.choice([0, 1])\n",
    "            replay_buffer.push(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Sample a batch from replay buffer and update DQN\n",
    "        batch = replay_buffer.sample(batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        states = torch.tensor(np.array(states), dtype=torch.float).to(device)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).to(device)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float).to(device)\n",
    "        next_states = torch.tensor(np.array(next_states), dtype=torch.float).to(device)\n",
    "        dones = torch.tensor(dones, dtype=torch.float).to(device)\n",
    "        \n",
    "        current_q_values = dqn_model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        max_next_q_values = dqn_model(next_states).max(1)[0]\n",
    "        expected_q_values = rewards + (discount_factor * max_next_q_values * (1 - dones))\n",
    "        \n",
    "        loss = criterion(current_q_values, expected_q_values)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "def make_decisions(env, gae_model, dqn_model, feature_matrix, adjacency_matrix):\n",
    "    # Convert the input data to tensors\n",
    "    feature_matrix = torch.tensor(feature_matrix, dtype=torch.float).to(device)\n",
    "    edge_index = torch.tensor(np.array(adjacency_matrix.nonzero()), dtype=torch.long).to(device)\n",
    "    \n",
    "    # Encode the features to obtain embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = gae_model.encode(feature_matrix, edge_index)\n",
    "    state = embeddings.flatten().cpu().numpy()\n",
    "\n",
    "    # Ensure the state tensor has the correct shape\n",
    "    state_dim = dqn_model.fc1.in_features  # Get the expected input dimension from the DQN model\n",
    "    state = state[:state_dim]  # Ensure the state has the correct number of features\n",
    "    state = torch.tensor(state, dtype=torch.float).unsqueeze(0).to(device)\n",
    "\n",
    "    # Get the action space\n",
    "    action_space = get_c2s_action_space(env.customers, env.noof_warehouses)\n",
    "    print(f'Action space size: {len(action_space)}')\n",
    "    print(f'Q-values output size: {dqn_model(state).size()}')\n",
    "\n",
    "    if len(action_space) == 0:\n",
    "        print(\"Error: Action space is empty.\")\n",
    "        return []\n",
    "\n",
    "    # Get the action for the given embeddings\n",
    "    with torch.no_grad():\n",
    "        q_values = dqn_model(state)\n",
    "    action_index = q_values.argmax().item()\n",
    "    print(f'Action index: {action_index}')\n",
    "\n",
    "    # Ensure the action index is within bounds\n",
    "    if action_index >= len(action_space):\n",
    "        action_index = len(action_space) - 1\n",
    "    action = action_space[action_index]\n",
    "    \n",
    "    return [action]  # Ensure the return value is a list of tuples\n",
    "\n",
    "\n",
    "# def generate_hardcoded_data():\n",
    "#     customers = list(range(10))  # 10 customer IDs\n",
    "#     noof_warehouses = 4  # 4 warehouses\n",
    "#     feature_matrix = np.array([\n",
    "#         [0.1, 0.2, 0.3],\n",
    "#         [0.4, 0.5, 0.6],\n",
    "#         [0.7, 0.8, 0.9],\n",
    "#         [1.0, 1.1, 1.2],\n",
    "#         [1.3, 1.4, 1.5],\n",
    "#         [1.6, 1.7, 1.8],\n",
    "#         [1.9, 2.0, 2.1],\n",
    "#         [2.2, 2.3, 2.4],\n",
    "#         [2.5, 2.6, 2.7],\n",
    "#         [2.8, 2.9, 3.0]\n",
    "#     ])  # Hardcoded feature matrix\n",
    "#     adjacency_matrix = np.array([\n",
    "#         [0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "#         [1, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
    "#         [0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
    "#         [0, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
    "#         [0, 0, 0, 1, 0, 1, 0, 0, 0, 1],\n",
    "#         [0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
    "#         [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
    "#         [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
    "#         [1, 0, 1, 0, 0, 0, 0, 1, 0, 1],\n",
    "#         [0, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
    "#     ])  # Hardcoded adjacency matrix\n",
    "#     return customers, noof_warehouses, feature_matrix, adjacency_matrix\n",
    "\n",
    "\n",
    "# # Generate hardcoded data\n",
    "# customers, noof_warehouses, feature_matrix, adjacency_matrix = generate_hardcoded_data()\n",
    "\n",
    "# # Initialize models\n",
    "# gae_model = GAE(in_channels=3, hidden_dim=64, dropout=0.4).to(device)\n",
    "# dqn_model = DQN(input_dim=19, output_dim=5).to(device)\n",
    "\n",
    "# # Test the make_decisions function with hardcoded data\n",
    "# action_example, reward_example = make_decisions(gae_model, dqn_model, customers, noof_warehouses, feature_matrix, adjacency_matrix)\n",
    "# print(f'Action for the given embeddings: {action_example}, Reward: {reward_example}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "def generate_synthetic_data(num_samples=1000, state_dim=19, action_dim=5):\n",
    "    states = np.random.rand(num_samples, state_dim)\n",
    "    actions = np.random.randint(0, action_dim, size=(num_samples,))\n",
    "    rewards = np.random.rand(num_samples)\n",
    "    next_states = np.random.rand(num_samples, state_dim)\n",
    "    dones = np.random.choice([0, 1], size=(num_samples,))\n",
    "    return states, actions, rewards, next_states, dones\n",
    "\n",
    "states, actions, rewards, next_states, dones = generate_synthetic_data()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "states = torch.tensor(states, dtype=torch.float).to(device)\n",
    "actions = torch.tensor(actions, dtype=torch.long).to(device)\n",
    "rewards = torch.tensor(rewards, dtype=torch.float).to(device)\n",
    "next_states = torch.tensor(next_states, dtype=torch.float).to(device)\n",
    "dones = torch.tensor(dones, dtype=torch.float).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_dqn_model(dqn_model, states, actions, rewards, next_states, dones, batch_size=64, discount_factor=0.9, epochs=100):\n",
    "    optimizer = optim.Adam(dqn_model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    num_samples = states.size(0)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        permutation = torch.randperm(num_samples)\n",
    "        \n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            indices = permutation[i:i + batch_size]\n",
    "            batch_states = states[indices]\n",
    "            batch_actions = actions[indices]\n",
    "            batch_rewards = rewards[indices]\n",
    "            batch_next_states = next_states[indices]\n",
    "            batch_dones = dones[indices]\n",
    "            \n",
    "            current_q_values = dqn_model(batch_states).gather(1, batch_actions.unsqueeze(1)).squeeze(1)\n",
    "            max_next_q_values = dqn_model(batch_next_states).max(1)[0]\n",
    "            expected_q_values = batch_rewards + (discount_factor * max_next_q_values * (1 - batch_dones))\n",
    "            \n",
    "            loss = criterion(current_q_values, expected_q_values)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Train the DQN model\n",
    "train_dqn_model(dqn_model, states, actions, rewards, next_states, dones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def test_dqn_model(dqn_model, test_states):\n",
    "    dqn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        q_values = dqn_model(test_states)\n",
    "        actions = q_values.argmax(1).cpu().numpy()\n",
    "    return actions\n",
    "\n",
    "# Generate some test states\n",
    "test_states = torch.tensor(np.random.rand(10, 19), dtype=torch.float).to(device)\n",
    "\n",
    "# Get actions for the test states\n",
    "actions = test_dqn_model(dqn_model, test_states)\n",
    "print(f'Actions for test states: {actions}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vrp_action_space(customers):\n",
    "    return list(permutations(customers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class VRPLNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim ):\n",
    "        super(VRPLNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 8)\n",
    "        self.fc5 = nn.Linear(8, output_dim)  # Adjusted to output the correct number of actions\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tanh(self.fc1(x))\n",
    "        x = self.tanh(self.fc2(x))\n",
    "        x = self.tanh(self.fc3(x))\n",
    "        x = self.tanh(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "    def make_decisions(self, env, gae_model, feature_matrix, adjacency_matrix):\n",
    "        # Convert the input data to tensors\n",
    "        feature_matrix = torch.tensor(feature_matrix, dtype=torch.float).to(device)\n",
    "        edge_index = torch.tensor(np.array(adjacency_matrix.nonzero()), dtype=torch.long).to(device)\n",
    "        \n",
    "        # Encode the features to obtain embeddings\n",
    "        with torch.no_grad():\n",
    "            embeddings = gae_model.encode(feature_matrix, edge_index)\n",
    "        state = embeddings.flatten().cpu().numpy()\n",
    "\n",
    "        # Ensure the state tensor has the correct shape\n",
    "        state_dim = self.fc1.in_features  # Get the expected input dimension from the VRP model\n",
    "        state = state[:state_dim]  # Ensure the state has the correct number of features\n",
    "        state = torch.tensor(state, dtype=torch.float).unsqueeze(0).to(device)\n",
    "\n",
    "        # Get the action space\n",
    "        action_space = get_vrp_action_space(env.customers)\n",
    "        print(f'Action space size: {len(action_space)}')\n",
    "        print(f'Q-values output size: {self(state).size()}')\n",
    "\n",
    "        if len(action_space) == 0:\n",
    "            print(\"Error: Action space is empty.\")\n",
    "            return []\n",
    "\n",
    "        # Get the action for the given embeddings\n",
    "        with torch.no_grad():\n",
    "            q_values = self(state)\n",
    "        action_index = q_values.argmax().item()\n",
    "        print(f'Action index: {action_index}')\n",
    "\n",
    "        # Ensure the action index is within bounds\n",
    "        if action_index >= len(action_space):\n",
    "            action_index = len(action_space) - 1\n",
    "        action = action_space[action_index]\n",
    "        \n",
    "        return action  # Return the action tuple\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.array(state), np.array(action), np.array(reward), np.array(next_state), np.array(done)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vrp_action_space(customers):\n",
    "    return list(permutations(customers))\n",
    "\n",
    "def train_vrpl_agent(env, gae_model, vrp_model, replay_buffer, epochs=1000, batch_size=512, discount_factor=0.9, lr=0.001):\n",
    "    optimizer = optim.Adam(vrp_model.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.999\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if len(replay_buffer) < batch_size:\n",
    "            continue\n",
    "        \n",
    "        env.reset()\n",
    "        feature_matrix, adjacency_matrix = env.create_graph_matrices()\n",
    "        feature_matrix = torch.tensor(feature_matrix, dtype=torch.float).to(device)\n",
    "        adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.long).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embeddings = gae_model.encode(feature_matrix, adjacency_matrix)\n",
    "        state = embeddings.flatten().cpu().numpy()\n",
    "\n",
    "        for t in range(100):  # Assume each episode has max length of 100 steps\n",
    "            action_space = get_vrp_action_space(env.customers)\n",
    "            \n",
    "            if random.random() < epsilon:\n",
    "                action_index = random.randint(0, len(action_space) - 1)\n",
    "            else:\n",
    "                action_values = vrp_model(torch.tensor(state, dtype=torch.float).unsqueeze(0).to(device))\n",
    "                action_index = torch.softmax(action_values, dim=-1).argmax().item()\n",
    "                \n",
    "            vrp_action = action_space[action_index]\n",
    "            env.input_actions([], vrp_action)  # Apply VRP actions\n",
    "            \n",
    "            reward = env.calculate_vrp_reward(vrp_action)\n",
    "            \n",
    "            next_feature_matrix, next_adjacency_matrix = env.create_graph_matrices()\n",
    "            next_feature_matrix = torch.tensor(next_feature_matrix, dtype=torch.float).to(device)\n",
    "            next_adjacency_matrix = torch.tensor(next_adjacency_matrix, dtype=torch.long).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                next_embeddings = gae_model.encode(next_feature_matrix, next_adjacency_matrix)\n",
    "            next_state = next_embeddings.flatten().cpu().numpy()\n",
    "            \n",
    "            done = env.is_done()  # Check if the episode is done\n",
    "            replay_buffer.push(state, vrp_action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Sample a batch from replay buffer and update VRP model\n",
    "        batch = replay_buffer.sample(batch_size)\n",
    "        states, actions, rewards, next_states, dones = batch\n",
    "        states = torch.tensor(states, dtype=torch.float).to(device)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).to(device)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float).to(device)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float).to(device)\n",
    "        dones = torch.tensor(dones, dtype=torch.float).to(device)\n",
    "        \n",
    "        current_q_values = vrp_model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        max_next_q_values = vrp_model(next_states).max(1)[0]\n",
    "        expected_q_values = rewards + (discount_factor * max_next_q_values * (1 - dones))\n",
    "        \n",
    "        loss = criterion(current_q_values, expected_q_values)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epsilon = max(epsilon * epsilon_decay, 0.01)  # Decay epsilon\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / 100}, Epsilon: {epsilon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fabricate_data(input_dim, action_space_size, num_samples):\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        state = np.random.rand(input_dim)\n",
    "        action = random.randint(0, action_space_size - 1)\n",
    "        reward = random.random()\n",
    "        next_state = np.random.rand(input_dim)\n",
    "        done = random.choice([0, 1])\n",
    "        data.append((state, action, reward, next_state, done))\n",
    "    return data\n",
    "\n",
    "def train_vrpl_agent_fabricated(vrp_model, replay_buffer, input_dim, action_space_size, epochs=1000, batch_size=512, discount_factor=0.9, lr=0.001):\n",
    "    optimizer = optim.Adam(vrp_model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.999\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if len(replay_buffer) < batch_size:\n",
    "            continue\n",
    "\n",
    "        total_loss = 0\n",
    "        \n",
    "        for _ in range(100):  # Assume each episode has max length of 100 steps\n",
    "            state = np.random.rand(input_dim)\n",
    "            action_space = list(range(action_space_size))\n",
    "            \n",
    "            if random.random() < epsilon:\n",
    "                action_index = random.randint(0, action_space_size - 1)\n",
    "            else:\n",
    "                action_values = vrp_model(torch.tensor(state, dtype=torch.float).unsqueeze(0).to(device))\n",
    "                action_index = torch.softmax(action_values, dim=-1).argmax().item()\n",
    "            \n",
    "            action = action_space[action_index]\n",
    "            reward = random.random()\n",
    "            next_state = np.random.rand(input_dim)\n",
    "            done = random.choice([0, 1])\n",
    "            \n",
    "            replay_buffer.push(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Sample a batch from replay buffer and update VRP model\n",
    "        batch = replay_buffer.sample(batch_size)\n",
    "        states, actions, rewards, next_states, dones = batch\n",
    "        states = torch.tensor(states, dtype=torch.float).to(device)\n",
    "        actions = torch.tensor(actions, dtype=torch.long).to(device)\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float).to(device)\n",
    "        next_states = torch.tensor(next_states, dtype=torch.float).to(device)\n",
    "        dones = torch.tensor(dones, dtype=torch.float).to(device)\n",
    "        \n",
    "        current_q_values = vrp_model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "        max_next_q_values = vrp_model(next_states).max(1)[0]\n",
    "        expected_q_values = rewards + (discount_factor * max_next_q_values * (1 - dones))\n",
    "        \n",
    "        loss = criterion(current_q_values, expected_q_values)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        epsilon = max(epsilon * epsilon_decay, 0.01)  # Decay epsilon\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / 100}, Epsilon: {epsilon}')\n",
    "\n",
    "# Initialize VRP model and replay buffer\n",
    "input_dim = 255  # Example input dimension, adjust as needed\n",
    "action_space_size = 10  # Example action space size, adjust as needed\n",
    "vrp_model = VRPLNetwork(input_dim).to(device)\n",
    "replay_buffer = ReplayBuffer(max_size=10000)\n",
    "\n",
    "# Fabricate data and add to replay buffer\n",
    "fabricated_data = fabricate_data(input_dim, action_space_size, num_samples=10000)\n",
    "for data in fabricated_data:\n",
    "    replay_buffer.push(*data)\n",
    "\n",
    "# Train VRP agent with fabricated data\n",
    "train_vrpl_agent_fabricated(vrp_model, replay_buffer, input_dim, action_space_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmrnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "class Warehouse:\n",
    "    def __init__(self, warehouse_id, location, max_inventory):\n",
    "        self.warehouse_id = warehouse_id\n",
    "        self.location = location\n",
    "        self.max_inventory = max_inventory\n",
    "        self.current_inventory = max_inventory\n",
    "\n",
    "    def restock(self):\n",
    "        self.current_inventory = self.max_inventory\n",
    "\n",
    "class Customer:\n",
    "    def __init__(self, customer_id, location, demand, time_window, noof_defered=0):\n",
    "        self.customer_id = customer_id\n",
    "        self.location = location\n",
    "        self.demand = demand\n",
    "        self.time_window = time_window\n",
    "        self.fulfilled = False\n",
    "        self.noof_defered = noof_defered\n",
    "        self.assigned_warehouse_id = None\n",
    "        self.assigned_vehicle_id = None\n",
    "\n",
    "class Vehicle:\n",
    "    def __init__(self, vehicle_id, capacity, speed):\n",
    "        self.vehicle_id = vehicle_id\n",
    "        self.capacity = capacity\n",
    "        self.speed = speed\n",
    "        self.route = []\n",
    "        self.current_load = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.route = []\n",
    "        self.current_load = 0\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, grid_size=200, noof_warehouses=4, noof_customers=400, vehicle_capacity=20, vehicle_speed=2, simulation_time=100, episode_time=5):\n",
    "        self.grid_size = grid_size\n",
    "        self.noof_warehouses = noof_warehouses\n",
    "        self.noof_customers = noof_customers\n",
    "        self.vehicle_capacity = vehicle_capacity\n",
    "        self.vehicle_speed = vehicle_speed\n",
    "        self.simulation_time = simulation_time\n",
    "        self.episode_time = episode_time\n",
    "        self.no_of_episodes = simulation_time // episode_time\n",
    "        self.time_lapsed = 0\n",
    "\n",
    "        self.warehouses = self._setting_up_warehouses()\n",
    "        self.vehicles = []\n",
    "        self.customers = []\n",
    "\n",
    "    def _setting_up_warehouses(self):\n",
    "        warehouse_locations = [\n",
    "            (-self.grid_size / 4, -self.grid_size / 4),\n",
    "            (self.grid_size / 4, -self.grid_size / 4),\n",
    "            (-self.grid_size / 4, self.grid_size / 4),\n",
    "            (self.grid_size / 4, self.grid_size / 4)\n",
    "        ]\n",
    "        warehouses = [Warehouse(warehouse_id=i, location=warehouse_locations[i], max_inventory=100) for i in range(self.noof_warehouses)]\n",
    "        return warehouses\n",
    "\n",
    "    def generate_customers(self):\n",
    "        customers_per_episode = self.noof_customers // self.no_of_episodes\n",
    "        customers_per_episode_rnd = rnd.randint(customers_per_episode // 2, customers_per_episode)\n",
    "        start = len(self.customers)\n",
    "        if start + customers_per_episode_rnd > self.noof_customers:\n",
    "            raise ValueError(f\"Attempting to generate {customers_per_episode_rnd} customers exceeds the total allowed {self.noof_customers}.\")\n",
    "        for i in range(start, start + customers_per_episode_rnd):\n",
    "            x = rnd.uniform(-self.grid_size / 2, self.grid_size / 2)\n",
    "            y = rnd.uniform(-self.grid_size / 2, self.grid_size / 2)\n",
    "            demand = rnd.randint(1, 10)\n",
    "            time_window = (rnd.uniform(0.2, 0.8) * self.grid_size, rnd.uniform(0.9, 2.0) * self.grid_size)\n",
    "            self.customers.append(Customer(customer_id=i, demand=demand, location=(x, y), time_window=time_window))\n",
    "\n",
    "    def reset(self):\n",
    "        for warehouse in self.warehouses:\n",
    "            warehouse.restock()\n",
    "        self.vehicles = []\n",
    "        self.customers = []\n",
    "        self.generate_customers()\n",
    "\n",
    "    def distance(self, loc1, loc2):\n",
    "        return np.sqrt((loc1[0] - loc2[0]) ** 2 + (loc1[1] - loc2[1]) ** 2)\n",
    "\n",
    "    def norm_1_distance(self, loc1, loc2):\n",
    "        return np.mod(loc1[0] - loc2[0]) + np.mod(loc1[1] - loc2[1])\n",
    "\n",
    "    # def create_graph_matrices(self):\n",
    "    #     feature_matrix = np.random.rand(self.noof_customers, 3)  # Example feature matrix\n",
    "    #     adjacency_matrix = np.random.randint(0, 2, (self.noof_customers, self.noof_customers))  # Example adjacency matrix\n",
    "    #     return feature_matrix, adjacency_matrix\n",
    "\n",
    "\n",
    "    # def simulation_for_each_episode(self, gae_model):\n",
    "    #     self.generate_customers()\n",
    "    #     feature_matrix, adjacency_matrix = self.create_graph_matrices()\n",
    "    #     # Perform a forward pass and calculate RMSE\n",
    "\n",
    "    #     data = Data(x=feature_matrix, edge_index=adjacency_matrix).to(device)\n",
    "    #     gae_model.eval()\n",
    "    #     with torch.no_grad():\n",
    "    #         embeddings = gae_model.encode(data.x, data.edge_index)\n",
    "    #     make_decisions(env, gae_model, dqn_model, feature_matrix, adjacency_matrix)\n",
    "        \n",
    "    #     self.Rl_Decision(feature_matrix, adjacency_matrix)\n",
    "    #     self.time_lapsed += self.episode_time\n",
    "\n",
    "    def simulation(self):\n",
    "        self.time_lapsed = 0\n",
    "        self.reset()\n",
    "        for i in range(self.no_of_episodes):\n",
    "            self.simulation_for_each_episode()\n",
    "\n",
    "    def input_actions(self, c2s_decisions, vrp_decisions):\n",
    "        self.vehicles = []  # Clear the list of vehicles\n",
    "        vehicle_ids = [decision[0] for decision in vrp_decisions]  # Extract vehicle IDs from vrp_decisions\n",
    "        noof_vehicles = len(set(vehicle_ids))  # Get unique vehicle count\n",
    "\n",
    "        for vehicle_id in range(noof_vehicles):\n",
    "            vehicle = Vehicle(vehicle_id=vehicle_id, capacity=self.vehicle_capacity, speed=self.vehicle_speed)\n",
    "            self.vehicles.append(vehicle)\n",
    "\n",
    "        for decision in c2s_decisions:\n",
    "            customer_id, warehouse_id, defer_flag = decision\n",
    "            customer = self.customers[customer_id]\n",
    "            if defer_flag:\n",
    "                customer.noof_defered += 1\n",
    "                continue\n",
    "            warehouse = self.warehouses[warehouse_id]\n",
    "            if warehouse.current_inventory >= customer.demand:\n",
    "                customer.assigned_warehouse_id = warehouse_id\n",
    "                warehouse.current_inventory -= customer.demand\n",
    "                customer.fulfilled = True\n",
    "            else:\n",
    "                customer.noof_defered += 1\n",
    "\n",
    "        for decision in vrp_decisions:\n",
    "            vehicle_id, route = decision\n",
    "            vehicle = self.vehicles[vehicle_id]\n",
    "            vehicle.reset()\n",
    "\n",
    "            for customer_id in route:\n",
    "                customer = self.customers[customer_id]\n",
    "                warehouse_id = customer.assigned_warehouse_id if customer.assigned_warehouse_id is not None else -1\n",
    "                if warehouse_id == -1:\n",
    "                    continue  # Skip if no warehouse assigned\n",
    "                if customer.fulfilled and vehicle.current_load + customer.demand <= vehicle.capacity:\n",
    "                    vehicle.route.append(customer.location)\n",
    "                    vehicle.current_load += customer.demand\n",
    "                else:\n",
    "                    customer.noof_defered += 1\n",
    "                    customer.fulfilled = False\n",
    "\n",
    "    \n",
    "\n",
    "    def calculate_c2s_reward(self, decision):\n",
    "        a1 = 1\n",
    "        a2 = 2\n",
    "        customer_id, warehouse_id, defer_flag = decision\n",
    "        customer = self.customers[customer_id]\n",
    "        if defer_flag:\n",
    "            h = customer.noof_defered\n",
    "            deferred_reward = a1 * (-2.12) + a2 * (-1)\n",
    "            return np.power(0.9, h) * deferred_reward\n",
    "        warehouse = self.warehouses[warehouse_id]\n",
    "        Di = -self.distance(warehouse.location, customer.location)\n",
    "        trip_customers = sum(1 for c in self.customers if c.assigned_warehouse_id == warehouse_id)\n",
    "        Li = -Di / max(trip_customers, 1)\n",
    "        Fi = 1 if customer.fulfilled else 0\n",
    "        Ui = -((self.vehicle_capacity - customer.demand) / self.vehicle_capacity)\n",
    "        return a1 * (Di + Li) + Fi + a2 * Ui\n",
    "\n",
    "    def calculate_vrp_reward(self, decision):\n",
    "        vehicle_id, route = decision\n",
    "        vehicle = self.vehicles[vehicle_id]\n",
    "        P = len(route)\n",
    "        route_distance = 0\n",
    "        vrp_rewards = []\n",
    "\n",
    "        for p, customer_id in enumerate(route):\n",
    "            customer = self.customers[customer_id]\n",
    "            warehouse_id = customer.assigned_warehouse_id if customer.assigned_warehouse_id is not None else -1\n",
    "            if warehouse_id == -1:\n",
    "                continue  # Skip if no warehouse assigned\n",
    "            dp = self.distance(vehicle.route[p - 1] if p > 0 else self.warehouses[warehouse_id].location, customer.location)\n",
    "            tp = dp / vehicle.speed\n",
    "            Rk_p = (0.7 - dp / self.grid_size) + (1.0 - tp / 1.5) + (0.9 * (P - p))\n",
    "            vrp_rewards.append(Rk_p)\n",
    "            route_distance += dp\n",
    "\n",
    "        if route:\n",
    "            last_customer = self.customers[route[-1]]\n",
    "            last_warehouse_id = last_customer.assigned_warehouse_id if last_customer.assigned_warehouse_id is not None else -1\n",
    "            if last_warehouse_id == -1:\n",
    "                last_warehouse_id = 0  # Default to the first warehouse if none assigned (or handle appropriately)\n",
    "            Dreturn = self.distance(vehicle.route[-1], self.warehouses[last_warehouse_id].location)\n",
    "        else:\n",
    "            Dreturn = 0\n",
    "        Rterm = 2 * 0.7 - 1 / (P + 1) * (route_distance + Dreturn)\n",
    "        vrp_rewards.append(Rterm)\n",
    "\n",
    "        return vrp_rewards\n",
    "        \n",
    "    def create_graph_matrices(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        n_warehouses = len(self.warehouses)\n",
    "        n_customers = len(self.customers)\n",
    "        n_nodes = n_warehouses + n_customers\n",
    "\n",
    "        # Initialize matrices\n",
    "        feature_matrix = np.zeros((n_nodes, 7))  # 7 features including node ID\n",
    "        adjacency_matrix = np.zeros((n_nodes, n_nodes))\n",
    "\n",
    "        # Add warehouse features\n",
    "        for i, warehouse in enumerate(self.warehouses):\n",
    "            x, y = warehouse.location\n",
    "            feature_matrix[i] = [\n",
    "                x / self.grid_size,  # normalized x\n",
    "                y / self.grid_size,  # normalized y\n",
    "                1.0,                 # is_warehouse flag\n",
    "                warehouse.current_inventory / warehouse.max_inventory,\n",
    "                0.0,                 # no time window start\n",
    "                1.0,                 # no time window end\n",
    "                warehouse.warehouse_id  # warehouse ID\n",
    "            ]\n",
    "\n",
    "        # Add customer features\n",
    "        for i, customer in enumerate(self.customers):\n",
    "            idx = i + n_warehouses\n",
    "            x, y = customer.location\n",
    "            time_start, time_end = customer.time_window\n",
    "            \n",
    "            feature_matrix[idx] = [\n",
    "                x / self.grid_size,\n",
    "                y / self.grid_size,\n",
    "                0.0,               # is_warehouse flag\n",
    "                customer.demand / 10.0,  # normalized demand\n",
    "                time_start / self.grid_size,\n",
    "                time_end / self.grid_size,\n",
    "                customer.customer_id  # customer ID\n",
    "            ]\n",
    "\n",
    "        # Create connections in adjacency matrix\n",
    "        for w_idx, warehouse in enumerate(self.warehouses):\n",
    "            for c_idx, customer in enumerate(self.customers):\n",
    "                matrix_idx = c_idx + n_warehouses\n",
    "                distance = self.distance(warehouse.location, customer.location)\n",
    "                time_start, time_end = customer.time_window\n",
    "\n",
    "                is_feasible = (\n",
    "                    warehouse.current_inventory >= customer.demand and\n",
    "                    distance <= self.grid_size * 0.7 and\n",
    "                    time_end - time_start >= distance\n",
    "                )\n",
    "\n",
    "                if is_feasible:\n",
    "                    time_compatibility = 1.0 - (time_start / time_end)\n",
    "                    edge_weight = 1.0 / (1.0 + distance) * time_compatibility\n",
    "                    adjacency_matrix[w_idx, matrix_idx] = edge_weight\n",
    "                    adjacency_matrix[matrix_idx, w_idx] = edge_weight\n",
    "\n",
    "        # Add customer-to-customer connections\n",
    "        for i, cust1 in enumerate(self.customers):\n",
    "            idx1 = i + n_warehouses\n",
    "            time_start1, time_end1 = cust1.time_window\n",
    "            \n",
    "            for j, cust2 in enumerate(self.customers[i+1:]):\n",
    "                idx2 = j + i + 1 + n_warehouses\n",
    "                time_start2, time_end2 = cust2.time_window\n",
    "                distance = self.distance(cust1.location, cust2.location)\n",
    "\n",
    "                time_compatible = (\n",
    "                    (time_start1 <= time_start2 and time_end1 <= time_end2) or\n",
    "                    (time_start2 <= time_start1 and time_end2 <= time_end1)\n",
    "                )\n",
    "\n",
    "                if time_compatible and distance <= self.grid_size * 0.3:\n",
    "                    edge_weight = 1.0 / (1.0 + distance)\n",
    "                    adjacency_matrix[idx1, idx2] = edge_weight\n",
    "                    adjacency_matrix[idx2, idx1] = edge_weight\n",
    "\n",
    "        return feature_matrix, adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Environment\n",
    "env = Environment()\n",
    "\n",
    "# Test resetting the environment\n",
    "print(\"Testing environment reset...\")\n",
    "env.reset()\n",
    "print(f\"Number of warehouses: {len(env.warehouses)}\")\n",
    "print(f\"Number of customers: {len(env.customers)}\")\n",
    "print(\"Warehouses after reset:\")\n",
    "for warehouse in env.warehouses:\n",
    "    print(f\"Warehouse ID: {warehouse.warehouse_id}, Location: {warehouse.location}, Current Inventory: {warehouse.current_inventory}\")\n",
    "\n",
    "print(\"\\nCustomers after reset:\")\n",
    "for customer in env.customers:\n",
    "    print(f\"Customer ID: {customer.customer_id}, Location: {customer.location}, Demand: {customer.demand}, Time Window: {customer.time_window}\")\n",
    "\n",
    "# Test generating customers\n",
    "print(\"\\nTesting customer generation...\")\n",
    "env.generate_customers()\n",
    "print(f\"Number of customers after generation: {len(env.customers)}\")\n",
    "\n",
    "# Test distance calculation\n",
    "print(\"\\nTesting distance calculation...\")\n",
    "loc1 = (0, 0)\n",
    "loc2 = (3, 4)\n",
    "distance = env.distance(loc1, loc2)\n",
    "print(f\"Distance between {loc1} and {loc2}: {distance}\")\n",
    "\n",
    "# Test creating graph matrices\n",
    "print(\"\\nTesting graph matrix creation...\")\n",
    "feature_matrix, adjacency_matrix = env.create_graph_matrices()\n",
    "print(f\"Feature matrix shape: {feature_matrix.shape}\")\n",
    "print(f\"Adjacency matrix shape: {adjacency_matrix.shape}\")\n",
    "\n",
    "# Test input actions\n",
    "print(\"\\nTesting input actions...\")\n",
    "c2s_decisions = [(0, 0, 0), (1, 1, 1)]\n",
    "vrp_decisions = [(0, [0, 1])]\n",
    "env.input_actions(c2s_decisions, vrp_decisions)\n",
    "for customer in env.customers:\n",
    "    print(f\"Customer ID: {customer.customer_id}, Fulfilled: {customer.fulfilled}, No. of Deferred: {customer.noof_defered}, Assigned Warehouse: {customer.assigned_warehouse_id}\")\n",
    "\n",
    "# Test reward calculation\n",
    "print(\"\\nTesting reward calculation...\")\n",
    "c2s_rewards, vrp_rewards = env.calculate_rewards(c2s_decisions, vrp_decisions)\n",
    "print(f\"C2S Rewards: {c2s_rewards}\")\n",
    "print(f\"VRP Rewards: {vrp_rewards}\")\n",
    "\n",
    "# Test simulation\n",
    "print(\"\\nOutput Embeddings...\")\n",
    "print(env.create_graph_matrices())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[-0.2689, -1.6878],\n",
      "        [ 1.5989,  0.8531],\n",
      "        [-1.1583,  0.2240],\n",
      "        [-0.1717,  0.6107]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 1, Loss: 1.4533520936965942\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 1.0302, -0.0827],\n",
      "        [ 0.7539,  1.5290],\n",
      "        [-0.6779, -0.9733],\n",
      "        [-1.2663, -0.6330]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 2, Loss: 1.1574887037277222\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9120, -0.0431],\n",
      "        [ 0.5692,  1.3338],\n",
      "        [-0.3209, -1.2181],\n",
      "        [-1.4790, -0.3835]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 3, Loss: 1.0329029560089111\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6926, -0.5151],\n",
      "        [ 0.7338,  1.3353],\n",
      "        [-0.4939, -1.0232],\n",
      "        [-1.4087, -0.2440]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 4, Loss: 0.9185439944267273\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8912, -0.3862],\n",
      "        [ 0.3557,  1.0412],\n",
      "        [-0.4920, -1.2970],\n",
      "        [-1.3886,  0.0762]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 5, Loss: 0.8235088586807251\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7712,  0.3232],\n",
      "        [ 0.3983,  0.7808],\n",
      "        [-0.5909, -1.3457],\n",
      "        [-1.3694, -0.4253]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 6, Loss: 0.7249903082847595\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9622,  0.5392],\n",
      "        [ 0.0837,  0.2482],\n",
      "        [-0.9932, -1.4669],\n",
      "        [-1.0006, -0.0747]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 7, Loss: 0.6437238454818726\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7478,  0.4729],\n",
      "        [ 0.2215,  0.5400],\n",
      "        [-0.7591, -1.1637],\n",
      "        [-1.3153, -0.6826]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 8, Loss: 0.5603741407394409\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6899,  0.3890],\n",
      "        [ 0.1910,  0.5295],\n",
      "        [-0.7969, -1.1125],\n",
      "        [-1.3467, -0.7170]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 9, Loss: 0.48677998781204224\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7981,  0.4727],\n",
      "        [-0.0547,  0.2947],\n",
      "        [-0.8912, -1.1932],\n",
      "        [-1.2729, -0.5677]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 10, Loss: 0.4192555546760559\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6445,  0.3327],\n",
      "        [ 0.1149,  0.4052],\n",
      "        [-1.0551, -1.0088],\n",
      "        [-1.2832, -0.8143]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 11, Loss: 0.3573383688926697\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6176,  0.3289],\n",
      "        [ 0.0378,  0.3100],\n",
      "        [-0.9591, -0.8436],\n",
      "        [-1.4335, -0.9839]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 12, Loss: 0.29342299699783325\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4541, -0.0504],\n",
      "        [ 0.2046,  0.5166],\n",
      "        [-1.1216, -0.9377],\n",
      "        [-1.4327, -0.8323]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 13, Loss: 0.25004470348358154\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4300,  0.1835],\n",
      "        [ 0.1372,  0.2448],\n",
      "        [-1.0403, -0.9901],\n",
      "        [-1.5803, -0.8677]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 14, Loss: 0.19657494127750397\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6502,  0.3622],\n",
      "        [-0.2001, -0.0816],\n",
      "        [-1.2160, -0.9208],\n",
      "        [-1.4444, -0.9241]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 15, Loss: 0.15553215146064758\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5131,  0.2486],\n",
      "        [-0.2227, -0.0534],\n",
      "        [-0.8550, -0.8989],\n",
      "        [-1.8006, -1.0027]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 16, Loss: 0.11259675770998001\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5941,  0.0904],\n",
      "        [-0.2938,  0.0205],\n",
      "        [-1.1389, -0.9593],\n",
      "        [-1.6787, -1.0056]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 17, Loss: 0.08772630989551544\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4252,  0.1394],\n",
      "        [-0.1169, -0.1782],\n",
      "        [-1.1645, -1.1216],\n",
      "        [-1.8093, -0.8451]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 18, Loss: 0.07082309573888779\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5413, -0.0247],\n",
      "        [-0.5213, -0.1028],\n",
      "        [-0.9025, -1.1739],\n",
      "        [-1.9253, -0.8575]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 19, Loss: 0.0522439070045948\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4473, -0.0952],\n",
      "        [-0.5468, -0.1100],\n",
      "        [-0.7919, -1.0369],\n",
      "        [-2.0511, -1.0694]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 20, Loss: 0.04687362164258957\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3396, -0.0965],\n",
      "        [-0.3056, -0.2455],\n",
      "        [-1.0329, -0.8977],\n",
      "        [-2.0686, -1.2207]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 21, Loss: 0.043752655386924744\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5153, -0.1240],\n",
      "        [-0.6446, -0.3110],\n",
      "        [-1.0748, -1.2118],\n",
      "        [-1.9765, -0.9550]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 22, Loss: 0.04099411889910698\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2040, -0.2049],\n",
      "        [-0.3125, -0.2986],\n",
      "        [-0.9837, -1.1373],\n",
      "        [-2.1877, -1.0909]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 23, Loss: 0.04682818800210953\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3782, -0.1064],\n",
      "        [-0.4072, -0.5436],\n",
      "        [-1.4124, -1.1517],\n",
      "        [-1.9223, -1.0435]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 24, Loss: 0.05212186276912689\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3361, -0.2341],\n",
      "        [-0.5309, -0.4457],\n",
      "        [-1.1552, -1.1126],\n",
      "        [-2.0806, -1.1462]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 25, Loss: 0.04697471484541893\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3491, -0.2012],\n",
      "        [-0.6736, -0.5807],\n",
      "        [-1.0690, -1.0983],\n",
      "        [-2.0868, -1.1286]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 26, Loss: 0.051423635333776474\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4284, -0.2387],\n",
      "        [-0.8401, -0.6050],\n",
      "        [-1.1334, -1.1721],\n",
      "        [-1.9679, -1.0395]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 27, Loss: 0.05574458837509155\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2347, -0.3239],\n",
      "        [-0.5584, -0.5276],\n",
      "        [-1.1149, -1.1351],\n",
      "        [-2.0909, -1.0916]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 28, Loss: 0.0453505665063858\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3218, -0.3392],\n",
      "        [-0.6069, -0.5493],\n",
      "        [-1.3513, -1.0677],\n",
      "        [-1.8946, -1.1237]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 29, Loss: 0.045853838324546814\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2703, -0.4061],\n",
      "        [-0.5795, -0.4980],\n",
      "        [-1.2826, -1.1361],\n",
      "        [-1.9273, -1.0226]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 30, Loss: 0.03829066455364227\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2775, -0.3360],\n",
      "        [-0.7264, -0.6082],\n",
      "        [-1.0829, -1.0209],\n",
      "        [-1.9639, -1.0653]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 31, Loss: 0.03755871206521988\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.1689, -0.3710],\n",
      "        [-0.5874, -0.6116],\n",
      "        [-1.0306, -1.1402],\n",
      "        [-2.0134, -0.8635]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 32, Loss: 0.03023996204137802\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.1353, -0.4424],\n",
      "        [-0.3771, -0.4866],\n",
      "        [-1.3375, -1.0588],\n",
      "        [-1.8423, -0.9456]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 33, Loss: 0.03063330613076687\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.0466, -0.5490],\n",
      "        [-0.4452, -0.4044],\n",
      "        [-0.9540, -1.0708],\n",
      "        [-2.0220, -0.8510]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 34, Loss: 0.026869045570492744\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2443, -0.4491],\n",
      "        [-0.6100, -0.4630],\n",
      "        [-1.1204, -0.9750],\n",
      "        [-1.8370, -0.9276]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 35, Loss: 0.02052856981754303\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[-0.0148, -0.4501],\n",
      "        [-0.3642, -0.4605],\n",
      "        [-0.8849, -0.8490],\n",
      "        [-2.0050, -0.9944]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 36, Loss: 0.029995262622833252\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.1172, -0.4392],\n",
      "        [-0.5473, -0.4582],\n",
      "        [-0.8288, -0.9704],\n",
      "        [-1.9546, -0.8279]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 37, Loss: 0.023000232875347137\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3371, -0.3857],\n",
      "        [-0.6940, -0.4913],\n",
      "        [-1.0830, -0.8766],\n",
      "        [-1.7182, -0.8877]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 38, Loss: 0.020937461405992508\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.0829, -0.4336],\n",
      "        [-0.3872, -0.4216],\n",
      "        [-0.8700, -0.8612],\n",
      "        [-1.9296, -0.8760]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 39, Loss: 0.021524349227547646\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3630, -0.4157],\n",
      "        [-0.5999, -0.4238],\n",
      "        [-1.1658, -0.8594],\n",
      "        [-1.6495, -0.8508]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 40, Loss: 0.018379101529717445\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4181, -0.3212],\n",
      "        [-0.6171, -0.5323],\n",
      "        [-1.2682, -0.8625],\n",
      "        [-1.5365, -0.7978]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 41, Loss: 0.025794124230742455\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3932, -0.4073],\n",
      "        [-0.5297, -0.4054],\n",
      "        [-1.2179, -0.8097],\n",
      "        [-1.6050, -0.8625]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 42, Loss: 0.0181024968624115\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3946, -0.4351],\n",
      "        [-0.5146, -0.3678],\n",
      "        [-1.1324, -0.8531],\n",
      "        [-1.6672, -0.8067]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 43, Loss: 0.014019646681845188\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3443, -0.3634],\n",
      "        [-0.3295, -0.4278],\n",
      "        [-1.6195, -0.8500],\n",
      "        [-1.2805, -0.8053]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 44, Loss: 0.049795594066381454\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2888, -0.3746],\n",
      "        [-0.4027, -0.4039],\n",
      "        [-0.8733, -0.8389],\n",
      "        [-1.8688, -0.8183]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 45, Loss: 0.013120253570377827\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2980, -0.3739],\n",
      "        [-0.2291, -0.3947],\n",
      "        [-1.1519, -0.8250],\n",
      "        [-1.7496, -0.8354]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 46, Loss: 0.013657936826348305\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3843, -0.4367],\n",
      "        [-0.3665, -0.3415],\n",
      "        [-1.0427, -0.7462],\n",
      "        [-1.7898, -0.9010]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 47, Loss: 0.010867719538509846\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4563, -0.4526],\n",
      "        [-0.3735, -0.3184],\n",
      "        [-1.1962, -0.8917],\n",
      "        [-1.6888, -0.7612]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 48, Loss: 0.011376962997019291\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3903, -0.4319],\n",
      "        [-0.2985, -0.3184],\n",
      "        [-1.0611, -0.8271],\n",
      "        [-1.8256, -0.8460]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 49, Loss: 0.009126449003815651\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3623, -0.3919],\n",
      "        [-0.2400, -0.3477],\n",
      "        [-1.0437, -0.8847],\n",
      "        [-1.8711, -0.7989]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 50, Loss: 0.009208879433572292\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2582, -0.4114],\n",
      "        [-0.1014, -0.3358],\n",
      "        [-1.0100, -0.9317],\n",
      "        [-1.9410, -0.7437]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 51, Loss: 0.013609037734568119\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4074, -0.4791],\n",
      "        [-0.3124, -0.2667],\n",
      "        [-0.9653, -0.8118],\n",
      "        [-1.9267, -0.8641]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 52, Loss: 0.008388171903789043\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5721, -0.3061],\n",
      "        [-0.4297, -0.4201],\n",
      "        [-1.2405, -0.8904],\n",
      "        [-1.7032, -0.8039]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 53, Loss: 0.013002851977944374\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4107, -0.3527],\n",
      "        [-0.3343, -0.3651],\n",
      "        [-0.9139, -0.9090],\n",
      "        [-1.9695, -0.7919]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 54, Loss: 0.008117690682411194\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5147, -0.2189],\n",
      "        [-0.3806, -0.5417],\n",
      "        [-1.0990, -0.8375],\n",
      "        [-1.8491, -0.8185]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 55, Loss: 0.010826925747096539\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4940, -0.4576],\n",
      "        [-0.2942, -0.2629],\n",
      "        [-1.2092, -0.8365],\n",
      "        [-1.8125, -0.8571]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 56, Loss: 0.007946431636810303\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4018, -0.4622],\n",
      "        [-0.1714, -0.2566],\n",
      "        [-1.1834, -0.8267],\n",
      "        [-1.8777, -0.8661]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 57, Loss: 0.00945364311337471\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5200, -0.4535],\n",
      "        [-0.4242, -0.2669],\n",
      "        [-1.0244, -0.9168],\n",
      "        [-1.9113, -0.7718]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 58, Loss: 0.004563516937196255\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4593, -0.6054],\n",
      "        [-0.2162, -0.1955],\n",
      "        [-1.2754, -0.9024],\n",
      "        [-1.8171, -0.7032]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 59, Loss: 0.01011985819786787\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4167, -0.3646],\n",
      "        [-0.2421, -0.3208],\n",
      "        [-1.0795, -0.8822],\n",
      "        [-1.9543, -0.8367]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 60, Loss: 0.006170621141791344\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4006, -0.5140],\n",
      "        [-0.2125, -0.2700],\n",
      "        [-1.1015, -0.9944],\n",
      "        [-1.9555, -0.6239]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 61, Loss: 0.006500574294477701\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3625, -0.3004],\n",
      "        [-0.2950, -0.3778],\n",
      "        [-0.8778, -0.8756],\n",
      "        [-2.0682, -0.8466]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 62, Loss: 0.009568819776177406\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6426, -0.2226],\n",
      "        [-0.5652, -0.5244],\n",
      "        [-1.2032, -0.9463],\n",
      "        [-1.7621, -0.7056]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 63, Loss: 0.014711612835526466\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5544, -0.4447],\n",
      "        [-0.3918, -0.2481],\n",
      "        [-1.2496, -0.7954],\n",
      "        [-1.8099, -0.9093]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 64, Loss: 0.00760483555495739\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5104, -0.3767],\n",
      "        [-0.4371, -0.3427],\n",
      "        [-1.0314, -1.0036],\n",
      "        [-1.9473, -0.6732]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 65, Loss: 0.00399289233610034\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4207, -0.4031],\n",
      "        [-0.3314, -0.3703],\n",
      "        [-0.9920, -1.0418],\n",
      "        [-2.0106, -0.5799]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 66, Loss: 0.005189176183193922\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5073, -0.5241],\n",
      "        [-0.3972, -0.2052],\n",
      "        [-1.1222, -0.9332],\n",
      "        [-1.9085, -0.7316]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 67, Loss: 0.003326370380818844\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3607, -0.7429],\n",
      "        [-0.3255, -0.2261],\n",
      "        [-0.8923, -0.9443],\n",
      "        [-2.0702, -0.4797]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 68, Loss: 0.010887423530220985\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4098, -0.3658],\n",
      "        [-0.3475, -0.3030],\n",
      "        [-0.9774, -0.9510],\n",
      "        [-2.0184, -0.7720]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 69, Loss: 0.0043587046675384045\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5126, -0.5360],\n",
      "        [-0.4336, -0.1794],\n",
      "        [-1.1150, -0.7882],\n",
      "        [-1.9028, -0.8867]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 70, Loss: 0.00477727223187685\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4032, -0.3819],\n",
      "        [-0.2542, -0.3083],\n",
      "        [-1.1585, -0.9983],\n",
      "        [-1.9339, -0.6998]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 71, Loss: 0.005129379220306873\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4553, -0.3815],\n",
      "        [-0.3955, -0.2726],\n",
      "        [-1.0472, -0.9275],\n",
      "        [-1.9599, -0.8041]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 72, Loss: 0.003265111008659005\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4003, -0.3216],\n",
      "        [-0.4406, -0.3198],\n",
      "        [-0.8623, -0.9157],\n",
      "        [-2.0480, -0.8254]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 73, Loss: 0.007447449956089258\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5639, -0.3437],\n",
      "        [-0.5316, -0.2926],\n",
      "        [-1.1591, -0.8389],\n",
      "        [-1.8265, -0.9033]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 74, Loss: 0.007273017428815365\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5324, -0.4932],\n",
      "        [-0.5200, -0.2015],\n",
      "        [-1.0909, -0.9549],\n",
      "        [-1.8768, -0.7245]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 75, Loss: 0.0035473175812512636\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5090, -0.3879],\n",
      "        [-0.3924, -0.3260],\n",
      "        [-1.2959, -1.0407],\n",
      "        [-1.7776, -0.6147]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 76, Loss: 0.0087360218167305\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5151, -0.6537],\n",
      "        [-0.5190, -0.2023],\n",
      "        [-1.0650, -0.9868],\n",
      "        [-1.8891, -0.5214]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 77, Loss: 0.005321928765624762\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3951, -0.4333],\n",
      "        [-0.3995, -0.2878],\n",
      "        [-0.9549, -1.0403],\n",
      "        [-1.9994, -0.5977]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 78, Loss: 0.003831558395177126\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4491, -0.3912],\n",
      "        [-0.5053, -0.2465],\n",
      "        [-0.9297, -0.9574],\n",
      "        [-1.9728, -0.7588]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 79, Loss: 0.004039491061121225\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4805, -0.5236],\n",
      "        [-0.4764, -0.1478],\n",
      "        [-1.0601, -0.8447],\n",
      "        [-1.9027, -0.8327]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 80, Loss: 0.003417405765503645\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3314, -0.3788],\n",
      "        [-0.3188, -0.2322],\n",
      "        [-0.9530, -0.8418],\n",
      "        [-2.0178, -0.8908]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 81, Loss: 0.0066537512466311455\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3002, -0.3863],\n",
      "        [-0.1952, -0.2724],\n",
      "        [-1.1054, -1.0154],\n",
      "        [-1.9571, -0.6644]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 82, Loss: 0.006564727518707514\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3289, -0.5495],\n",
      "        [-0.3530, -0.1798],\n",
      "        [-0.9019, -0.9907],\n",
      "        [-2.0308, -0.6137]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 83, Loss: 0.005525901447981596\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4363, -0.5212],\n",
      "        [-0.4499, -0.1369],\n",
      "        [-1.0019, -0.8721],\n",
      "        [-1.9404, -0.7991]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 84, Loss: 0.003018842777237296\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5105, -0.4775],\n",
      "        [-0.5266, -0.1565],\n",
      "        [-1.0825, -0.8932],\n",
      "        [-1.8560, -0.7980]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 85, Loss: 0.0033746655099093914\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3822, -0.4240],\n",
      "        [-0.4858, -0.2243],\n",
      "        [-0.8307, -1.0031],\n",
      "        [-2.0190, -0.6700]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 86, Loss: 0.005664969328790903\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.1598, -0.3337],\n",
      "        [-0.1921, -0.2487],\n",
      "        [-0.8202, -0.8183],\n",
      "        [-2.0997, -0.9173]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 87, Loss: 0.01778390444815159\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3483, -0.3761],\n",
      "        [-0.4549, -0.2084],\n",
      "        [-0.8045, -0.8876],\n",
      "        [-2.0397, -0.8427]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 88, Loss: 0.00825098529458046\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3673, -0.4359],\n",
      "        [-0.3082, -0.1758],\n",
      "        [-1.0729, -0.9380],\n",
      "        [-1.9358, -0.7626]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 89, Loss: 0.00311631360091269\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5920, -0.2397],\n",
      "        [-0.6449, -0.3289],\n",
      "        [-1.1615, -0.8735],\n",
      "        [-1.7339, -0.8680]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 90, Loss: 0.012046425603330135\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4759, -0.4057],\n",
      "        [-0.4481, -0.1811],\n",
      "        [-1.1250, -0.8939],\n",
      "        [-1.8498, -0.8278]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 91, Loss: 0.00295123178511858\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5916, -0.4681],\n",
      "        [-0.6218, -0.2400],\n",
      "        [-1.2107, -1.0511],\n",
      "        [-1.7050, -0.5486]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 92, Loss: 0.011224531568586826\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5557, -0.3812],\n",
      "        [-0.5445, -0.2120],\n",
      "        [-1.2224, -0.9664],\n",
      "        [-1.7336, -0.7480]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 93, Loss: 0.007172476500272751\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4172, -0.2454],\n",
      "        [-0.2744, -0.3656],\n",
      "        [-1.3331, -1.0093],\n",
      "        [-1.7534, -0.6879]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 94, Loss: 0.011382733471691608\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4246, -0.3297],\n",
      "        [-0.4322, -0.2492],\n",
      "        [-1.0082, -0.9643],\n",
      "        [-1.9269, -0.7663]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 95, Loss: 0.002334670163691044\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2504, -0.4970],\n",
      "        [-0.3584, -0.1332],\n",
      "        [-0.7508, -0.9212],\n",
      "        [-2.0831, -0.7601]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 96, Loss: 0.011537213809788227\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3951, -0.3254],\n",
      "        [-0.4451, -0.2588],\n",
      "        [-0.9173, -0.9798],\n",
      "        [-1.9738, -0.7500]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 97, Loss: 0.0034462411422282457\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4248, -0.5294],\n",
      "        [-0.4886, -0.1488],\n",
      "        [-0.9217, -0.9857],\n",
      "        [-1.9549, -0.6528]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 98, Loss: 0.0031786381732672453\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5105, -0.6483],\n",
      "        [-0.4881, -0.0714],\n",
      "        [-1.1604, -0.7888],\n",
      "        [-1.8018, -0.8113]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 99, Loss: 0.006028539966791868\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3087, -0.4968],\n",
      "        [-0.3891, -0.1266],\n",
      "        [-0.8122, -0.8945],\n",
      "        [-2.0468, -0.8051]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 100, Loss: 0.007909338921308517\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6049, -0.3113],\n",
      "        [-0.6467, -0.2556],\n",
      "        [-1.2059, -0.9379],\n",
      "        [-1.6914, -0.8211]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 101, Loss: 0.011273836717009544\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3699, -0.2645],\n",
      "        [-0.3580, -0.3023],\n",
      "        [-0.9846, -0.8184],\n",
      "        [-1.9661, -0.9421]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 102, Loss: 0.006162018980830908\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4485, -0.5012],\n",
      "        [-0.4506, -0.1862],\n",
      "        [-1.0298, -1.0302],\n",
      "        [-1.9070, -0.6108]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 103, Loss: 0.002045219298452139\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.1180, -0.3810],\n",
      "        [-0.0033, -0.2066],\n",
      "        [-1.0642, -0.9635],\n",
      "        [-1.9892, -0.7782]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 104, Loss: 0.01806316338479519\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4822, -0.4352],\n",
      "        [-0.5052, -0.1785],\n",
      "        [-1.0302, -0.9782],\n",
      "        [-1.8854, -0.7383]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 105, Loss: 0.0018220257479697466\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4889, -0.3877],\n",
      "        [-0.5074, -0.1906],\n",
      "        [-1.0449, -0.9094],\n",
      "        [-1.8753, -0.8431]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 106, Loss: 0.002551156096160412\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5092, -0.4933],\n",
      "        [-0.4818, -0.1911],\n",
      "        [-1.1539, -1.0351],\n",
      "        [-1.8120, -0.6118]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 107, Loss: 0.003864104626700282\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5511, -0.2020],\n",
      "        [-0.5753, -0.4294],\n",
      "        [-1.1201, -1.0176],\n",
      "        [-1.7942, -0.6827]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 108, Loss: 0.009226636961102486\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5063, -0.6720],\n",
      "        [-0.5029, -0.0777],\n",
      "        [-1.1010, -0.8853],\n",
      "        [-1.8410, -0.6970]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 109, Loss: 0.004572671838104725\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5213, -0.3835],\n",
      "        [-0.5998, -0.1954],\n",
      "        [-0.9873, -0.9271],\n",
      "        [-1.8728, -0.8261]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 110, Loss: 0.0041921064257621765\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4191, -0.4328],\n",
      "        [-0.5297, -0.1665],\n",
      "        [-0.8389, -0.9407],\n",
      "        [-1.9892, -0.7921]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 111, Loss: 0.004996320232748985\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4130, -0.5042],\n",
      "        [-0.4430, -0.1371],\n",
      "        [-0.9432, -0.9584],\n",
      "        [-1.9655, -0.7324]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 112, Loss: 0.0023247567005455494\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2896, -0.8035],\n",
      "        [-0.2132, -0.0904],\n",
      "        [-1.0340, -0.8618],\n",
      "        [-1.9810, -0.5763]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 113, Loss: 0.012459518387913704\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5350, -0.4155],\n",
      "        [-0.6217, -0.1767],\n",
      "        [-0.9859, -0.9441],\n",
      "        [-1.8660, -0.7956]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 114, Loss: 0.004405391868203878\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4340, -0.5332],\n",
      "        [-0.3749, -0.1317],\n",
      "        [-1.1064, -0.9698],\n",
      "        [-1.8914, -0.6970]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 115, Loss: 0.0020577553659677505\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3963, -0.3919],\n",
      "        [-0.4640, -0.2367],\n",
      "        [-0.8694, -1.0362],\n",
      "        [-2.0016, -0.6665]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 116, Loss: 0.0037443512119352818\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4025, -0.3844],\n",
      "        [-0.4875, -0.1902],\n",
      "        [-0.8492, -0.9029],\n",
      "        [-2.0044, -0.8535]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 117, Loss: 0.005312907509505749\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5694, -0.3627],\n",
      "        [-0.6065, -0.2337],\n",
      "        [-1.1040, -1.0045],\n",
      "        [-1.7975, -0.7296]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 118, Loss: 0.005480365362018347\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4459, -0.3549],\n",
      "        [-0.5768, -0.2304],\n",
      "        [-0.8244, -0.9878],\n",
      "        [-1.9832, -0.7567]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 119, Loss: 0.005926694255322218\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4615, -0.2516],\n",
      "        [-0.3926, -0.3222],\n",
      "        [-1.1452, -0.9772],\n",
      "        [-1.8621, -0.7782]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 120, Loss: 0.0038313281256705523\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4507, -0.3644],\n",
      "        [-0.4061, -0.2073],\n",
      "        [-1.0850, -0.9440],\n",
      "        [-1.8979, -0.8125]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 121, Loss: 0.0017115978989750147\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3824, -0.4261],\n",
      "        [-0.3226, -0.1604],\n",
      "        [-1.0491, -0.9153],\n",
      "        [-1.9488, -0.8257]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 122, Loss: 0.0025768373161554337\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5283, -0.3667],\n",
      "        [-0.5016, -0.2020],\n",
      "        [-1.1471, -0.9331],\n",
      "        [-1.8175, -0.8249]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 123, Loss: 0.0034600833896547556\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5431, -0.3358],\n",
      "        [-0.4588, -0.2508],\n",
      "        [-1.3127, -1.0070],\n",
      "        [-1.7093, -0.7323]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 124, Loss: 0.009139956906437874\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3759, -0.4195],\n",
      "        [-0.3543, -0.1889],\n",
      "        [-0.9772, -1.0001],\n",
      "        [-1.9819, -0.7169]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 125, Loss: 0.002114288043230772\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3590, -0.3487],\n",
      "        [-0.2412, -0.2395],\n",
      "        [-1.1429, -1.0075],\n",
      "        [-1.9120, -0.7293]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 126, Loss: 0.004254049155861139\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2845, -0.3468],\n",
      "        [-0.2830, -0.2409],\n",
      "        [-0.8902, -1.0083],\n",
      "        [-2.0482, -0.7287]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 127, Loss: 0.006140552926808596\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3836, -0.5772],\n",
      "        [-0.2190, -0.1478],\n",
      "        [-1.2832, -1.0144],\n",
      "        [-1.8181, -0.5854]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 128, Loss: 0.009715181775391102\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3841, -0.4173],\n",
      "        [-0.3149, -0.2080],\n",
      "        [-1.0652, -1.0304],\n",
      "        [-1.9402, -0.6693]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 129, Loss: 0.00221427995711565\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2586, -0.5750],\n",
      "        [-0.2598, -0.1046],\n",
      "        [-0.8741, -0.9492],\n",
      "        [-2.0607, -0.6965]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 130, Loss: 0.009006038308143616\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4584, -0.3085],\n",
      "        [-0.3308, -0.2690],\n",
      "        [-1.2745, -1.0019],\n",
      "        [-1.7887, -0.7461]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 131, Loss: 0.0063395025208592415\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5284, -0.4702],\n",
      "        [-0.4916, -0.1465],\n",
      "        [-1.1663, -0.9666],\n",
      "        [-1.8057, -0.7428]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 132, Loss: 0.003172774100676179\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2377, -0.3977],\n",
      "        [-0.2853, -0.1942],\n",
      "        [-0.7980, -0.9874],\n",
      "        [-2.0894, -0.7472]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 133, Loss: 0.009819328784942627\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5131, -0.2336],\n",
      "        [-0.5160, -0.3429],\n",
      "        [-1.0718, -0.9890],\n",
      "        [-1.8600, -0.7613]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 134, Loss: 0.004565163515508175\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.2416, -0.3681],\n",
      "        [-0.2240, -0.2238],\n",
      "        [-0.8973, -1.0078],\n",
      "        [-2.0547, -0.7271]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 135, Loss: 0.007984817028045654\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4317, -0.5109],\n",
      "        [-0.4243, -0.1130],\n",
      "        [-1.0021, -0.9082],\n",
      "        [-1.9396, -0.7948]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 136, Loss: 0.0018377491505816579\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4348, -0.5510],\n",
      "        [-0.4515, -0.1201],\n",
      "        [-0.9676, -0.9724],\n",
      "        [-1.9498, -0.6833]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 137, Loss: 0.0019924717489629984\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4595, -0.2813],\n",
      "        [-0.4965, -0.2748],\n",
      "        [-0.9607, -0.9512],\n",
      "        [-1.9364, -0.8192]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 138, Loss: 0.003246320877224207\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.4921, -0.4044],\n",
      "        [-0.4219, -0.1929],\n",
      "        [-1.1886, -0.9973],\n",
      "        [-1.8157, -0.7315]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 139, Loss: 0.0029228997882455587\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.3903, -0.3104],\n",
      "        [-0.4509, -0.2645],\n",
      "        [-0.8687, -1.0009],\n",
      "        [-2.0047, -0.7496]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 140, Loss: 0.004052889067679644\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5263, -0.4113],\n",
      "        [-0.5640, -0.1697],\n",
      "        [-1.0363, -0.9478],\n",
      "        [-1.8601, -0.7960]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 141, Loss: 0.0027126746717840433\n",
      "Early stopping triggered.\n",
      "Size of input data: torch.Size([38, 2])\n",
      "Size of embeddings: torch.Size([38, 2])\n",
      "Embeddings: tensor([[-2.5065,  0.5241],\n",
      "        [-2.3776, -0.0178],\n",
      "        [-1.4402, -0.7783],\n",
      "        [-1.1659, -0.8873],\n",
      "        [-0.3283,  0.6076],\n",
      "        [-0.0130, -2.4220],\n",
      "        [ 0.6785,  0.5232],\n",
      "        [-0.0524,  0.7617],\n",
      "        [-2.3151,  2.2548],\n",
      "        [ 0.9194, -0.2440],\n",
      "        [-1.7234, -0.4779],\n",
      "        [-0.8120,  0.5724],\n",
      "        [-0.0789, -1.8528],\n",
      "        [-0.0895, -0.5226],\n",
      "        [ 0.4350,  0.9596],\n",
      "        [-1.2314,  0.0710],\n",
      "        [ 0.6975,  0.7601],\n",
      "        [ 0.0884,  1.0824],\n",
      "        [ 0.6374,  1.2164],\n",
      "        [ 0.4785, -0.3333],\n",
      "        [ 0.3504,  0.6580],\n",
      "        [-0.2388, -0.6768],\n",
      "        [ 0.7469,  1.0987],\n",
      "        [-0.1220, -1.6702],\n",
      "        [ 0.5085, -1.1469],\n",
      "        [ 0.9393, -0.4401],\n",
      "        [ 0.8868,  0.5302],\n",
      "        [ 0.5534,  0.0307],\n",
      "        [ 0.8871,  1.5631],\n",
      "        [ 1.1977, -0.5878],\n",
      "        [ 1.1633,  0.9565],\n",
      "        [-0.1162,  0.0872],\n",
      "        [ 0.8947, -0.9554],\n",
      "        [ 0.8363, -0.1504],\n",
      "        [ 0.2811,  0.0631],\n",
      "        [-0.1220, -1.6702],\n",
      "        [ 0.7682,  1.0679],\n",
      "        [ 0.7845, -0.5549]], device='cuda:0')\n",
      "Action space size: 170\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 1/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -4.12\n",
      "Size of input data: torch.Size([56, 2])\n",
      "Size of embeddings: torch.Size([56, 2])\n",
      "Embeddings: tensor([[-2.9396,  0.5534],\n",
      "        [-2.0995,  0.6304],\n",
      "        [-2.9223,  0.3654],\n",
      "        [-1.8388,  0.6419],\n",
      "        [-0.2381,  0.3653],\n",
      "        [ 0.3145, -0.6042],\n",
      "        [-0.3581,  0.4383],\n",
      "        [-0.2943,  1.0265],\n",
      "        [ 0.4197,  1.4129],\n",
      "        [ 0.2803, -0.9710],\n",
      "        [-0.2069, -0.7265],\n",
      "        [-0.7243,  1.3568],\n",
      "        [-0.5984, -2.1371],\n",
      "        [ 0.7734,  0.3312],\n",
      "        [ 0.4396,  0.3527],\n",
      "        [-0.0972, -1.2823],\n",
      "        [ 0.1005,  0.6676],\n",
      "        [ 1.3901,  0.0807],\n",
      "        [-1.6725,  1.5581],\n",
      "        [-0.5923, -0.5309],\n",
      "        [ 0.8250,  0.7672],\n",
      "        [-0.4331, -0.5975],\n",
      "        [ 0.0952,  0.2082],\n",
      "        [-0.3406, -2.2382],\n",
      "        [ 0.6241,  0.0449],\n",
      "        [ 0.1356, -0.3717],\n",
      "        [ 0.3391,  0.7585],\n",
      "        [-0.2478, -0.0955],\n",
      "        [ 0.6748,  0.1378],\n",
      "        [ 0.1687, -0.2943],\n",
      "        [ 0.8832,  0.4941],\n",
      "        [-0.3783,  0.7256],\n",
      "        [ 0.2983, -2.7706],\n",
      "        [-0.6457, -1.4767],\n",
      "        [ 0.5192, -0.0100],\n",
      "        [-0.3406, -2.2382],\n",
      "        [-0.4799,  0.8632],\n",
      "        [ 1.1518, -0.0358],\n",
      "        [-0.3148,  0.1138],\n",
      "        [-0.8542,  1.4578],\n",
      "        [ 1.1060, -0.6842],\n",
      "        [-0.6250,  1.8755],\n",
      "        [ 1.1931, -0.1002],\n",
      "        [-0.5998,  0.1531],\n",
      "        [ 0.2133,  1.4055],\n",
      "        [ 1.7910, -0.1090],\n",
      "        [-0.1746, -1.3742],\n",
      "        [-0.2048,  0.2157],\n",
      "        [ 1.8153, -0.1752],\n",
      "        [ 0.0383,  0.7424],\n",
      "        [ 0.2181,  1.1286],\n",
      "        [ 1.1456,  0.2897],\n",
      "        [ 1.1619, -0.5656],\n",
      "        [ 0.1136,  0.2523],\n",
      "        [-0.1432, -1.4699],\n",
      "        [ 2.1352, -0.5565]], device='cuda:0')\n",
      "Action space size: 260\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 2/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -3.708\n",
      "Size of input data: torch.Size([67, 2])\n",
      "Size of embeddings: torch.Size([67, 2])\n",
      "Embeddings: tensor([[-1.1990,  1.8963],\n",
      "        [-0.6743,  1.8698],\n",
      "        [-2.4878,  0.7259],\n",
      "        [-1.4538,  1.5107],\n",
      "        [ 1.0544,  1.4722],\n",
      "        [ 1.6485, -1.5833],\n",
      "        [-1.2116,  0.6560],\n",
      "        [ 0.5026,  1.1265],\n",
      "        [-0.6509,  0.5193],\n",
      "        [ 0.5300, -1.6473],\n",
      "        [-0.1746, -1.8353],\n",
      "        [ 0.3571,  0.8595],\n",
      "        [-0.1296, -1.7772],\n",
      "        [ 1.4911, -0.1648],\n",
      "        [ 0.5815,  0.0634],\n",
      "        [-0.3386, -0.3943],\n",
      "        [-0.8782,  1.2541],\n",
      "        [ 1.4551,  0.2877],\n",
      "        [-2.2844,  2.0409],\n",
      "        [-1.4854,  0.9299],\n",
      "        [ 0.7022,  0.3883],\n",
      "        [ 0.9612, -0.1130],\n",
      "        [-0.3527,  0.6560],\n",
      "        [-0.2387, -1.5864],\n",
      "        [-0.8956, -1.2269],\n",
      "        [-0.9813, -0.5925],\n",
      "        [-0.9432,  0.2762],\n",
      "        [-1.9777,  0.2075],\n",
      "        [-0.0187,  0.3784],\n",
      "        [-0.4309, -0.5833],\n",
      "        [ 0.3058,  0.1846],\n",
      "        [-0.5320,  0.7004],\n",
      "        [ 1.2988, -0.2775],\n",
      "        [-0.3098, -1.2667],\n",
      "        [ 0.8358, -0.9611],\n",
      "        [-0.2387, -1.5864],\n",
      "        [-0.4197,  1.6113],\n",
      "        [ 0.0821, -1.4636],\n",
      "        [-1.0318,  0.9521],\n",
      "        [-0.1464,  0.2525],\n",
      "        [ 1.1730, -0.0209],\n",
      "        [-2.2808,  1.9358],\n",
      "        [ 0.9604, -0.8683],\n",
      "        [-0.3721,  0.0718],\n",
      "        [ 0.1323,  0.7699],\n",
      "        [ 1.0997,  0.4316],\n",
      "        [ 0.3942, -0.1661],\n",
      "        [-0.5930,  0.1986],\n",
      "        [ 1.8128, -0.6571],\n",
      "        [-0.2998,  0.4391],\n",
      "        [-0.0818,  0.4506],\n",
      "        [-0.6241, -1.8642],\n",
      "        [ 1.6203, -0.9397],\n",
      "        [-0.2748, -1.1607],\n",
      "        [ 0.3924,  0.0986],\n",
      "        [ 2.1635, -0.5334],\n",
      "        [ 0.8015,  0.1320],\n",
      "        [ 0.8933, -0.9101],\n",
      "        [-0.0955, -0.1151],\n",
      "        [-0.2573,  0.1973],\n",
      "        [ 0.3576, -0.6817],\n",
      "        [ 0.9638,  0.6306],\n",
      "        [ 0.0163, -0.0797],\n",
      "        [ 0.1805,  0.3454],\n",
      "        [ 0.9004,  0.0866],\n",
      "        [ 0.8503,  0.0588],\n",
      "        [-0.1544, -1.6098]], device='cuda:0')\n",
      "Action space size: 315\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 3/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -3.3372\n",
      "Size of input data: torch.Size([85, 2])\n",
      "Size of embeddings: torch.Size([85, 2])\n",
      "Embeddings: tensor([[-2.6925,  1.6045],\n",
      "        [-2.4289,  1.6323],\n",
      "        [-2.8835,  2.0077],\n",
      "        [-2.3316,  1.5103],\n",
      "        [ 0.8111,  0.0893],\n",
      "        [-0.2847, -2.2424],\n",
      "        [-0.1839,  0.8224],\n",
      "        [ 0.7229,  0.8784],\n",
      "        [-0.1599,  0.5174],\n",
      "        [-0.5378, -0.9125],\n",
      "        [ 0.0510, -0.9144],\n",
      "        [-0.4484,  0.7495],\n",
      "        [-1.2959, -0.6307],\n",
      "        [ 0.6027, -1.2100],\n",
      "        [ 0.6937,  0.1042],\n",
      "        [-1.2426, -0.8767],\n",
      "        [ 0.6407,  1.0653],\n",
      "        [ 0.5565, -0.5190],\n",
      "        [-1.3527,  2.7697],\n",
      "        [-1.1684,  1.1187],\n",
      "        [ 1.0322, -0.0460],\n",
      "        [-0.3553, -0.9869],\n",
      "        [ 0.6713,  0.5688],\n",
      "        [-1.5658, -0.3207],\n",
      "        [-0.2577, -0.0731],\n",
      "        [ 0.8678, -0.0147],\n",
      "        [ 0.1279,  0.7923],\n",
      "        [-1.9395,  0.9092],\n",
      "        [ 0.4262,  0.9837],\n",
      "        [-0.1517, -0.0563],\n",
      "        [ 0.2989,  0.2118],\n",
      "        [-0.4805,  0.9763],\n",
      "        [-0.8154, -1.6856],\n",
      "        [-1.3581, -0.7765],\n",
      "        [ 1.0082, -0.5846],\n",
      "        [-1.5658, -0.3207],\n",
      "        [ 0.2233,  1.7056],\n",
      "        [ 1.2505, -1.1129],\n",
      "        [ 0.4478,  1.1635],\n",
      "        [ 0.1652, -0.0049],\n",
      "        [ 0.5600, -0.7221],\n",
      "        [-0.3584,  2.7485],\n",
      "        [ 1.5552, -0.4790],\n",
      "        [-1.0492,  1.0513],\n",
      "        [-0.0867,  0.6576],\n",
      "        [ 0.3627, -0.9559],\n",
      "        [-1.6142, -1.0242],\n",
      "        [-0.9584, -0.4586],\n",
      "        [ 1.2056, -1.0952],\n",
      "        [ 0.4440,  0.3766],\n",
      "        [ 0.0645,  1.0523],\n",
      "        [-0.0361, -0.4281],\n",
      "        [ 1.2616, -1.4162],\n",
      "        [ 0.5878,  0.1350],\n",
      "        [-1.2543, -1.1573],\n",
      "        [ 1.0792, -1.6120],\n",
      "        [-0.4214, -1.1134],\n",
      "        [ 0.5132, -1.4330],\n",
      "        [ 0.3302,  0.6637],\n",
      "        [ 1.2694, -0.2112],\n",
      "        [ 0.9457,  0.2175],\n",
      "        [ 1.0081, -0.1884],\n",
      "        [ 0.5391,  0.4540],\n",
      "        [ 0.6823,  0.5682],\n",
      "        [-0.2745, -0.5395],\n",
      "        [ 0.3469, -0.4852],\n",
      "        [-0.2369, -0.9296],\n",
      "        [-0.1108,  1.1903],\n",
      "        [-0.0474,  0.1960],\n",
      "        [ 0.1891, -0.0309],\n",
      "        [ 0.5140, -1.4285],\n",
      "        [ 1.2779, -0.6078],\n",
      "        [ 0.5455, -0.7942],\n",
      "        [ 0.6085,  0.5909],\n",
      "        [-1.0980, -0.0711],\n",
      "        [-0.1646,  0.9350],\n",
      "        [ 1.3567, -1.2785],\n",
      "        [ 0.6109, -0.1188],\n",
      "        [-0.1561,  0.6097],\n",
      "        [ 1.4873, -0.5075],\n",
      "        [ 0.2491,  0.9557],\n",
      "        [ 0.8678,  0.0461],\n",
      "        [ 0.2019, -1.1652],\n",
      "        [ 0.4008, -0.6094],\n",
      "        [ 1.7045, -0.4800]], device='cuda:0')\n",
      "Action space size: 405\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 4/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -3.0034800000000006\n",
      "Size of input data: torch.Size([103, 2])\n",
      "Size of embeddings: torch.Size([103, 2])\n",
      "Embeddings: tensor([[-1.6788e+00,  5.5263e-01],\n",
      "        [-1.6626e+00,  4.7933e-01],\n",
      "        [-3.0578e+00,  1.5956e+00],\n",
      "        [-2.5645e+00,  9.9308e-01],\n",
      "        [ 1.3978e-01,  1.2920e+00],\n",
      "        [-2.2762e-01, -2.0936e+00],\n",
      "        [-8.6363e-01,  1.3708e+00],\n",
      "        [-6.0172e-01,  1.0641e+00],\n",
      "        [-6.2503e-02,  1.1995e-01],\n",
      "        [ 1.9208e+00, -3.7285e-01],\n",
      "        [ 2.9703e-01, -7.0908e-01],\n",
      "        [-3.3425e-01,  7.4520e-01],\n",
      "        [-1.4440e+00, -7.9532e-01],\n",
      "        [ 6.9170e-01, -4.1754e-02],\n",
      "        [-7.8776e-02, -7.1458e-01],\n",
      "        [ 8.5539e-01, -1.2159e+00],\n",
      "        [-6.1688e-01,  1.1880e+00],\n",
      "        [ 1.2409e+00, -1.2353e-02],\n",
      "        [-3.0444e+00,  2.2478e+00],\n",
      "        [-1.9469e+00,  8.1785e-01],\n",
      "        [ 1.4295e-01,  2.7771e-01],\n",
      "        [ 1.4160e+00,  9.0488e-01],\n",
      "        [-2.7812e-01, -2.0658e-01],\n",
      "        [-1.8177e+00, -1.9471e-01],\n",
      "        [-1.5955e+00,  9.6459e-01],\n",
      "        [ 2.0512e-01, -5.0450e-01],\n",
      "        [ 3.1104e-01,  1.0861e+00],\n",
      "        [-1.6950e+00,  1.8985e+00],\n",
      "        [-2.7811e-01,  3.5413e-01],\n",
      "        [-2.8178e-01,  6.5268e-01],\n",
      "        [ 5.0399e-01, -6.4914e-01],\n",
      "        [-9.7650e-01,  1.3616e+00],\n",
      "        [ 6.3938e-01, -2.2906e+00],\n",
      "        [ 3.1839e-01, -2.8656e-01],\n",
      "        [ 3.9230e-03, -1.1751e+00],\n",
      "        [-1.8177e+00, -1.9471e-01],\n",
      "        [-1.0424e+00,  7.5819e-01],\n",
      "        [-7.8282e-02, -2.2366e+00],\n",
      "        [-5.0924e-01,  6.0797e-01],\n",
      "        [ 1.0115e+00,  2.7080e-01],\n",
      "        [ 1.2945e-01, -9.1271e-02],\n",
      "        [-2.7688e+00,  2.4166e+00],\n",
      "        [-2.4318e-01, -4.3013e-01],\n",
      "        [-3.2163e-01,  3.3210e-01],\n",
      "        [-3.9039e-01,  8.8403e-01],\n",
      "        [ 1.3940e+00, -9.6416e-03],\n",
      "        [ 6.7616e-01, -1.4959e+00],\n",
      "        [ 1.5571e-01, -9.0221e-01],\n",
      "        [ 1.2207e+00, -3.5706e-01],\n",
      "        [ 8.7296e-02,  9.8708e-01],\n",
      "        [-3.3350e-01,  2.3176e+00],\n",
      "        [-1.0592e+00,  1.0778e+00],\n",
      "        [ 3.0550e-01, -1.3927e+00],\n",
      "        [ 1.6973e-01,  1.2299e-02],\n",
      "        [ 9.2140e-01, -1.1347e+00],\n",
      "        [ 1.1419e+00, -6.1085e-01],\n",
      "        [ 1.0548e+00, -1.1153e+00],\n",
      "        [-1.7090e-01, -1.3423e+00],\n",
      "        [ 1.3791e-01,  1.0262e+00],\n",
      "        [ 2.0946e-01, -7.7718e-01],\n",
      "        [ 4.7178e-01,  3.3226e-01],\n",
      "        [ 4.5244e-01, -1.0799e-01],\n",
      "        [ 9.9760e-02,  1.0748e+00],\n",
      "        [ 1.7748e-01, -7.4255e-01],\n",
      "        [ 1.3095e+00,  2.2858e-01],\n",
      "        [ 1.0982e+00, -1.9744e-01],\n",
      "        [ 2.0550e-01, -1.5500e+00],\n",
      "        [-1.6658e-01,  1.2828e+00],\n",
      "        [ 6.0936e-01,  9.2538e-01],\n",
      "        [ 9.0099e-01, -8.7177e-02],\n",
      "        [ 1.4353e+00, -4.4337e-01],\n",
      "        [ 2.8429e-01, -8.1238e-01],\n",
      "        [ 8.6393e-01, -5.3191e-01],\n",
      "        [-2.2284e-01, -1.2331e-01],\n",
      "        [ 6.1354e-01,  1.9931e-02],\n",
      "        [ 6.0689e-02,  1.7722e+00],\n",
      "        [ 1.1501e-01, -2.0199e+00],\n",
      "        [ 4.6094e-01, -3.8139e-01],\n",
      "        [-1.3251e+00, -2.0999e-02],\n",
      "        [ 3.0124e-01, -1.0142e+00],\n",
      "        [ 1.0081e-01,  1.2648e+00],\n",
      "        [ 3.7028e-01,  3.8257e-01],\n",
      "        [ 7.6429e-01, -8.6577e-01],\n",
      "        [ 1.2671e+00, -7.4717e-02],\n",
      "        [-9.2989e-01, -5.1618e-01],\n",
      "        [-6.2834e-01,  2.4049e-01],\n",
      "        [ 1.2480e+00, -1.0357e+00],\n",
      "        [ 7.3391e-01, -1.5508e+00],\n",
      "        [ 2.7846e-01, -6.2358e-01],\n",
      "        [-3.4740e-01,  1.8316e-01],\n",
      "        [ 9.1330e-01,  1.3123e-01],\n",
      "        [ 7.0644e-01,  4.7412e-01],\n",
      "        [ 3.0268e-01,  5.4277e-04],\n",
      "        [ 9.4136e-01, -1.0877e+00],\n",
      "        [ 3.8313e-01,  1.3023e+00],\n",
      "        [ 4.0628e-01,  6.7976e-01],\n",
      "        [-9.7674e-01, -3.8485e-02],\n",
      "        [ 1.4288e+00, -6.3540e-01],\n",
      "        [ 1.4890e-01, -2.2070e-01],\n",
      "        [-8.0717e-02, -1.5923e+00],\n",
      "        [ 1.7888e-01, -6.7611e-01],\n",
      "        [ 5.4813e-01, -5.2800e-01],\n",
      "        [ 1.0374e+00, -1.2125e-01]], device='cuda:0')\n",
      "Action space size: 495\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 5/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -2.703132\n",
      "Size of input data: torch.Size([117, 2])\n",
      "Size of embeddings: torch.Size([117, 2])\n",
      "Embeddings: tensor([[-2.0962e+00,  1.2987e+00],\n",
      "        [-2.1111e+00,  1.5440e+00],\n",
      "        [-3.2955e+00,  2.6004e+00],\n",
      "        [-2.3514e+00,  1.6123e+00],\n",
      "        [-4.1406e-01, -4.6510e-01],\n",
      "        [ 9.3515e-01, -1.8414e+00],\n",
      "        [-2.0095e-01,  7.9848e-01],\n",
      "        [-8.0603e-01,  5.1246e-01],\n",
      "        [ 2.1364e-01, -2.4322e-01],\n",
      "        [ 1.2433e+00, -5.9754e-01],\n",
      "        [ 2.2256e-01, -4.2961e-01],\n",
      "        [-5.1428e-01,  8.7486e-01],\n",
      "        [-2.4387e+00,  1.3962e+00],\n",
      "        [-2.4486e-01, -9.3492e-01],\n",
      "        [ 1.6792e-01, -5.3922e-01],\n",
      "        [ 1.7525e-01, -1.4461e+00],\n",
      "        [-1.9706e-01,  2.8417e-01],\n",
      "        [ 1.0822e+00, -3.5705e-01],\n",
      "        [-3.7745e+00,  3.0468e+00],\n",
      "        [-1.1372e+00,  2.2079e+00],\n",
      "        [ 3.9625e-01,  3.2063e-01],\n",
      "        [-1.2621e-01, -2.1347e-01],\n",
      "        [-4.6128e-01,  1.9039e-01],\n",
      "        [-2.6709e+00,  2.1662e+00],\n",
      "        [-1.4689e-01, -5.8755e-01],\n",
      "        [ 4.2996e-01, -1.9656e-02],\n",
      "        [ 2.3454e-01,  7.4640e-01],\n",
      "        [-1.4573e+00,  2.0901e+00],\n",
      "        [-8.1118e-01,  6.8292e-01],\n",
      "        [ 2.4145e-01,  3.7557e-01],\n",
      "        [ 5.1265e-01, -2.0808e-01],\n",
      "        [-3.2275e-01,  8.8752e-01],\n",
      "        [ 3.2292e-03, -1.8348e+00],\n",
      "        [-9.6251e-01, -9.6438e-01],\n",
      "        [ 2.1817e-01, -1.7101e-01],\n",
      "        [-2.6709e+00,  2.1662e+00],\n",
      "        [-1.0157e+00,  7.3385e-01],\n",
      "        [ 8.2703e-01, -1.3459e+00],\n",
      "        [-5.9439e-01,  1.6203e-01],\n",
      "        [ 7.3674e-01, -5.8614e-01],\n",
      "        [ 1.6830e-01, -3.7696e-01],\n",
      "        [-4.0811e+00,  2.8223e+00],\n",
      "        [ 1.7973e-02, -9.3495e-03],\n",
      "        [ 1.3611e-01,  1.7695e-01],\n",
      "        [-6.3975e-02,  1.2441e+00],\n",
      "        [ 1.0930e+00, -5.6463e-01],\n",
      "        [ 1.1486e-01, -1.7303e+00],\n",
      "        [ 2.5397e-01, -4.5399e-01],\n",
      "        [ 9.5112e-01, -6.8855e-01],\n",
      "        [ 1.4086e-01,  3.1458e-01],\n",
      "        [-1.0632e-01,  9.1154e-01],\n",
      "        [ 5.0258e-01, -5.4137e-01],\n",
      "        [ 1.3594e-01, -1.0770e+00],\n",
      "        [ 6.9627e-01,  4.4818e-01],\n",
      "        [ 1.9884e-01, -1.5012e+00],\n",
      "        [ 6.8184e-01, -1.1899e+00],\n",
      "        [ 1.1375e-01, -1.4860e+00],\n",
      "        [-3.5424e-01, -1.3945e+00],\n",
      "        [ 2.7623e-01,  4.5920e-01],\n",
      "        [-1.7481e-02, -4.0268e-01],\n",
      "        [ 9.6597e-01,  3.1251e-01],\n",
      "        [ 9.1187e-01,  7.4547e-01],\n",
      "        [ 2.3949e-01,  8.7424e-01],\n",
      "        [ 3.0798e-01,  1.2524e-01],\n",
      "        [ 5.0898e-01, -5.1331e-01],\n",
      "        [ 6.0930e-01, -1.2062e+00],\n",
      "        [ 6.4258e-01, -1.5479e+00],\n",
      "        [-3.3114e-02,  1.2146e+00],\n",
      "        [ 1.4982e-01,  1.3817e-01],\n",
      "        [ 3.7297e-01, -3.6555e-01],\n",
      "        [ 8.2443e-01, -6.6245e-01],\n",
      "        [ 2.1190e-01, -5.2823e-02],\n",
      "        [ 4.2203e-01,  1.8380e-02],\n",
      "        [ 2.2869e-02,  1.4032e-01],\n",
      "        [ 6.6960e-01, -8.5257e-01],\n",
      "        [ 2.4389e-01,  4.8265e-01],\n",
      "        [ 6.8797e-01, -1.0240e+00],\n",
      "        [ 7.2286e-01, -7.4394e-03],\n",
      "        [-3.7961e-01, -4.6721e-01],\n",
      "        [ 2.1884e-01,  1.2889e-02],\n",
      "        [ 2.3468e-01,  1.3043e+00],\n",
      "        [ 4.9077e-01,  4.0613e-01],\n",
      "        [ 7.6435e-01, -4.8007e-01],\n",
      "        [ 1.6031e+00, -1.7590e-01],\n",
      "        [ 8.6090e-01, -2.4898e-01],\n",
      "        [-3.9462e-01,  9.9142e-02],\n",
      "        [ 1.3249e+00, -8.2789e-01],\n",
      "        [ 7.0090e-01, -1.0364e-01],\n",
      "        [-4.1697e-01, -3.5153e-01],\n",
      "        [-1.6829e-01, -2.9717e-01],\n",
      "        [ 8.4674e-01, -5.3572e-01],\n",
      "        [ 1.0387e+00,  4.1197e-01],\n",
      "        [-9.1556e-02, -6.4628e-02],\n",
      "        [ 4.7232e-01, -1.7844e+00],\n",
      "        [-1.2312e-01,  9.3524e-01],\n",
      "        [ 3.4552e-01,  3.3291e-01],\n",
      "        [ 1.5387e-01,  3.7598e-01],\n",
      "        [ 1.3569e+00, -6.9861e-01],\n",
      "        [ 5.0313e-01, -2.5930e-02],\n",
      "        [ 1.1102e+00, -6.3777e-01],\n",
      "        [-1.1548e-01, -1.4261e-01],\n",
      "        [ 9.3594e-01,  3.4990e-01],\n",
      "        [ 1.2946e+00, -1.1997e+00],\n",
      "        [-6.4864e-01, -4.4857e-01],\n",
      "        [-3.2408e-01, -1.3457e+00],\n",
      "        [-5.6938e-03, -8.6489e-02],\n",
      "        [ 2.6249e-01,  1.7322e-02],\n",
      "        [-2.5331e-02, -9.7007e-01],\n",
      "        [ 1.5861e-01,  1.3647e+00],\n",
      "        [ 4.8316e-01,  9.7700e-01],\n",
      "        [ 8.5800e-01, -4.5671e-01],\n",
      "        [-3.5165e-01, -1.1503e+00],\n",
      "        [ 2.1810e-02,  6.6529e-01],\n",
      "        [ 6.7985e-01, -1.0419e+00],\n",
      "        [ 2.6400e-01,  4.6906e-01],\n",
      "        [-4.6716e-01,  1.4123e-01],\n",
      "        [ 3.6970e-01, -1.0145e+00]], device='cuda:0')\n",
      "Action space size: 565\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 6/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -2.4328188\n",
      "Size of input data: torch.Size([130, 2])\n",
      "Size of embeddings: torch.Size([130, 2])\n",
      "Embeddings: tensor([[-2.3887e+00,  1.5826e+00],\n",
      "        [-2.0732e+00,  2.2712e+00],\n",
      "        [-4.0159e+00,  2.3729e+00],\n",
      "        [-2.5952e+00,  2.6449e+00],\n",
      "        [ 6.2791e-02,  4.7724e-01],\n",
      "        [ 2.1118e-01, -1.2438e+00],\n",
      "        [ 1.3987e-02,  1.0824e+00],\n",
      "        [-5.9131e-01,  1.0692e+00],\n",
      "        [ 8.3380e-02,  4.4599e-01],\n",
      "        [ 4.3997e-01, -8.2388e-01],\n",
      "        [-4.5034e-01, -5.8444e-01],\n",
      "        [-1.4601e+00,  1.8546e+00],\n",
      "        [-3.4809e+00, -4.1408e-01],\n",
      "        [ 4.5192e-01,  5.0902e-01],\n",
      "        [ 8.4313e-02, -5.1087e-02],\n",
      "        [-2.4926e-01, -2.7522e-01],\n",
      "        [ 2.5472e-01,  8.2762e-01],\n",
      "        [ 3.5279e-01, -9.4139e-02],\n",
      "        [-1.9296e+00,  3.7165e+00],\n",
      "        [-1.9939e+00,  1.0895e+00],\n",
      "        [-3.9364e-01,  3.3519e-01],\n",
      "        [ 8.3360e-01,  7.8825e-01],\n",
      "        [ 2.2031e-01,  2.8865e-01],\n",
      "        [-3.6330e+00,  2.6266e-01],\n",
      "        [-9.9020e-01, -6.1890e-01],\n",
      "        [-1.1378e-01, -5.3936e-01],\n",
      "        [ 1.7537e-01,  2.2046e-01],\n",
      "        [-2.7100e+00,  8.6475e-01],\n",
      "        [-7.3954e-02,  5.2246e-01],\n",
      "        [-1.7623e-03,  4.0265e-01],\n",
      "        [ 1.9086e-01, -7.8298e-02],\n",
      "        [-5.2234e-01,  4.1312e-01],\n",
      "        [ 4.6536e-02, -2.3209e+00],\n",
      "        [ 1.4387e-01, -9.5584e-01],\n",
      "        [ 6.9601e-01, -3.3101e-01],\n",
      "        [-3.6330e+00,  2.6266e-01],\n",
      "        [ 1.1701e-02,  1.7289e+00],\n",
      "        [ 1.0252e+00, -1.4475e+00],\n",
      "        [-2.7705e-01,  6.5888e-02],\n",
      "        [ 7.0534e-01, -4.5556e-01],\n",
      "        [-3.0183e-01,  1.5624e-01],\n",
      "        [-1.2090e+00,  4.3817e+00],\n",
      "        [ 6.8318e-01, -1.5633e-01],\n",
      "        [ 5.2481e-02,  3.1198e-01],\n",
      "        [-5.8179e-01,  8.1602e-01],\n",
      "        [ 7.3541e-01,  2.1956e-01],\n",
      "        [ 9.9574e-01, -1.2323e+00],\n",
      "        [-3.9908e-01, -2.0610e-01],\n",
      "        [ 2.7372e-01, -5.2859e-01],\n",
      "        [ 4.5070e-01,  6.4549e-01],\n",
      "        [ 7.2321e-01,  8.3305e-01],\n",
      "        [-4.2108e-01, -2.3825e-01],\n",
      "        [ 2.3664e-02, -4.2938e-01],\n",
      "        [ 4.4933e-01, -2.4186e-01],\n",
      "        [-1.0580e-01, -6.5072e-01],\n",
      "        [ 9.4539e-01, -3.4009e-01],\n",
      "        [-3.6540e-01, -4.0646e-01],\n",
      "        [ 3.5217e-01, -1.8559e-01],\n",
      "        [ 6.7678e-01,  5.2492e-01],\n",
      "        [ 1.3610e+00, -2.2984e-01],\n",
      "        [ 4.9193e-01, -4.3000e-01],\n",
      "        [-4.2325e-01,  2.6701e-01],\n",
      "        [ 4.3239e-01,  3.0949e-01],\n",
      "        [-6.6018e-01, -1.2437e-02],\n",
      "        [-1.9171e-02, -2.5278e-01],\n",
      "        [ 8.0812e-01, -4.0817e-01],\n",
      "        [-4.9772e-01, -7.3828e-01],\n",
      "        [-2.0809e-01,  1.0442e+00],\n",
      "        [ 4.4873e-02, -3.2600e-01],\n",
      "        [-3.0231e-01,  2.6089e-01],\n",
      "        [ 1.0175e+00, -7.8057e-01],\n",
      "        [ 9.6728e-01, -4.5138e-01],\n",
      "        [ 1.6968e-01, -1.3683e+00],\n",
      "        [ 2.8531e-01,  5.6571e-01],\n",
      "        [ 4.8970e-02, -6.8716e-01],\n",
      "        [ 5.6707e-01,  5.8259e-01],\n",
      "        [ 8.7344e-01, -1.2796e+00],\n",
      "        [ 5.5444e-01, -7.0148e-01],\n",
      "        [-6.0876e-01, -1.8304e-01],\n",
      "        [ 1.0104e+00, -4.6080e-01],\n",
      "        [ 2.8530e-01,  5.5616e-01],\n",
      "        [ 4.5013e-01, -2.9542e-01],\n",
      "        [ 3.9445e-01,  2.8642e-02],\n",
      "        [ 5.6673e-01,  2.1517e-02],\n",
      "        [ 1.5918e+00,  7.3186e-01],\n",
      "        [-1.1562e-01,  2.8802e-01],\n",
      "        [ 4.3240e-01, -1.4479e+00],\n",
      "        [ 1.0405e-01, -1.5208e+00],\n",
      "        [-4.0483e-01, -7.5106e-01],\n",
      "        [-3.0998e-01,  1.4296e-01],\n",
      "        [-1.7566e-01, -8.6096e-01],\n",
      "        [ 6.2851e-02, -6.4790e-01],\n",
      "        [-7.4097e-01,  4.5856e-01],\n",
      "        [ 5.5149e-01, -1.2209e+00],\n",
      "        [ 5.4819e-01,  2.7924e-01],\n",
      "        [ 6.2050e-01,  6.0237e-01],\n",
      "        [-3.9068e-01,  4.4304e-01],\n",
      "        [ 1.0337e+00, -7.7828e-01],\n",
      "        [ 1.6289e-01, -3.2853e-02],\n",
      "        [ 9.4002e-01, -9.4259e-01],\n",
      "        [ 7.6774e-01, -3.7390e-02],\n",
      "        [ 1.4042e-01, -8.0005e-01],\n",
      "        [ 4.3788e-01, -9.4729e-01],\n",
      "        [-7.8072e-01,  9.4446e-03],\n",
      "        [ 2.5171e-01,  4.1140e-01],\n",
      "        [ 7.8444e-01, -2.0752e-01],\n",
      "        [ 8.2938e-01, -4.4090e-01],\n",
      "        [ 7.9476e-01, -5.6929e-01],\n",
      "        [-1.4996e-01,  6.4456e-01],\n",
      "        [ 6.0630e-01,  3.1815e-01],\n",
      "        [ 7.1177e-01,  1.7887e-01],\n",
      "        [ 3.2015e-01, -2.7467e-01],\n",
      "        [ 5.1907e-01,  4.3303e-01],\n",
      "        [ 4.6370e-01, -1.1069e+00],\n",
      "        [ 3.1362e-01,  2.2461e-02],\n",
      "        [ 4.0662e-02,  7.1316e-01],\n",
      "        [ 9.7658e-01, -7.6449e-01],\n",
      "        [-3.1446e-01,  2.4006e-01],\n",
      "        [ 5.4351e-01, -7.6812e-01],\n",
      "        [ 7.2351e-01, -1.8485e+00],\n",
      "        [ 4.0411e-01, -9.8389e-02],\n",
      "        [ 5.6521e-01, -1.2788e+00],\n",
      "        [ 4.9582e-01,  2.2012e-01],\n",
      "        [ 7.1731e-01, -2.5852e+00],\n",
      "        [ 1.1097e+00, -1.5488e+00],\n",
      "        [ 2.7197e-01,  1.1599e-02],\n",
      "        [-2.1060e-03,  9.9561e-01],\n",
      "        [-7.7037e-01,  1.7019e+00],\n",
      "        [ 1.2301e+00, -1.3730e+00],\n",
      "        [ 1.0741e+00, -1.6343e-01]], device='cuda:0')\n",
      "Action space size: 630\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 7/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -2.18953692\n",
      "Size of input data: torch.Size([150, 2])\n",
      "Size of embeddings: torch.Size([150, 2])\n",
      "Embeddings: tensor([[-1.0384e+00,  1.8330e+00],\n",
      "        [-9.6708e-01,  3.0441e+00],\n",
      "        [-2.2466e+00,  2.9719e+00],\n",
      "        [-1.6243e+00,  2.4619e+00],\n",
      "        [ 5.6868e-01,  8.8539e-01],\n",
      "        [ 8.1748e-01, -7.9352e-01],\n",
      "        [ 3.4360e-01,  6.1599e-01],\n",
      "        [ 1.4231e-01,  1.0484e+00],\n",
      "        [-3.6497e-01,  4.5553e-01],\n",
      "        [ 1.0946e-01, -9.7377e-01],\n",
      "        [ 3.6097e-02,  5.0147e-02],\n",
      "        [-9.7856e-01,  1.3271e+00],\n",
      "        [-1.3654e+00, -3.1854e-01],\n",
      "        [ 3.8443e-01, -1.6963e-01],\n",
      "        [ 1.2447e-01,  1.2427e-01],\n",
      "        [ 2.3888e-01, -8.3777e-03],\n",
      "        [-1.0628e-01,  1.4916e-01],\n",
      "        [ 1.2861e-02,  6.1673e-01],\n",
      "        [-1.5841e+00, -8.1871e-02],\n",
      "        [-9.4741e-01,  9.5063e-01],\n",
      "        [ 1.8511e-01,  5.5791e-01],\n",
      "        [-2.1363e-01,  4.0625e-02],\n",
      "        [-4.7110e-01,  1.8722e+00],\n",
      "        [-1.8280e+00, -9.0160e-02],\n",
      "        [-1.0273e+00, -2.7172e-01],\n",
      "        [ 1.2842e-01, -8.2437e-01],\n",
      "        [-1.1926e-02,  3.3849e-01],\n",
      "        [-1.7306e+00,  6.9349e-01],\n",
      "        [ 5.8748e-02,  9.0886e-02],\n",
      "        [ 4.7202e-01,  5.3134e-02],\n",
      "        [-4.1861e-01,  8.8216e-02],\n",
      "        [-1.1288e-01,  9.4092e-01],\n",
      "        [ 5.1704e-01, -1.2502e+00],\n",
      "        [ 4.1957e-01, -7.3504e-01],\n",
      "        [ 3.8244e-01,  5.7785e-01],\n",
      "        [-2.1812e+00, -2.0993e-02],\n",
      "        [-1.0745e+00,  8.1257e-03],\n",
      "        [ 5.8946e-01, -2.0280e+00],\n",
      "        [-2.2961e-01,  5.4530e-01],\n",
      "        [ 2.1983e-01, -5.3783e-02],\n",
      "        [ 8.0717e-01,  5.8782e-01],\n",
      "        [-1.3856e+00, -7.1707e-01],\n",
      "        [ 5.8256e-01,  6.9480e-01],\n",
      "        [-7.4807e-01,  5.5392e-01],\n",
      "        [-8.1350e-02,  2.0495e-01],\n",
      "        [-3.6738e-01,  2.4598e-01],\n",
      "        [ 4.1828e-01, -8.2546e-01],\n",
      "        [-3.3685e-01,  4.5114e-01],\n",
      "        [ 3.3885e-01,  3.3468e-01],\n",
      "        [ 1.3354e-01, -1.3185e-01],\n",
      "        [-4.7538e-01,  1.6255e+00],\n",
      "        [-9.5193e-01, -1.8735e+00],\n",
      "        [ 4.6585e-01,  2.4723e-01],\n",
      "        [ 5.1021e-01, -1.4756e-01],\n",
      "        [ 6.0840e-01,  4.2956e-01],\n",
      "        [ 7.7890e-02, -2.0049e-01],\n",
      "        [ 3.4364e-02,  1.1051e-01],\n",
      "        [ 6.8366e-01, -1.1073e+00],\n",
      "        [ 2.8593e-01,  5.0388e-01],\n",
      "        [ 3.0678e-01, -1.4918e-01],\n",
      "        [ 5.0541e-01, -5.2464e-01],\n",
      "        [-2.5300e-01,  1.3432e+00],\n",
      "        [ 2.0307e-01,  3.9400e-01],\n",
      "        [-5.4412e-01,  5.6445e-01],\n",
      "        [-1.0889e-01,  5.7408e-02],\n",
      "        [ 2.7154e-01, -2.3925e-01],\n",
      "        [-1.5322e-01, -4.5971e-01],\n",
      "        [-8.8830e-02,  7.1657e-01],\n",
      "        [ 2.2650e-02,  4.7560e-01],\n",
      "        [-3.3990e-01,  3.6854e-01],\n",
      "        [ 9.9373e-01, -4.7121e-01],\n",
      "        [ 7.2379e-01, -5.0890e-01],\n",
      "        [ 2.2923e-01, -1.8112e+00],\n",
      "        [ 1.3084e-01,  3.6887e-01],\n",
      "        [-5.3202e-02, -7.8230e-02],\n",
      "        [-4.5243e-02,  1.3442e-01],\n",
      "        [ 8.3588e-01, -1.3680e+00],\n",
      "        [ 4.7029e-01, -5.1254e-01],\n",
      "        [-6.5748e-01, -3.6305e-01],\n",
      "        [ 6.4484e-01, -1.5166e-01],\n",
      "        [ 2.6344e-01,  7.2265e-01],\n",
      "        [ 1.5704e-01, -7.3437e-01],\n",
      "        [ 2.5026e-01,  7.8370e-01],\n",
      "        [ 5.0321e-01,  7.6277e-01],\n",
      "        [-2.2576e+00, -1.1809e+00],\n",
      "        [-9.2399e-01,  1.0415e+00],\n",
      "        [ 8.3629e-01, -9.1536e-01],\n",
      "        [ 3.8075e-01, -1.4021e+00],\n",
      "        [ 1.7762e-02, -2.7880e-01],\n",
      "        [ 3.2073e-01,  2.5797e-01],\n",
      "        [ 2.2345e-01, -2.7110e-01],\n",
      "        [ 5.5708e-01,  9.0811e-02],\n",
      "        [-9.2381e-01,  8.3320e-02],\n",
      "        [ 7.8624e-01, -7.8451e-01],\n",
      "        [ 2.7097e-02,  4.7151e-04],\n",
      "        [-2.1736e-03,  3.4800e-01],\n",
      "        [-5.1011e-02, -3.2563e-01],\n",
      "        [ 3.6659e-01, -6.8441e-01],\n",
      "        [-3.5610e-01,  1.5447e-02],\n",
      "        [ 9.5327e-01, -1.5586e+00],\n",
      "        [ 3.9187e-01,  3.5612e-01],\n",
      "        [ 2.1202e-01, -3.5250e-01],\n",
      "        [ 1.4672e-01, -1.1859e+00],\n",
      "        [-9.9628e-02, -5.8821e-01],\n",
      "        [ 2.9165e-01, -1.3518e-01],\n",
      "        [ 7.1527e-01, -2.1034e-02],\n",
      "        [ 7.2342e-01,  2.0068e-01],\n",
      "        [ 1.4760e+00, -5.1204e-01],\n",
      "        [ 2.7876e-01,  9.6282e-01],\n",
      "        [ 2.5163e-01,  3.7376e-01],\n",
      "        [ 2.5521e-01, -1.4311e-01],\n",
      "        [ 1.2519e+00,  4.6354e-01],\n",
      "        [-9.0377e-03,  6.1224e-01],\n",
      "        [ 1.3577e-01, -5.5863e-01],\n",
      "        [ 1.3609e-01,  7.8869e-02],\n",
      "        [-9.4565e-01,  6.1358e-01],\n",
      "        [ 6.2410e-01, -1.1996e+00],\n",
      "        [-4.4923e-01,  5.1267e-01],\n",
      "        [ 5.2920e-01, -5.5088e-01],\n",
      "        [ 1.2448e+00, -1.2109e+00],\n",
      "        [ 2.4915e-01, -1.6064e-01],\n",
      "        [ 2.4086e-01, -1.1989e+00],\n",
      "        [-2.1004e-02, -5.3718e-02],\n",
      "        [ 1.1259e+00, -3.1987e+00],\n",
      "        [ 1.5340e+00, -1.3953e+00],\n",
      "        [ 1.4389e-01,  2.1660e-01],\n",
      "        [ 2.1396e-01,  5.4853e-01],\n",
      "        [-6.2999e-01,  6.5502e-01],\n",
      "        [ 1.5361e+00, -9.7419e-01],\n",
      "        [ 1.5281e+00,  8.0236e-01],\n",
      "        [ 2.7386e-01,  4.9996e-01],\n",
      "        [-1.7133e-01,  5.6894e-01],\n",
      "        [ 5.8495e-01,  5.6784e-01],\n",
      "        [-4.8247e-01,  3.0095e-02],\n",
      "        [ 6.9374e-01,  4.9257e-01],\n",
      "        [ 2.5880e-01,  1.2376e+00],\n",
      "        [ 3.0020e-03,  8.3366e-01],\n",
      "        [ 6.5105e-01,  7.6311e-01],\n",
      "        [ 5.4125e-01, -7.6416e-01],\n",
      "        [ 5.3891e-01, -7.0707e-01],\n",
      "        [ 6.8804e-01,  2.8249e-01],\n",
      "        [ 3.7163e-01,  5.4815e-01],\n",
      "        [ 6.0561e-02, -3.3289e-01],\n",
      "        [ 3.8865e-01, -1.4925e-01],\n",
      "        [-8.2616e-01,  1.2659e-01],\n",
      "        [ 2.2522e-01,  6.3076e-01],\n",
      "        [ 1.1801e+00,  5.2265e-01],\n",
      "        [-8.5193e+00, -6.2258e+00],\n",
      "        [-4.7440e-01, -5.9376e-01],\n",
      "        [ 8.8100e-01, -7.5335e-01]], device='cuda:0')\n",
      "Action space size: 730\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 8/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -1.9705832280000004\n",
      "Size of input data: torch.Size([161, 2])\n",
      "Size of embeddings: torch.Size([161, 2])\n",
      "Embeddings: tensor([[-2.3690e+00,  1.1411e+00],\n",
      "        [-2.2961e+00,  1.3654e+00],\n",
      "        [-4.3525e+00,  1.6145e+00],\n",
      "        [-3.3143e+00,  1.4594e+00],\n",
      "        [ 1.2437e+00,  2.1191e-01],\n",
      "        [ 6.8064e-01, -5.4104e-01],\n",
      "        [-2.6578e-01,  9.0951e-02],\n",
      "        [ 8.5663e-02,  9.3182e-02],\n",
      "        [-2.4148e-01, -2.8998e-01],\n",
      "        [ 7.4391e-01, -4.4679e-01],\n",
      "        [-4.6318e-01, -5.1221e-01],\n",
      "        [-9.3402e-01,  5.2519e-01],\n",
      "        [-2.2281e+00,  1.8143e-01],\n",
      "        [ 7.8697e-02, -1.3005e-01],\n",
      "        [ 5.1998e-01,  1.7956e-01],\n",
      "        [ 3.8365e-01, -7.5011e-01],\n",
      "        [ 5.4924e-02,  1.4812e-01],\n",
      "        [ 2.1760e-01,  4.5431e-01],\n",
      "        [ 1.1717e+00,  1.2575e+00],\n",
      "        [-8.4309e-01,  4.5380e-01],\n",
      "        [ 7.6673e-01,  4.8010e-01],\n",
      "        [ 5.0182e-01, -1.1830e-01],\n",
      "        [-7.1548e-01,  2.0071e-01],\n",
      "        [-2.2531e+00,  4.6389e-01],\n",
      "        [-1.8828e+00, -2.9496e-01],\n",
      "        [-2.1882e-01, -3.6361e-01],\n",
      "        [ 7.7951e-02,  6.0695e-02],\n",
      "        [-1.9496e+00,  5.5039e-01],\n",
      "        [ 6.9456e-01,  1.4681e-01],\n",
      "        [-4.7684e-01, -1.9298e-01],\n",
      "        [-2.3429e-01,  6.3549e-01],\n",
      "        [-1.7338e+00,  1.4878e-01],\n",
      "        [ 9.7711e-01, -1.3842e+00],\n",
      "        [ 1.1185e+00, -5.5335e-01],\n",
      "        [-2.2391e-01, -1.0582e-01],\n",
      "        [-1.2835e+00,  8.0843e-01],\n",
      "        [ 9.6758e-01,  1.1422e+00],\n",
      "        [ 6.0002e-01, -8.9217e-01],\n",
      "        [-1.3788e+00,  1.9382e-01],\n",
      "        [ 1.0663e+00, -5.6079e-01],\n",
      "        [ 6.8204e-01,  1.7673e-01],\n",
      "        [ 4.5412e-01,  1.1972e+00],\n",
      "        [ 1.4877e-01, -6.6009e-02],\n",
      "        [-6.4351e-01,  4.9268e-01],\n",
      "        [ 1.0121e+00,  2.2581e-01],\n",
      "        [-1.7262e-01,  2.8076e-01],\n",
      "        [ 6.7060e-01, -8.2394e-01],\n",
      "        [ 5.5662e-02, -4.7078e-01],\n",
      "        [ 3.6539e-01,  4.2033e-01],\n",
      "        [ 2.2344e-01, -5.0683e-02],\n",
      "        [ 1.3392e-01,  1.0222e-01],\n",
      "        [ 3.0844e-01, -7.2363e-01],\n",
      "        [-4.9037e-01, -1.4326e-01],\n",
      "        [-3.5272e-01, -1.8953e-01],\n",
      "        [ 1.0832e+00, -8.2779e-01],\n",
      "        [ 1.6631e-01, -1.8660e-01],\n",
      "        [ 1.2088e-01, -7.0570e-01],\n",
      "        [-4.6684e-02, -5.9609e-01],\n",
      "        [-3.2448e-02,  8.7543e-02],\n",
      "        [ 4.1168e-01, -8.7753e-02],\n",
      "        [-2.3915e-01, -2.0637e-01],\n",
      "        [-2.4230e-01,  8.1205e-01],\n",
      "        [-2.1902e-01,  1.6292e-01],\n",
      "        [-6.2914e-01,  6.7135e-01],\n",
      "        [ 2.7606e-01,  9.5527e-02],\n",
      "        [ 5.3689e-01, -1.8209e-01],\n",
      "        [-4.0448e-01, -8.2754e-01],\n",
      "        [-8.6884e-02,  1.2661e-01],\n",
      "        [ 1.7302e-02, -1.5607e-01],\n",
      "        [ 2.8818e-01, -3.7520e-01],\n",
      "        [ 1.6431e+00, -3.2838e-01],\n",
      "        [ 5.2781e-01, -4.4503e-01],\n",
      "        [ 5.8871e-02, -6.5810e-01],\n",
      "        [-1.7811e-01,  1.4565e-01],\n",
      "        [ 1.1965e-01, -6.7664e-01],\n",
      "        [ 7.7408e-01,  9.1760e-02],\n",
      "        [ 5.7210e-01, -8.0118e-01],\n",
      "        [-1.3327e+00, -3.4358e-01],\n",
      "        [-1.4072e+00, -9.5918e-02],\n",
      "        [ 8.2179e-01, -3.5573e-01],\n",
      "        [ 2.3406e-01,  2.9388e-01],\n",
      "        [ 3.0345e-02, -1.0094e-01],\n",
      "        [-1.8659e-01,  3.9568e-01],\n",
      "        [ 6.0208e-01,  5.6527e-01],\n",
      "        [-2.5134e+00,  5.5724e-01],\n",
      "        [-1.3638e+00,  4.4034e-01],\n",
      "        [ 9.7042e-01, -5.9788e-01],\n",
      "        [-1.5499e+00, -5.6299e-01],\n",
      "        [ 8.8377e-01, -4.9083e-01],\n",
      "        [ 1.1436e+00,  2.6169e-03],\n",
      "        [ 4.4081e-01, -5.3372e-01],\n",
      "        [ 2.2887e-01, -2.0527e-01],\n",
      "        [-8.3038e-01,  3.0292e-02],\n",
      "        [ 1.3479e+00, -1.0829e+00],\n",
      "        [-4.5424e-01,  9.5559e-02],\n",
      "        [ 4.3319e-01,  6.0873e-02],\n",
      "        [ 3.0063e-01, -2.1764e-01],\n",
      "        [ 5.8554e-01,  1.4909e-01],\n",
      "        [ 4.0006e-01,  3.7447e-01],\n",
      "        [ 5.6583e-01, -7.3451e-01],\n",
      "        [ 9.2370e-02, -1.7044e-01],\n",
      "        [ 1.8182e-01, -6.8617e-02],\n",
      "        [ 5.4263e-01, -1.0484e+00],\n",
      "        [-1.1182e+00, -4.2022e-01],\n",
      "        [ 1.3359e-01, -2.6625e-01],\n",
      "        [ 3.3271e-01, -2.1421e-01],\n",
      "        [ 4.8427e-01, -3.8026e-01],\n",
      "        [ 1.0669e+00, -2.6726e-01],\n",
      "        [ 1.4258e-01,  2.0256e-01],\n",
      "        [ 2.4849e-01,  1.9159e-01],\n",
      "        [ 4.3911e-01, -2.7478e-01],\n",
      "        [ 5.1011e-02, -4.6369e-01],\n",
      "        [-6.3913e-01,  7.4135e-02],\n",
      "        [ 3.5715e-01, -7.0547e-01],\n",
      "        [-1.0029e+00,  1.3262e-01],\n",
      "        [-1.4152e+00,  2.5532e-01],\n",
      "        [ 2.6742e-01, -6.9886e-01],\n",
      "        [ 1.9440e-02, -3.7492e-01],\n",
      "        [ 1.2889e+00, -8.3892e-01],\n",
      "        [ 5.1909e-01, -1.1680e+00],\n",
      "        [-1.0449e+00,  2.3180e-02],\n",
      "        [-1.3570e-01, -9.1312e-01],\n",
      "        [-5.2249e-01,  1.2759e-01],\n",
      "        [-6.0829e-03, -1.6631e+00],\n",
      "        [ 8.1203e-01, -3.9571e-01],\n",
      "        [ 3.6147e-01,  2.0211e-01],\n",
      "        [-2.9405e-01,  3.1300e-02],\n",
      "        [-2.6194e-01,  4.9935e-01],\n",
      "        [ 4.5512e-01, -2.6548e-01],\n",
      "        [ 9.1840e-01,  2.1983e-01],\n",
      "        [-2.5603e-01, -6.5240e-03],\n",
      "        [ 2.1237e-01,  2.2341e-01],\n",
      "        [ 3.7239e-01, -1.1161e-01],\n",
      "        [-2.2538e-01,  4.1440e-02],\n",
      "        [ 3.7797e-01, -1.5132e-01],\n",
      "        [ 5.8166e-01,  2.4883e-01],\n",
      "        [-7.9656e-01,  2.2488e-01],\n",
      "        [ 1.3270e+00,  4.3703e-01],\n",
      "        [ 2.8905e-01, -3.3633e-01],\n",
      "        [ 9.6661e-01, -9.3977e-01],\n",
      "        [ 1.5189e+00,  2.9860e-01],\n",
      "        [ 3.3284e-01,  1.5182e-01],\n",
      "        [-2.2678e-01,  2.4866e-01],\n",
      "        [ 1.2595e+00, -5.9474e-02],\n",
      "        [-4.3824e-01,  4.2750e-01],\n",
      "        [ 7.8802e-01,  1.9813e-01],\n",
      "        [ 8.3391e-01, -3.4435e-01],\n",
      "        [-4.4522e+00,  1.0720e+01],\n",
      "        [-9.6494e-01, -3.2920e-01],\n",
      "        [ 1.4863e+00, -7.3857e-01],\n",
      "        [ 1.7050e-02, -6.6184e-01],\n",
      "        [ 3.0568e-01,  9.9382e-02],\n",
      "        [ 1.0793e+00, -3.4873e-02],\n",
      "        [ 5.9055e-01, -2.3581e-01],\n",
      "        [ 5.1944e-01, -9.9816e-04],\n",
      "        [ 4.1202e-01, -1.0909e+00],\n",
      "        [ 1.1489e+00,  1.9140e-01],\n",
      "        [ 1.3319e+00, -9.6163e-02],\n",
      "        [ 6.5080e-01,  2.4028e-01],\n",
      "        [-1.4367e-01,  1.9409e-01],\n",
      "        [ 2.7135e-01, -2.4472e-01]], device='cuda:0')\n",
      "Action space size: 785\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 9/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -1.7735249052000004\n",
      "Size of input data: torch.Size([174, 2])\n",
      "Size of embeddings: torch.Size([174, 2])\n",
      "Embeddings: tensor([[-1.9309e+00,  2.5931e+00],\n",
      "        [-1.9064e+00,  2.9536e+00],\n",
      "        [-4.2837e+00,  3.2380e+00],\n",
      "        [-2.9709e+00,  3.6722e+00],\n",
      "        [ 2.7519e-01,  4.9634e-01],\n",
      "        [ 1.1583e+00, -3.2282e-01],\n",
      "        [-6.8685e-02,  7.6082e-02],\n",
      "        [ 5.8921e-01,  6.9799e-01],\n",
      "        [ 1.0705e-01,  4.7540e-01],\n",
      "        [ 3.1084e-01, -4.4392e-01],\n",
      "        [-2.1337e-01, -7.8464e-01],\n",
      "        [-4.8728e-01,  9.9359e-01],\n",
      "        [-2.1876e+00, -2.0889e+00],\n",
      "        [ 1.1272e+00,  3.9645e-01],\n",
      "        [ 7.1428e-01,  8.7086e-02],\n",
      "        [-6.0115e-01, -5.9752e-01],\n",
      "        [-5.8891e-01,  3.9455e-01],\n",
      "        [ 8.0832e-01,  5.7288e-01],\n",
      "        [-2.3359e-01,  3.0824e+00],\n",
      "        [-1.3498e+00, -8.8788e-01],\n",
      "        [ 9.3383e-01,  7.1352e-01],\n",
      "        [ 3.7064e-01,  8.1888e-02],\n",
      "        [ 9.7247e-02,  1.1795e+00],\n",
      "        [-1.6544e+00, -2.4146e+00],\n",
      "        [-3.0825e+00,  2.1594e+00],\n",
      "        [-1.5502e-01, -6.4744e-01],\n",
      "        [-1.3252e+00,  3.3319e-02],\n",
      "        [-3.7079e+00,  4.8510e-01],\n",
      "        [ 3.5118e-01,  1.3350e-01],\n",
      "        [-1.9431e-01, -4.8270e-01],\n",
      "        [ 8.2538e-01,  5.6758e-01],\n",
      "        [-2.0447e+00,  9.7556e-01],\n",
      "        [ 5.3390e-01, -1.4590e+00],\n",
      "        [ 4.4972e-01, -5.8212e-01],\n",
      "        [ 7.5275e-01,  1.9417e-01],\n",
      "        [-1.3252e+00, -2.6195e+00],\n",
      "        [-4.1462e-01,  1.7665e+00],\n",
      "        [ 1.0268e+00, -1.3073e+00],\n",
      "        [-2.0749e+00,  8.7821e-01],\n",
      "        [ 1.0238e-01, -7.6931e-01],\n",
      "        [ 6.3866e-01,  4.0444e-01],\n",
      "        [-3.0610e-01,  2.5463e+00],\n",
      "        [ 1.3117e+00,  2.3220e-01],\n",
      "        [-3.7659e-01,  7.6812e-01],\n",
      "        [ 6.2451e-01,  6.8784e-01],\n",
      "        [ 5.5592e-01,  6.1690e-01],\n",
      "        [-2.9711e-02, -6.5632e-01],\n",
      "        [-4.8177e-01, -1.3790e-01],\n",
      "        [ 8.6262e-01,  4.8282e-01],\n",
      "        [-4.1996e-01,  1.5056e-02],\n",
      "        [-2.7847e-01,  9.2904e-01],\n",
      "        [-1.3110e+00,  1.2586e+00],\n",
      "        [ 9.9107e-01,  1.5443e-02],\n",
      "        [ 1.6000e-01, -3.0860e-01],\n",
      "        [-5.0906e-01, -4.2131e-01],\n",
      "        [ 1.2760e+00, -1.2241e-01],\n",
      "        [-7.6824e-01, -4.7724e-01],\n",
      "        [ 3.1860e-01, -3.1138e-01],\n",
      "        [-1.1175e-01,  4.1984e-02],\n",
      "        [ 1.3371e+00, -4.6762e-02],\n",
      "        [-2.5999e-01, -3.9127e-01],\n",
      "        [ 7.3837e-01,  9.1333e-01],\n",
      "        [-2.2829e-01,  2.7306e-01],\n",
      "        [ 4.3046e-01,  7.7602e-01],\n",
      "        [-1.4793e-01, -2.5101e-01],\n",
      "        [ 3.7506e-01,  6.9727e-02],\n",
      "        [-3.2302e-01, -1.3664e+00],\n",
      "        [ 1.5524e-01,  2.5762e-01],\n",
      "        [-2.0634e-02, -1.8434e-01],\n",
      "        [-6.4442e-01, -2.5211e-01],\n",
      "        [ 2.9428e-01, -7.1518e-01],\n",
      "        [ 9.4804e-01, -7.4339e-01],\n",
      "        [-9.3853e-01, -1.1333e+00],\n",
      "        [-6.2362e-01,  1.6615e-01],\n",
      "        [-4.2392e-01, -1.6634e-01],\n",
      "        [ 1.7126e-01,  1.1515e-01],\n",
      "        [ 1.0945e+00, -1.4108e+00],\n",
      "        [-8.1268e-01, -2.0279e-01],\n",
      "        [-2.9319e+00,  1.3458e+00],\n",
      "        [ 1.2532e+00, -6.3527e-01],\n",
      "        [ 2.7355e-01,  3.1446e-01],\n",
      "        [-9.3124e-01, -3.2461e-01],\n",
      "        [ 5.3469e-01,  4.2309e-01],\n",
      "        [ 8.6998e-01,  4.4893e-01],\n",
      "        [-5.5638e-02,  1.3583e+00],\n",
      "        [-3.5787e-01,  1.2520e+00],\n",
      "        [ 6.0699e-01, -9.3687e-01],\n",
      "        [-9.9120e-01, -8.8488e-01],\n",
      "        [ 2.3007e-01, -3.6562e-01],\n",
      "        [ 9.2854e-01,  3.3058e-01],\n",
      "        [ 3.7737e-01, -9.6971e-01],\n",
      "        [-4.2488e-02, -2.4014e-01],\n",
      "        [ 6.3781e-01,  7.4564e-01],\n",
      "        [-2.7258e-01, -9.1754e-01],\n",
      "        [-9.6705e-01,  3.4631e-01],\n",
      "        [ 4.1104e-01,  1.0855e-01],\n",
      "        [ 2.9148e-01, -6.2444e-02],\n",
      "        [ 6.0941e-01,  9.7068e-02],\n",
      "        [ 6.8438e-01,  6.5981e-01],\n",
      "        [ 1.3179e+00, -1.2705e+00],\n",
      "        [ 7.8159e-01, -1.1480e-01],\n",
      "        [-1.3956e-01, -4.6230e-01],\n",
      "        [ 6.0580e-01, -1.4147e+00],\n",
      "        [-1.1874e+00, -1.3875e-01],\n",
      "        [-3.1932e-01, -1.8164e-01],\n",
      "        [ 2.0507e-01, -4.7638e-01],\n",
      "        [ 1.1221e+00, -6.7529e-01],\n",
      "        [ 1.4556e+00, -2.4222e-01],\n",
      "        [-4.4650e-01,  3.9734e-01],\n",
      "        [ 1.1537e-01,  2.4992e-01],\n",
      "        [ 4.2352e-01, -4.7811e-01],\n",
      "        [ 9.2842e-01, -3.4773e-01],\n",
      "        [-3.8985e-01,  8.2637e-01],\n",
      "        [ 9.5329e-03, -1.0030e+00],\n",
      "        [-5.6555e-01,  3.6169e-01],\n",
      "        [-1.3458e+00,  1.4875e+00],\n",
      "        [ 1.1230e+00, -1.1695e+00],\n",
      "        [-5.7618e-01,  2.3565e-01],\n",
      "        [ 2.0786e-01, -7.9464e-01],\n",
      "        [ 9.5684e-01, -1.6843e+00],\n",
      "        [-8.3584e-01,  4.3240e-02],\n",
      "        [-3.5684e-01, -9.7349e-01],\n",
      "        [-8.8971e-01,  3.4839e-01],\n",
      "        [ 1.1464e+00, -2.6312e+00],\n",
      "        [-2.9311e-01, -8.9701e-01],\n",
      "        [ 4.9705e-01, -1.9394e-01],\n",
      "        [-9.1441e-02, -9.2894e-03],\n",
      "        [-4.4331e-01,  1.2552e+00],\n",
      "        [-5.0179e-01, -6.2767e-01],\n",
      "        [ 8.2031e-01,  4.4935e-01],\n",
      "        [-4.1801e-02, -7.1566e-02],\n",
      "        [ 6.9032e-02, -3.2554e-01],\n",
      "        [ 1.1708e+00, -2.6238e-01],\n",
      "        [ 3.2929e-01,  8.5959e-01],\n",
      "        [ 9.8354e-01, -3.1573e-01],\n",
      "        [ 5.4365e-01,  3.2840e-01],\n",
      "        [-6.1461e-01,  9.6090e-01],\n",
      "        [ 1.0361e+00,  7.3195e-01],\n",
      "        [ 2.5531e-01, -4.4442e-01],\n",
      "        [ 1.4334e-01, -1.0304e+00],\n",
      "        [ 8.4450e-01,  5.9509e-01],\n",
      "        [ 3.9490e-01,  3.1352e-01],\n",
      "        [ 8.4409e-01,  4.8053e-01],\n",
      "        [ 1.0291e+00,  1.6980e-01],\n",
      "        [-4.2826e-01,  1.0152e+00],\n",
      "        [ 5.5644e-01,  4.8104e-01],\n",
      "        [ 1.1896e+00,  4.1602e-01],\n",
      "        [-2.3834e+00, -2.2802e+00],\n",
      "        [ 3.2299e-01, -1.6744e+00],\n",
      "        [ 5.4068e-03, -3.5768e-01],\n",
      "        [ 1.1738e+00, -1.3139e+00],\n",
      "        [ 2.8543e-01, -3.3796e-01],\n",
      "        [ 2.8410e-01, -1.3709e-01],\n",
      "        [ 1.3725e+00, -4.3042e-01],\n",
      "        [ 2.0272e-01,  2.5451e-01],\n",
      "        [ 4.3975e-01, -1.5856e+00],\n",
      "        [ 7.2959e-01,  5.2939e-01],\n",
      "        [ 7.7684e-01,  2.0830e-01],\n",
      "        [ 4.6702e-01,  6.5715e-01],\n",
      "        [-2.9573e-02,  9.3429e-01],\n",
      "        [ 1.0372e+00,  1.3028e-01],\n",
      "        [ 2.1532e-03, -2.6564e-01],\n",
      "        [-2.7422e+00, -1.0222e+00],\n",
      "        [ 8.1713e-02, -3.9610e-01],\n",
      "        [ 2.4009e-01, -5.6888e-01],\n",
      "        [ 9.5679e-02,  9.0673e-01],\n",
      "        [ 1.2999e+00, -1.2569e-01],\n",
      "        [ 6.8367e-02,  3.8067e-01],\n",
      "        [-3.7957e-01, -1.2659e+00],\n",
      "        [-1.4843e-01, -3.4069e-01],\n",
      "        [ 7.1113e-01, -2.0610e+00],\n",
      "        [ 3.4298e-01, -5.5638e-01],\n",
      "        [ 9.5189e-01,  4.4449e-01],\n",
      "        [ 9.9327e-01, -3.5096e-01]], device='cuda:0')\n",
      "Action space size: 850\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 10/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -1.5961724146800005\n",
      "Size of input data: torch.Size([193, 2])\n",
      "Size of embeddings: torch.Size([193, 2])\n",
      "Embeddings: tensor([[-2.7852e+00,  3.6138e+00],\n",
      "        [-2.2329e+00,  3.9365e+00],\n",
      "        [-3.7553e+00,  3.9048e+00],\n",
      "        [-2.4852e+00,  3.9080e+00],\n",
      "        [ 1.5170e+00, -2.1956e-01],\n",
      "        [ 1.0095e+00,  2.5985e-02],\n",
      "        [-4.8923e-01,  5.2163e-01],\n",
      "        [ 4.0457e-01,  3.9326e-01],\n",
      "        [-1.5706e+00, -4.2419e-01],\n",
      "        [ 8.8214e-01, -1.1680e+00],\n",
      "        [-5.0668e-01, -6.3682e-01],\n",
      "        [-5.8353e-01,  1.1855e+00],\n",
      "        [-7.3900e-01, -6.9315e-01],\n",
      "        [ 8.6881e-01, -7.6396e-01],\n",
      "        [ 5.3811e-01,  1.9140e-01],\n",
      "        [-9.8321e-01, -1.0622e+00],\n",
      "        [-5.5353e-01, -3.3472e-02],\n",
      "        [ 1.5655e-01,  4.6368e-02],\n",
      "        [-3.5864e-01,  1.0363e+00],\n",
      "        [-8.5270e-01,  6.6378e-01],\n",
      "        [ 1.2535e+00,  5.9172e-01],\n",
      "        [ 7.8249e-01, -6.6137e-01],\n",
      "        [-1.4669e-01,  9.9572e-01],\n",
      "        [-3.0276e-01, -9.0512e-01],\n",
      "        [-2.0267e+00,  6.3067e-02],\n",
      "        [-1.0237e+00, -1.5416e-01],\n",
      "        [-1.0952e+00,  1.0756e+00],\n",
      "        [-1.3459e+00,  1.1593e+00],\n",
      "        [ 4.2545e-01,  6.2370e-01],\n",
      "        [-5.1045e-01,  5.7493e-01],\n",
      "        [ 6.4312e-01,  8.5066e-01],\n",
      "        [-2.2650e+00,  1.8360e+00],\n",
      "        [ 4.2602e-01, -1.0401e+00],\n",
      "        [ 1.1084e-03, -3.8635e-01],\n",
      "        [ 4.1918e-01, -1.5118e-02],\n",
      "        [ 5.2673e-01, -1.5140e+00],\n",
      "        [ 1.0122e+00,  1.1865e+00],\n",
      "        [ 2.5214e-01, -5.2405e-01],\n",
      "        [-2.4311e+00,  1.4569e+00],\n",
      "        [ 8.2274e-01, -1.2563e+00],\n",
      "        [ 1.4526e+00, -2.5127e-02],\n",
      "        [-8.0892e-02,  1.3068e+00],\n",
      "        [ 5.5027e-01, -2.8795e-01],\n",
      "        [-4.1308e-01,  1.2261e+00],\n",
      "        [ 7.1891e-01,  4.9306e-01],\n",
      "        [ 2.0500e-01, -1.3509e-01],\n",
      "        [ 7.9244e-02, -9.2491e-01],\n",
      "        [-1.1980e+00, -8.7602e-01],\n",
      "        [ 3.3115e-01, -6.1511e-01],\n",
      "        [-1.9859e-01,  3.8210e-01],\n",
      "        [-6.6450e-01,  7.7603e-01],\n",
      "        [ 1.0676e+00, -1.0768e+00],\n",
      "        [ 5.8242e-01, -3.7526e-01],\n",
      "        [ 5.7878e-02,  3.6512e-01],\n",
      "        [ 3.3959e-01, -1.1324e+00],\n",
      "        [-2.1815e-01, -1.5280e+00],\n",
      "        [-1.0640e+00, -8.4161e-01],\n",
      "        [ 2.5070e-01, -1.2823e-01],\n",
      "        [-6.0669e-01, -1.1779e-01],\n",
      "        [ 6.2634e-01, -2.2797e-02],\n",
      "        [-4.8438e-01, -2.2926e-01],\n",
      "        [ 4.4290e-01,  1.1479e+00],\n",
      "        [-9.2354e-01,  1.7270e-01],\n",
      "        [ 4.8638e-01,  1.3221e+00],\n",
      "        [ 1.0365e+00, -2.6738e-01],\n",
      "        [ 2.8963e-01, -5.0795e-01],\n",
      "        [-1.1329e+00, -1.3934e+00],\n",
      "        [-7.0584e-01,  8.3284e-01],\n",
      "        [-5.3193e-02, -7.1672e-01],\n",
      "        [-6.1388e-01, -7.6695e-01],\n",
      "        [ 1.9221e+00, -4.6380e-01],\n",
      "        [ 2.0538e-01, -7.7995e-01],\n",
      "        [-4.5170e-01,  1.3768e-01],\n",
      "        [-1.1179e+00,  4.1234e-01],\n",
      "        [-1.0503e+00, -8.5618e-01],\n",
      "        [-3.3924e-01,  3.6200e-01],\n",
      "        [ 3.8353e-01, -1.2766e+00],\n",
      "        [-1.2995e+00,  4.5297e-01],\n",
      "        [-2.6141e+00,  1.2660e+00],\n",
      "        [ 6.8309e-01, -1.0228e+00],\n",
      "        [ 3.5826e-02,  4.6711e-01],\n",
      "        [-8.8146e-01,  1.1451e+00],\n",
      "        [ 6.7503e-02,  3.7814e-01],\n",
      "        [ 8.0811e-01,  3.0410e-01],\n",
      "        [ 4.6412e-01, -1.0940e+00],\n",
      "        [-6.6767e-01,  1.5436e+00],\n",
      "        [ 9.3351e-01, -1.3436e+00],\n",
      "        [-1.1500e+00, -6.7959e-01],\n",
      "        [ 3.5012e-01,  1.6630e-01],\n",
      "        [ 8.2133e-01, -1.1709e-01],\n",
      "        [ 9.6527e-01, -9.3603e-01],\n",
      "        [ 5.9119e-01,  1.4366e-01],\n",
      "        [-1.6090e-01, -3.2263e-01],\n",
      "        [-7.3602e-02, -1.4059e+00],\n",
      "        [-1.2229e+00,  1.0139e+00],\n",
      "        [ 2.6478e-01,  8.6142e-01],\n",
      "        [-2.9981e-01,  5.4910e-01],\n",
      "        [ 6.3051e-01,  6.7177e-02],\n",
      "        [ 5.2387e-01,  1.5088e-01],\n",
      "        [ 2.6141e-01, -7.5583e-01],\n",
      "        [ 6.1585e-01,  3.4542e-02],\n",
      "        [ 3.5570e-01, -1.8785e-01],\n",
      "        [ 1.8344e-01, -9.5990e-01],\n",
      "        [-5.4819e-01, -1.1379e-01],\n",
      "        [ 2.8629e-01, -2.3549e-01],\n",
      "        [ 4.4058e-01, -4.4302e-01],\n",
      "        [ 5.4838e-01, -8.3571e-01],\n",
      "        [ 1.5831e+00, -1.4407e+00],\n",
      "        [-5.3996e-01,  7.9752e-01],\n",
      "        [-2.9370e-01, -2.1048e-01],\n",
      "        [-3.7764e-01,  4.9458e-01],\n",
      "        [ 6.7391e-01, -6.5104e-01],\n",
      "        [-1.0521e+00,  1.2779e+00],\n",
      "        [ 1.2223e-01, -1.3831e+00],\n",
      "        [-9.2841e-01,  1.4504e-01],\n",
      "        [-1.4699e+00,  6.5739e-01],\n",
      "        [ 5.4702e-01, -1.1877e+00],\n",
      "        [-1.1645e+00, -1.3051e+00],\n",
      "        [ 2.9280e-01, -2.7151e-01],\n",
      "        [ 3.5077e-01, -1.3771e+00],\n",
      "        [-8.5513e-01,  7.7171e-01],\n",
      "        [-1.1225e+00, -7.8546e-01],\n",
      "        [-1.3440e+00,  5.0630e-01],\n",
      "        [ 8.5242e-01, -2.4743e+00],\n",
      "        [ 1.1269e+00, -8.3430e-01],\n",
      "        [ 1.1806e+00, -2.4215e-01],\n",
      "        [-6.1825e-01,  4.2858e-01],\n",
      "        [ 2.6535e-01,  1.2451e+00],\n",
      "        [ 7.5737e-01, -7.0789e-01],\n",
      "        [ 8.4883e-01, -1.1515e+00],\n",
      "        [-6.9512e-01,  4.6763e-01],\n",
      "        [ 8.0160e-03,  5.2728e-01],\n",
      "        [ 9.1638e-01,  1.6483e-02],\n",
      "        [-1.4278e+00, -5.2716e-01],\n",
      "        [ 8.0590e-01, -2.4931e-01],\n",
      "        [-2.9946e-01,  5.6858e-01],\n",
      "        [-2.2917e+00,  1.0795e+00],\n",
      "        [ 1.3819e+00,  5.2860e-01],\n",
      "        [ 1.9623e+00, -1.5685e+00],\n",
      "        [ 4.8984e-02, -1.1359e+00],\n",
      "        [ 1.4934e+00,  3.9458e-01],\n",
      "        [ 2.5494e-01,  6.0298e-01],\n",
      "        [-4.0941e-01, -5.2435e-01],\n",
      "        [ 6.8697e-01,  1.5669e-01],\n",
      "        [ 2.1096e-02,  1.3797e+00],\n",
      "        [ 1.2453e-01,  8.2438e-01],\n",
      "        [ 6.5491e-01, -2.3972e-01],\n",
      "        [-4.1799e+00,  2.6002e+00],\n",
      "        [ 1.5709e-01, -1.0708e+00],\n",
      "        [ 1.0568e+00, -5.5603e-01],\n",
      "        [ 4.9482e-04, -8.7713e-01],\n",
      "        [ 1.9695e-01,  5.3530e-01],\n",
      "        [ 9.6214e-01, -5.7694e-01],\n",
      "        [ 9.2328e-01, -6.1772e-01],\n",
      "        [ 8.7945e-01, -2.0458e-01],\n",
      "        [ 2.9144e-01, -7.9671e-01],\n",
      "        [ 6.6062e-01,  5.8187e-01],\n",
      "        [ 9.2278e-01, -4.5619e-01],\n",
      "        [ 4.4676e-01,  1.8483e-01],\n",
      "        [-4.2259e-01,  8.7003e-01],\n",
      "        [ 8.1350e-01, -3.4796e-01],\n",
      "        [-8.4423e-02,  2.5816e-01],\n",
      "        [-1.2213e+00,  9.3849e-01],\n",
      "        [ 1.0558e+00, -5.9497e-01],\n",
      "        [ 1.3796e+00, -6.0823e-01],\n",
      "        [ 1.0682e+00,  1.2084e+00],\n",
      "        [ 1.6041e+00, -1.0502e+00],\n",
      "        [ 3.4414e-01, -3.5736e-01],\n",
      "        [ 2.2230e-01, -1.1435e+00],\n",
      "        [-7.7900e-01, -1.0741e+00],\n",
      "        [-9.9459e-03, -1.1371e+00],\n",
      "        [-4.7381e-01, -2.6869e-01],\n",
      "        [ 7.7326e-01,  3.3815e-01],\n",
      "        [ 1.0080e+00, -1.4339e+00],\n",
      "        [ 7.4431e-01, -8.0250e-01],\n",
      "        [ 4.2182e-01,  1.8993e-01],\n",
      "        [ 8.2642e-01,  6.2028e-01],\n",
      "        [-3.9027e-01,  5.6589e-01],\n",
      "        [ 1.5288e+00, -1.0130e+00],\n",
      "        [-9.5344e-01,  7.1964e-01],\n",
      "        [ 2.0529e-01,  1.1859e+00],\n",
      "        [ 1.0354e+00, -5.8396e-02],\n",
      "        [-5.4676e-01, -2.8588e-01],\n",
      "        [ 5.0567e-01, -3.5549e-01],\n",
      "        [ 1.5462e-01,  4.1258e-01],\n",
      "        [-6.1142e-02,  9.0353e-01],\n",
      "        [ 1.5618e+00, -1.1923e-01],\n",
      "        [ 5.1395e-01, -1.1283e+00],\n",
      "        [ 3.6948e-02, -2.0777e-01],\n",
      "        [ 9.0510e-01,  7.0232e-01],\n",
      "        [ 1.0123e+00,  4.2732e-01],\n",
      "        [-1.3006e+00,  6.2464e-01],\n",
      "        [ 6.1085e-01, -1.3936e+00]], device='cuda:0')\n",
      "Action space size: 945\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 11/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -1.4365551732120005\n",
      "Size of input data: torch.Size([213, 2])\n",
      "Size of embeddings: torch.Size([213, 2])\n",
      "Embeddings: tensor([[-3.1665e+00,  2.8366e+00],\n",
      "        [-2.8762e+00,  4.0903e+00],\n",
      "        [-4.3910e+00,  3.5198e+00],\n",
      "        [-3.5847e+00,  3.8118e+00],\n",
      "        [ 1.0643e-01, -7.8856e-02],\n",
      "        [ 1.4912e-01, -2.7757e-01],\n",
      "        [ 1.9729e-01,  8.3801e-03],\n",
      "        [ 9.3725e-01,  1.7789e-01],\n",
      "        [-1.5886e+00, -2.1989e-01],\n",
      "        [ 1.2056e+00,  3.3021e-02],\n",
      "        [-3.5683e-01, -4.0454e-01],\n",
      "        [-1.0099e+00,  1.3732e+00],\n",
      "        [-2.6243e-02, -1.9870e+00],\n",
      "        [ 8.1273e-01,  3.6407e-01],\n",
      "        [-4.6378e-01, -7.5635e-02],\n",
      "        [-8.0474e-01, -6.1102e-01],\n",
      "        [-6.0471e-01, -6.7017e-01],\n",
      "        [ 4.3015e-01,  6.7926e-01],\n",
      "        [-2.9605e+00,  1.9592e+00],\n",
      "        [ 5.6625e-01, -5.0717e-01],\n",
      "        [ 4.9138e-01,  3.8844e-01],\n",
      "        [ 1.0980e+00,  5.3705e-02],\n",
      "        [-2.5707e-01,  8.9683e-01],\n",
      "        [ 4.9964e-01, -1.7947e+00],\n",
      "        [-3.7385e+00,  2.3584e-01],\n",
      "        [-1.1131e+00, -6.0738e-01],\n",
      "        [-4.8137e-01,  4.5541e-01],\n",
      "        [-1.5209e+00,  3.2251e-01],\n",
      "        [ 6.7888e-01,  8.5264e-02],\n",
      "        [ 1.1436e-01, -2.9201e-01],\n",
      "        [-1.2462e-01,  3.3610e-01],\n",
      "        [-1.3931e+00,  9.0784e-01],\n",
      "        [ 4.8437e-01, -1.0101e+00],\n",
      "        [ 2.8288e-01, -1.7600e-01],\n",
      "        [ 4.1616e-01,  4.5686e-01],\n",
      "        [ 1.1824e+00, -1.8658e+00],\n",
      "        [-2.9836e+00,  1.4670e+00],\n",
      "        [ 6.5836e-01, -2.1851e-01],\n",
      "        [-1.5887e+00,  5.7120e-01],\n",
      "        [ 4.7710e-02, -1.0335e+00],\n",
      "        [ 1.0866e+00,  1.7224e-01],\n",
      "        [-1.7176e+00,  1.7530e+00],\n",
      "        [ 9.1240e-01,  3.3630e-01],\n",
      "        [-9.9030e-01,  4.4427e-01],\n",
      "        [ 7.9236e-03,  4.4009e-01],\n",
      "        [ 7.9815e-03,  6.9467e-01],\n",
      "        [-2.3593e-01, -8.2392e-01],\n",
      "        [-4.0326e-01, -1.3749e-01],\n",
      "        [ 1.3914e-01,  4.6128e-01],\n",
      "        [ 3.5910e-02, -7.4525e-01],\n",
      "        [-7.9296e-01,  5.9111e-01],\n",
      "        [-2.0172e+00,  7.3419e-02],\n",
      "        [ 3.3164e-01, -2.7158e-01],\n",
      "        [ 6.8149e-01, -5.4910e-01],\n",
      "        [ 1.2920e-01, -6.2254e-01],\n",
      "        [ 2.6385e-01, -2.6685e-01],\n",
      "        [-1.6226e+00, -4.2679e-01],\n",
      "        [-5.1039e-02, -3.8757e-01],\n",
      "        [ 1.6784e-01, -3.4039e-01],\n",
      "        [ 5.5541e-01,  9.0530e-01],\n",
      "        [ 1.0864e-01, -7.5291e-01],\n",
      "        [-1.2017e-01,  7.4163e-01],\n",
      "        [-4.7572e-01, -1.8119e-01],\n",
      "        [-3.6700e-01,  5.6315e-01],\n",
      "        [ 4.5794e-01,  5.7188e-01],\n",
      "        [ 2.9220e-01,  3.1556e-01],\n",
      "        [-6.1786e-01, -8.7013e-01],\n",
      "        [-2.4991e-01,  5.3493e-01],\n",
      "        [-2.6949e-01, -2.4857e-01],\n",
      "        [-1.0808e+00, -3.4399e-01],\n",
      "        [ 7.8349e-01, -1.0339e+00],\n",
      "        [ 4.3769e-01,  2.5774e-01],\n",
      "        [ 2.4186e-01, -1.5405e+00],\n",
      "        [-4.8891e-01, -4.1010e-01],\n",
      "        [-1.1347e+00, -2.7877e-01],\n",
      "        [ 3.2839e-01,  9.4823e-01],\n",
      "        [ 7.9169e-01, -1.2258e+00],\n",
      "        [-1.5882e-01, -5.2381e-01],\n",
      "        [-2.3886e+00,  7.0024e-01],\n",
      "        [ 8.8744e-01,  2.7169e-01],\n",
      "        [ 4.4398e-01, -2.6833e-02],\n",
      "        [-4.2469e-01, -2.0347e-01],\n",
      "        [-3.7095e-03,  4.2301e-01],\n",
      "        [ 5.3981e-01,  5.5994e-01],\n",
      "        [-1.9995e+00, -1.1981e+00],\n",
      "        [-9.1373e-01,  7.3950e-01],\n",
      "        [ 1.2707e+00, -1.0593e+00],\n",
      "        [ 3.3897e-01, -1.1368e+00],\n",
      "        [-6.0959e-01,  4.3392e-01],\n",
      "        [ 9.1707e-01, -1.3059e-02],\n",
      "        [ 4.0419e-01, -7.8063e-01],\n",
      "        [ 7.4633e-01,  1.0794e-01],\n",
      "        [-1.2333e-01,  6.0819e-01],\n",
      "        [ 4.0224e-01, -9.5680e-01],\n",
      "        [-6.2810e-01,  3.9594e-01],\n",
      "        [ 1.4588e-01,  7.7688e-01],\n",
      "        [-4.0139e-01, -4.3293e-01],\n",
      "        [ 4.0902e-02,  2.2057e-01],\n",
      "        [-7.7182e-01,  7.9348e-01],\n",
      "        [ 1.0763e+00, -1.5077e+00],\n",
      "        [ 1.3114e-01,  2.0351e-01],\n",
      "        [ 5.1448e-01, -3.6049e-01],\n",
      "        [ 1.7763e-01, -1.0764e+00],\n",
      "        [-7.1919e-01, -1.4327e+00],\n",
      "        [-8.8266e-02,  6.3083e-01],\n",
      "        [ 2.5678e-01,  4.9650e-01],\n",
      "        [ 9.7360e-01,  4.8013e-01],\n",
      "        [ 1.2350e+00, -1.0790e+00],\n",
      "        [ 2.3505e-02,  3.2471e-01],\n",
      "        [ 3.0190e-01, -2.0420e-01],\n",
      "        [ 6.1951e-01, -3.1413e-01],\n",
      "        [ 9.0411e-01, -1.2288e-01],\n",
      "        [ 2.0939e-01,  3.7885e-01],\n",
      "        [-3.1199e-01, -7.5941e-01],\n",
      "        [-8.0636e-01, -6.7792e-02],\n",
      "        [-1.8872e+00,  1.2161e+00],\n",
      "        [ 8.7592e-01, -9.2376e-01],\n",
      "        [-3.3866e-01, -8.2442e-01],\n",
      "        [-4.3440e-01,  1.6823e-01],\n",
      "        [ 5.1577e-01, -7.1811e-01],\n",
      "        [-7.9930e-01,  6.1329e-01],\n",
      "        [ 4.0070e-01, -1.1311e+00],\n",
      "        [-1.0033e+00,  2.3112e-01],\n",
      "        [ 1.3489e+00, -2.8228e+00],\n",
      "        [-1.4376e+00, -4.7537e-01],\n",
      "        [ 3.2435e-01, -5.4424e-02],\n",
      "        [ 4.1878e-01, -1.0867e-01],\n",
      "        [-1.9624e+00,  1.3186e+00],\n",
      "        [-1.4059e+00, -3.6687e-01],\n",
      "        [ 2.3497e-01, -4.3061e-01],\n",
      "        [ 3.6736e-01, -1.2566e-01],\n",
      "        [ 6.3450e-01, -5.6192e-01],\n",
      "        [ 6.7441e-01,  8.1682e-01],\n",
      "        [ 4.4279e-01,  4.6273e-02],\n",
      "        [ 5.7991e-01,  4.5818e-01],\n",
      "        [-8.0108e-01,  1.5362e+00],\n",
      "        [-7.8541e-01,  1.1423e+00],\n",
      "        [ 8.2301e-01,  4.8696e-01],\n",
      "        [-3.2076e-01, -1.4396e+00],\n",
      "        [ 2.1798e-01, -6.1956e-01],\n",
      "        [ 1.2406e+00,  1.3930e-01],\n",
      "        [ 5.9208e-01,  2.4454e-01],\n",
      "        [ 9.2081e-01,  5.9138e-01],\n",
      "        [ 4.4482e-01, -1.0327e-01],\n",
      "        [-2.1310e+00,  1.2250e+00],\n",
      "        [ 1.1282e+00,  3.4911e-01],\n",
      "        [ 4.5341e-01,  8.3629e-02],\n",
      "        [ 1.4948e+00,  6.0058e+00],\n",
      "        [ 6.9258e-01, -1.5734e+00],\n",
      "        [ 7.3598e-01, -8.1062e-01],\n",
      "        [ 8.5749e-01, -1.4388e+00],\n",
      "        [ 8.8607e-01, -6.9423e-01],\n",
      "        [ 1.7246e-01, -2.2735e-01],\n",
      "        [ 6.9423e-01,  3.2972e-01],\n",
      "        [ 8.6567e-01,  1.1103e-01],\n",
      "        [-7.9260e-02, -3.4865e-01],\n",
      "        [ 1.0281e-01,  4.3308e-01],\n",
      "        [ 1.1967e+00,  1.3466e-01],\n",
      "        [ 3.8809e-01,  1.8516e-01],\n",
      "        [-3.4891e-01,  1.7580e+00],\n",
      "        [ 2.2787e-02, -2.6037e-01],\n",
      "        [ 2.2616e-01, -3.9892e-01],\n",
      "        [ 2.0810e-02, -4.7683e-01],\n",
      "        [ 4.1037e-01, -3.3462e-01],\n",
      "        [ 8.4766e-01, -4.5521e-01],\n",
      "        [ 7.7804e-01,  7.6280e-01],\n",
      "        [ 4.2062e-01, -2.7545e-01],\n",
      "        [-3.7965e-02,  4.4029e-01],\n",
      "        [ 1.9061e-01, -1.1974e+00],\n",
      "        [-8.0626e-01, -6.9409e-01],\n",
      "        [ 3.1665e-01, -8.5722e-01],\n",
      "        [ 1.2403e-01, -9.4025e-01],\n",
      "        [ 5.1291e-01,  4.5455e-01],\n",
      "        [ 8.7747e-01, -2.6851e-01],\n",
      "        [ 9.9388e-01,  6.1894e-01],\n",
      "        [-3.6234e-01, -2.1748e-01],\n",
      "        [ 1.1018e+00,  8.9909e-02],\n",
      "        [ 9.0237e-01, -6.5919e-01],\n",
      "        [ 1.4415e+00, -4.0262e-01],\n",
      "        [-7.8841e-01, -1.2499e-01],\n",
      "        [ 3.1808e-01,  3.4710e-01],\n",
      "        [ 7.1654e-01,  1.4812e-01],\n",
      "        [-2.9401e-01, -1.4002e+00],\n",
      "        [-1.2954e-01,  1.0243e-01],\n",
      "        [-1.7550e-01,  3.2754e-01],\n",
      "        [ 7.0769e-01,  1.7364e-01],\n",
      "        [ 9.2797e-01, -3.2871e-01],\n",
      "        [-7.5094e-01,  1.2666e-02],\n",
      "        [ 1.8135e-01, -6.3126e-01],\n",
      "        [ 7.4679e-01,  5.3992e-01],\n",
      "        [ 4.7822e-01,  3.4874e-01],\n",
      "        [-2.0969e+00,  2.2786e+00],\n",
      "        [-1.6695e-01, -9.2282e-01],\n",
      "        [ 6.3686e-01,  6.4086e-01],\n",
      "        [ 9.3370e-01, -3.3233e-02],\n",
      "        [ 8.2325e-01, -2.0158e-01],\n",
      "        [ 7.1820e-01,  2.0250e-01],\n",
      "        [ 2.9148e-02, -4.1656e-01],\n",
      "        [-9.9647e-02, -1.9523e+00],\n",
      "        [ 4.6953e-01,  2.0728e-01],\n",
      "        [ 6.3434e-01, -4.5575e-01],\n",
      "        [ 1.0031e+00, -1.0720e+00],\n",
      "        [ 9.0889e-01, -6.6734e-01],\n",
      "        [ 8.8024e-01, -8.1560e-01],\n",
      "        [ 1.1620e+00, -8.8879e-03],\n",
      "        [ 6.2499e-01, -3.9222e-01],\n",
      "        [ 7.3800e-01, -1.6545e+00],\n",
      "        [ 8.7071e-01,  8.1506e-02],\n",
      "        [ 5.6871e-01,  8.7357e-01],\n",
      "        [ 1.2498e+00, -1.4055e+00],\n",
      "        [ 2.8863e-01, -5.5199e-01],\n",
      "        [-4.9547e-01,  6.6205e-01],\n",
      "        [ 7.4655e-01,  4.9749e-01]], device='cuda:0')\n",
      "Action space size: 1045\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 12/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -1.2928996558908004\n",
      "Size of input data: torch.Size([228, 2])\n",
      "Size of embeddings: torch.Size([228, 2])\n",
      "Embeddings: tensor([[-3.9345,  3.2971],\n",
      "        [-3.4868,  3.6857],\n",
      "        [-4.9266,  4.2116],\n",
      "        [-4.1865,  3.8586],\n",
      "        [ 0.5669, -0.3342],\n",
      "        [-0.3316, -0.5471],\n",
      "        [ 0.7125,  0.5345],\n",
      "        [ 0.8187,  0.5172],\n",
      "        [-0.2619,  0.0565],\n",
      "        [ 0.0794, -0.3543],\n",
      "        [-0.0489, -0.5925],\n",
      "        [-0.4682,  1.3577],\n",
      "        [-0.0851, -0.2195],\n",
      "        [-0.2589, -0.6223],\n",
      "        [ 1.0298,  0.8415],\n",
      "        [-0.2075, -1.0408],\n",
      "        [ 0.7978,  0.5044],\n",
      "        [ 0.7024, -0.1798],\n",
      "        [-2.9765,  1.0358],\n",
      "        [ 0.2732,  0.2442],\n",
      "        [ 1.0510,  0.6288],\n",
      "        [ 0.1980, -0.4251],\n",
      "        [-0.2900,  1.3457],\n",
      "        [-0.1866, -0.3145],\n",
      "        [-2.8787,  0.6757],\n",
      "        [-0.4670, -0.6393],\n",
      "        [-1.8832,  0.6924],\n",
      "        [-1.9675,  1.8142],\n",
      "        [ 0.3638, -0.0098],\n",
      "        [ 0.6594,  0.0817],\n",
      "        [ 0.7670,  0.3669],\n",
      "        [-2.3678,  1.3464],\n",
      "        [ 0.4873, -2.1184],\n",
      "        [ 0.3612, -0.6001],\n",
      "        [ 0.6979,  0.7443],\n",
      "        [ 0.4471, -0.5255],\n",
      "        [-1.1188,  0.4329],\n",
      "        [ 1.1282, -0.1358],\n",
      "        [-2.4137,  1.3996],\n",
      "        [ 0.4140, -1.0817],\n",
      "        [ 0.7384, -0.2800],\n",
      "        [-2.6178,  0.0213],\n",
      "        [ 0.4778,  0.4341],\n",
      "        [-0.3408,  1.2850],\n",
      "        [ 0.3812, -0.2670],\n",
      "        [ 0.1978, -0.5181],\n",
      "        [ 0.2442, -1.3407],\n",
      "        [ 0.1735, -0.3469],\n",
      "        [ 0.2564, -0.9610],\n",
      "        [ 1.0997,  0.4095],\n",
      "        [-0.9470, -0.0715],\n",
      "        [-0.7090, -0.1660],\n",
      "        [ 0.4786, -1.0091],\n",
      "        [ 0.0686, -0.1936],\n",
      "        [-0.2315, -1.7194],\n",
      "        [ 0.4281, -1.5236],\n",
      "        [-0.5177, -1.2382],\n",
      "        [-0.1295, -0.1127],\n",
      "        [-0.0758,  0.2896],\n",
      "        [ 0.3417,  0.3906],\n",
      "        [ 0.1287, -0.4290],\n",
      "        [ 0.9670,  0.3090],\n",
      "        [-0.1689,  0.2706],\n",
      "        [ 0.5905,  0.3053],\n",
      "        [-0.4432,  0.2818],\n",
      "        [-0.3841, -0.4562],\n",
      "        [-0.0377, -0.9000],\n",
      "        [ 0.0336, -0.0331],\n",
      "        [-0.0131,  0.0241],\n",
      "        [-0.0827, -0.3737],\n",
      "        [ 0.9705, -0.9922],\n",
      "        [ 0.4591, -0.4222],\n",
      "        [-0.5742,  0.6035],\n",
      "        [ 0.3577,  0.5727],\n",
      "        [-0.0456, -0.2780],\n",
      "        [ 0.2010,  0.5362],\n",
      "        [ 0.8089, -1.4883],\n",
      "        [-1.2536,  0.8196],\n",
      "        [-2.8047,  1.4305],\n",
      "        [ 0.9121, -0.0937],\n",
      "        [ 0.5163,  0.3065],\n",
      "        [-0.5396,  0.9615],\n",
      "        [ 0.9272, -0.3543],\n",
      "        [ 0.8352, -0.1875],\n",
      "        [-1.3388, -0.4249],\n",
      "        [-1.1866,  1.2710],\n",
      "        [ 0.6126, -0.9277],\n",
      "        [-1.2300,  0.2489],\n",
      "        [ 0.2156, -0.9309],\n",
      "        [ 0.6450,  0.3211],\n",
      "        [ 0.9619, -0.8098],\n",
      "        [ 0.9675,  0.5783],\n",
      "        [-0.2140,  0.1361],\n",
      "        [ 0.2949, -1.5458],\n",
      "        [-1.6420,  1.2474],\n",
      "        [-0.0233,  0.4119],\n",
      "        [ 0.2985,  0.0932],\n",
      "        [ 0.0249, -0.5718],\n",
      "        [ 0.3507,  0.5390],\n",
      "        [ 0.5091, -0.4208],\n",
      "        [ 0.2496,  0.3767],\n",
      "        [ 0.9185,  0.6862],\n",
      "        [ 0.5663, -0.9855],\n",
      "        [-0.2890, -0.5812],\n",
      "        [-0.4066,  0.3785],\n",
      "        [ 0.2374, -0.0939],\n",
      "        [ 0.5013,  0.1892],\n",
      "        [ 0.6649, -1.5236],\n",
      "        [-0.2537,  0.3406],\n",
      "        [ 0.1542, -0.0559],\n",
      "        [ 0.6714,  0.4553],\n",
      "        [ 0.2305, -0.6429],\n",
      "        [-0.7205,  0.5835],\n",
      "        [ 0.1996, -1.1095],\n",
      "        [-1.0073,  0.4240],\n",
      "        [-2.0257,  1.0773],\n",
      "        [ 0.4690, -1.3495],\n",
      "        [ 1.2205, -0.4233],\n",
      "        [ 0.3512, -1.2667],\n",
      "        [ 0.8052, -1.8347],\n",
      "        [-0.7518,  0.8580],\n",
      "        [-0.8821,  0.2136],\n",
      "        [-1.9896,  1.2832],\n",
      "        [ 0.1151, -2.7021],\n",
      "        [-0.3416, -1.1763],\n",
      "        [-0.1215, -0.4334],\n",
      "        [ 0.7401,  0.4336],\n",
      "        [-1.2021,  0.8485],\n",
      "        [-0.5377, -0.9865],\n",
      "        [-0.1136, -1.1521],\n",
      "        [ 0.6685,  0.4082],\n",
      "        [ 0.4406, -0.0662],\n",
      "        [ 0.7675,  1.0334],\n",
      "        [-0.2342,  0.2036],\n",
      "        [ 0.8205,  0.3551],\n",
      "        [-0.4013,  0.4180],\n",
      "        [-1.4604,  1.0688],\n",
      "        [ 0.8001,  0.8683],\n",
      "        [-0.3157, -1.3775],\n",
      "        [ 0.3264, -1.4305],\n",
      "        [ 1.1072,  0.1979],\n",
      "        [ 0.3082,  0.7500],\n",
      "        [-1.2797, -0.0395],\n",
      "        [ 0.4496, -0.1738],\n",
      "        [-1.4330,  0.8184],\n",
      "        [ 0.2300,  1.1316],\n",
      "        [ 0.7104, -0.7436],\n",
      "        [-0.4087,  2.9266],\n",
      "        [ 0.7634, -1.2037],\n",
      "        [ 0.2612, -1.3386],\n",
      "        [-0.2381, -0.9034],\n",
      "        [ 0.5447, -0.1166],\n",
      "        [ 0.3538, -0.7708],\n",
      "        [ 0.6521, -0.0268],\n",
      "        [ 0.9832,  0.3085],\n",
      "        [ 0.0445, -0.6851],\n",
      "        [ 0.7557, -0.0774],\n",
      "        [ 0.2741, -0.4484],\n",
      "        [ 0.5029,  0.4837],\n",
      "        [-1.3672,  1.6538],\n",
      "        [ 0.2604, -0.2727],\n",
      "        [-0.5887,  0.3626],\n",
      "        [-1.2545,  0.8688],\n",
      "        [ 0.2540, -0.6963],\n",
      "        [ 0.4317, -0.8146],\n",
      "        [ 0.0417,  0.1815],\n",
      "        [ 0.3929, -1.2979],\n",
      "        [-0.4482, -0.3364],\n",
      "        [-0.0475, -1.5055],\n",
      "        [ 0.4540, -0.5794],\n",
      "        [ 0.8486, -0.4406],\n",
      "        [ 1.0260, -0.7186],\n",
      "        [ 0.8076, -0.0877],\n",
      "        [ 0.2887, -0.7610],\n",
      "        [ 0.7854, -0.1901],\n",
      "        [ 0.8865,  0.5138],\n",
      "        [ 0.4426,  0.3749],\n",
      "        [ 0.1926, -0.0230],\n",
      "        [ 0.3528, -0.4839],\n",
      "        [-2.1831, -1.1204],\n",
      "        [ 0.6028,  1.6147],\n",
      "        [ 0.4884,  0.1763],\n",
      "        [ 0.0318, -0.6460],\n",
      "        [ 0.0242,  0.7049],\n",
      "        [-0.1541,  1.0121],\n",
      "        [ 0.5870,  0.4412],\n",
      "        [ 0.4646, -0.6116],\n",
      "        [-0.2276, -0.7295],\n",
      "        [ 0.9084,  0.0814],\n",
      "        [ 0.3391,  0.5111],\n",
      "        [ 0.4895,  0.1220],\n",
      "        [-2.5188,  1.1350],\n",
      "        [ 0.2349, -2.1314],\n",
      "        [ 0.4256,  0.3570],\n",
      "        [ 0.8761, -0.0189],\n",
      "        [ 0.5843,  0.2692],\n",
      "        [ 0.6411,  0.3339],\n",
      "        [ 1.6264, -2.7445],\n",
      "        [ 0.0822, -1.1776],\n",
      "        [ 0.8069,  0.4707],\n",
      "        [ 0.5393, -0.3467],\n",
      "        [ 0.8302, -0.2906],\n",
      "        [ 0.7015, -0.7272],\n",
      "        [ 0.4768, -1.8148],\n",
      "        [ 0.4481, -0.8095],\n",
      "        [ 0.4359,  0.0870],\n",
      "        [ 0.2547, -0.5072],\n",
      "        [ 0.5719, -1.0370],\n",
      "        [ 1.1435,  0.8411],\n",
      "        [ 0.6375, -1.4683],\n",
      "        [ 0.9353,  0.2244],\n",
      "        [-0.5432,  0.6576],\n",
      "        [-1.5115,  0.2924],\n",
      "        [ 0.2053,  1.5343],\n",
      "        [ 0.1416,  0.4046],\n",
      "        [ 1.0464,  1.1669],\n",
      "        [-0.0180,  0.3245],\n",
      "        [ 0.3589, -0.0338],\n",
      "        [ 0.3818,  1.1787],\n",
      "        [ 0.9186, -0.0861],\n",
      "        [ 0.8091,  1.0119],\n",
      "        [ 0.3005,  0.6817],\n",
      "        [ 0.6727,  0.9174],\n",
      "        [ 0.3754,  0.3596],\n",
      "        [ 0.3608, -0.4816],\n",
      "        [ 0.9912, -1.1673],\n",
      "        [ 0.2793,  1.2866],\n",
      "        [ 0.1897, -2.0399]], device='cuda:0')\n",
      "Action space size: 1120\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 13/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -1.1636096903017206\n",
      "Size of input data: torch.Size([243, 2])\n",
      "Size of embeddings: torch.Size([243, 2])\n",
      "Embeddings: tensor([[-3.6121e+00,  3.2210e+00],\n",
      "        [-2.6796e+00,  3.5277e+00],\n",
      "        [-4.2146e+00,  3.9025e+00],\n",
      "        [-3.0246e+00,  3.8701e+00],\n",
      "        [ 1.8148e+00,  8.8488e-01],\n",
      "        [ 2.5818e-01, -5.8928e-02],\n",
      "        [-9.0225e-01,  1.6258e-01],\n",
      "        [ 1.1552e+00,  2.6940e-01],\n",
      "        [ 8.8743e-01,  4.6991e-01],\n",
      "        [ 7.4045e-01, -3.6553e-01],\n",
      "        [ 8.9555e-01, -1.1726e+00],\n",
      "        [-1.2739e-01,  1.2126e+00],\n",
      "        [-1.4203e+00, -2.6382e-01],\n",
      "        [ 1.7187e+00,  9.6407e-01],\n",
      "        [ 5.0821e-01,  2.4390e-01],\n",
      "        [ 6.8980e-02, -8.4546e-01],\n",
      "        [-4.4096e-01,  6.7920e-02],\n",
      "        [ 8.1166e-01,  6.2961e-01],\n",
      "        [-1.8493e+00,  1.7340e+00],\n",
      "        [-1.7660e+00,  4.0544e-01],\n",
      "        [ 1.1101e+00,  7.4021e-01],\n",
      "        [ 1.8479e+00,  2.9730e-01],\n",
      "        [-9.4131e-02,  5.7848e-01],\n",
      "        [-1.9851e+00, -5.1630e-01],\n",
      "        [-1.5899e+00,  5.9337e-01],\n",
      "        [-9.5096e-01, -8.5140e-01],\n",
      "        [-1.0577e+00,  7.3298e-01],\n",
      "        [-2.9899e+00,  1.0763e+00],\n",
      "        [ 1.8502e-01,  2.3390e-01],\n",
      "        [-1.0641e+00, -6.1918e-01],\n",
      "        [ 7.7507e-01,  3.3660e-01],\n",
      "        [-2.1527e+00,  1.2609e+00],\n",
      "        [-6.0917e-01, -1.6772e+00],\n",
      "        [-3.0419e-01,  9.7723e-02],\n",
      "        [ 8.1676e-02, -1.6791e-01],\n",
      "        [-1.1225e+00, -4.4245e-01],\n",
      "        [-9.3609e-01,  1.0192e+00],\n",
      "        [ 3.5844e-01, -1.4317e+00],\n",
      "        [-1.8046e+00,  1.0036e+00],\n",
      "        [ 4.0478e-01, -1.0744e+00],\n",
      "        [ 1.1287e+00,  1.4876e-01],\n",
      "        [-1.0451e+00,  1.4375e+00],\n",
      "        [ 8.7961e-01,  3.5455e-02],\n",
      "        [-4.9216e-01,  1.1398e+00],\n",
      "        [ 2.0937e-01,  1.1341e-01],\n",
      "        [ 1.0165e+00,  6.5620e-01],\n",
      "        [-2.2356e-01, -5.3343e-01],\n",
      "        [ 5.3186e-01, -6.0720e-02],\n",
      "        [ 8.8934e-01,  4.3604e-01],\n",
      "        [ 8.4748e-01,  1.2060e-01],\n",
      "        [-4.1243e-01,  3.9952e-01],\n",
      "        [-4.1146e-01,  1.6124e-01],\n",
      "        [ 7.0973e-01, -2.5493e-01],\n",
      "        [ 1.5349e-01, -4.5401e-01],\n",
      "        [ 6.1100e-01, -1.0386e+00],\n",
      "        [ 1.1709e+00,  2.6924e-02],\n",
      "        [-2.5807e-01, -9.0875e-01],\n",
      "        [ 6.4580e-01, -3.7028e-01],\n",
      "        [ 1.6139e-01,  5.0093e-01],\n",
      "        [ 9.9297e-02,  1.3575e-01],\n",
      "        [-6.9164e-02, -4.8868e-01],\n",
      "        [ 8.7254e-01,  8.3033e-01],\n",
      "        [-3.9000e-01,  4.6625e-01],\n",
      "        [ 8.1276e-01,  2.9592e-01],\n",
      "        [ 8.6944e-02,  4.9230e-01],\n",
      "        [ 5.8030e-01,  3.0999e-01],\n",
      "        [ 1.3173e-01, -1.3460e+00],\n",
      "        [-5.4584e-01,  7.7145e-02],\n",
      "        [ 3.4221e-01, -1.7673e-01],\n",
      "        [ 1.5988e-01, -7.8424e-01],\n",
      "        [ 1.6751e+00, -6.9758e-01],\n",
      "        [-2.8154e-02, -4.5305e-01],\n",
      "        [-4.6660e-01, -1.2564e+00],\n",
      "        [-3.2806e-01,  1.0470e-01],\n",
      "        [-3.5715e-01, -2.3576e-01],\n",
      "        [-3.1513e-01,  5.7960e-01],\n",
      "        [ 8.1389e-01, -1.6974e+00],\n",
      "        [-1.4497e+00, -1.3703e-01],\n",
      "        [-2.3391e+00,  9.9714e-01],\n",
      "        [ 4.6029e-01, -5.8176e-01],\n",
      "        [-7.6745e-02,  3.2240e-01],\n",
      "        [-4.6245e-01, -1.4001e-01],\n",
      "        [ 6.9152e-01,  3.3475e-01],\n",
      "        [ 1.0427e+00,  5.5107e-01],\n",
      "        [ 3.6901e-01,  9.2596e-02],\n",
      "        [-1.0782e+00,  1.4701e+00],\n",
      "        [ 2.5921e-01, -1.2073e+00],\n",
      "        [-1.9553e+00, -1.1217e+00],\n",
      "        [-4.2462e-01, -1.1616e-01],\n",
      "        [ 4.8217e-01,  1.9657e-01],\n",
      "        [ 4.2439e-01, -1.8289e+00],\n",
      "        [-2.8060e-02, -1.3549e+00],\n",
      "        [ 2.9743e-01,  6.9787e-01],\n",
      "        [ 2.0709e-01, -1.4312e+00],\n",
      "        [-8.4344e-01,  1.1294e+00],\n",
      "        [-1.6852e-01,  4.8575e-01],\n",
      "        [-1.9336e-02, -2.3881e-01],\n",
      "        [ 7.5851e-01,  1.4962e-01],\n",
      "        [-5.9097e-01,  7.1466e-01],\n",
      "        [ 6.1680e-01, -9.7111e-01],\n",
      "        [ 2.6236e-01, -3.3505e-01],\n",
      "        [ 1.7618e-01, -1.4858e+00],\n",
      "        [-5.4223e-01, -1.8330e+00],\n",
      "        [-7.5709e-01, -8.1923e-01],\n",
      "        [ 6.6878e-01,  2.3303e-01],\n",
      "        [ 1.5061e-02, -2.9151e-01],\n",
      "        [ 3.4089e-01, -2.5289e-01],\n",
      "        [ 2.8254e+00, -3.2898e-01],\n",
      "        [-2.7913e-01,  8.2809e-02],\n",
      "        [ 1.6816e-01,  2.0035e-01],\n",
      "        [-3.8150e-01, -1.3727e-01],\n",
      "        [ 7.4574e-01, -4.5106e-01],\n",
      "        [-9.7029e-01,  6.7036e-03],\n",
      "        [ 2.4864e-01, -9.1985e-01],\n",
      "        [-6.6257e-01,  8.7423e-01],\n",
      "        [-8.2484e-01,  1.2356e+00],\n",
      "        [ 6.9607e-02, -1.5688e+00],\n",
      "        [ 7.6417e-01, -9.3626e-02],\n",
      "        [-5.8778e-01, -4.7506e-01],\n",
      "        [ 2.8161e-01, -1.7006e+00],\n",
      "        [-1.3653e+00,  3.0984e-01],\n",
      "        [-3.3835e-01, -1.2485e+00],\n",
      "        [-1.0318e+00,  8.7233e-01],\n",
      "        [ 4.4534e-01, -2.7307e+00],\n",
      "        [ 1.5364e+00, -8.1681e-01],\n",
      "        [-1.0343e-01,  5.0626e-01],\n",
      "        [-1.1920e+00,  4.3487e-02],\n",
      "        [-1.2402e+00,  1.0878e+00],\n",
      "        [ 1.0448e+00, -7.8038e-01],\n",
      "        [ 6.3102e-01,  7.3467e-02],\n",
      "        [-1.1076e+00,  2.3639e-01],\n",
      "        [ 3.0964e-01, -7.3475e-01],\n",
      "        [ 1.1004e-01,  3.3138e-01],\n",
      "        [-6.1103e-01,  5.1615e-01],\n",
      "        [ 4.5347e-01, -1.6893e-01],\n",
      "        [ 2.5106e-01,  7.6132e-01],\n",
      "        [-1.2033e+00,  1.1017e+00],\n",
      "        [ 1.6924e+00,  8.3622e-01],\n",
      "        [ 1.3230e+00,  9.4736e-02],\n",
      "        [-5.4369e-01, -9.6822e-01],\n",
      "        [ 7.7619e-01,  2.5443e-01],\n",
      "        [ 3.7636e-01,  2.6374e-01],\n",
      "        [-3.4184e-01,  5.5084e-01],\n",
      "        [ 1.1289e+00,  3.8657e-01],\n",
      "        [-1.2002e+00,  1.1693e+00],\n",
      "        [ 4.5587e-01,  8.8295e-01],\n",
      "        [ 1.1670e+00, -1.7678e-01],\n",
      "        [-2.5964e+00,  4.9564e+00],\n",
      "        [-9.1133e-01, -9.8353e-01],\n",
      "        [ 9.0615e-01, -9.1284e-01],\n",
      "        [-3.8600e-01, -3.2839e-01],\n",
      "        [ 3.2933e-01, -8.2254e-01],\n",
      "        [ 1.7196e+00,  3.0755e-01],\n",
      "        [ 2.7182e-01, -5.6000e-01],\n",
      "        [ 2.9108e-01, -4.0708e-01],\n",
      "        [-5.8655e-01, -7.7073e-01],\n",
      "        [ 3.1943e-01,  3.7907e-01],\n",
      "        [ 1.9976e+00,  5.0792e-01],\n",
      "        [ 3.7878e-01,  1.8061e-01],\n",
      "        [-1.0944e+00,  1.5272e+00],\n",
      "        [ 9.0145e-01, -6.9030e-02],\n",
      "        [-6.2475e-01, -1.1495e-01],\n",
      "        [-2.2591e+00,  4.0844e-01],\n",
      "        [ 5.2419e-01, -6.8621e-01],\n",
      "        [ 2.1111e-01, -6.0238e-01],\n",
      "        [ 7.7613e-01,  4.6914e-01],\n",
      "        [ 1.0568e+00, -1.1947e-02],\n",
      "        [ 7.2812e-01,  7.4110e-01],\n",
      "        [ 2.5622e-01, -1.6546e+00],\n",
      "        [-1.2994e-01, -2.2969e-01],\n",
      "        [-7.3882e-01, -1.0015e+00],\n",
      "        [-3.4455e-01, -1.1594e+00],\n",
      "        [ 8.2142e-01,  6.9556e-01],\n",
      "        [ 4.8873e-01, -1.4093e-01],\n",
      "        [ 6.8716e-01, -3.5596e-01],\n",
      "        [ 2.5970e-01, -6.7721e-01],\n",
      "        [ 3.3272e-01,  5.5920e-01],\n",
      "        [-9.1124e-01, -3.3003e-02],\n",
      "        [ 1.4900e+00,  8.9298e-02],\n",
      "        [-1.3909e+00, -3.3236e-01],\n",
      "        [ 2.9868e-03,  8.6021e-01],\n",
      "        [ 7.3215e-01, -3.1416e-01],\n",
      "        [-6.1877e-01, -7.5040e-01],\n",
      "        [-4.7175e-01,  2.4072e-01],\n",
      "        [ 7.5225e-02,  1.1177e+00],\n",
      "        [ 6.7148e-01,  2.8734e-01],\n",
      "        [ 2.1939e+00,  2.6003e-01],\n",
      "        [-3.5461e-01,  1.7774e-01],\n",
      "        [-2.7266e-01, -1.2139e+00],\n",
      "        [ 3.1029e-01,  6.3953e-01],\n",
      "        [ 3.3965e-01,  2.0856e-01],\n",
      "        [-1.7939e+00,  1.5081e+00],\n",
      "        [ 1.0596e-01, -1.3098e+00],\n",
      "        [ 4.3751e-01,  6.5321e-01],\n",
      "        [ 8.4808e-01,  2.2738e-01],\n",
      "        [ 6.3387e-01, -2.1983e-02],\n",
      "        [ 1.5686e+00, -3.8500e-02],\n",
      "        [ 1.0872e+00, -3.0167e+00],\n",
      "        [-2.4758e-01, -8.9823e-01],\n",
      "        [ 3.4921e-01,  2.1288e-01],\n",
      "        [ 6.2688e-02, -1.1095e+00],\n",
      "        [-2.7574e-02, -1.2882e+00],\n",
      "        [-7.7285e-02, -1.4919e+00],\n",
      "        [ 6.6353e-01, -1.2063e+00],\n",
      "        [ 4.0856e-01, -4.3046e-01],\n",
      "        [-3.5051e-01, -1.2816e+00],\n",
      "        [-4.5239e-01, -1.5425e+00],\n",
      "        [ 6.6820e-01, -7.1699e-01],\n",
      "        [ 7.4246e-01,  5.8245e-01],\n",
      "        [ 2.5260e-01, -1.8560e+00],\n",
      "        [-3.9694e-01, -1.1011e+00],\n",
      "        [ 4.0734e-01,  7.5058e-01],\n",
      "        [-2.3032e-01,  2.3054e-01],\n",
      "        [ 5.4606e-01,  1.0309e+00],\n",
      "        [ 4.8994e-01,  6.6545e-01],\n",
      "        [ 4.3632e-01,  7.1245e-01],\n",
      "        [-8.0218e-03,  1.9418e-01],\n",
      "        [ 5.0436e-02, -7.7370e-01],\n",
      "        [ 3.5807e-01,  8.5635e-01],\n",
      "        [ 6.4556e-01, -1.1310e+00],\n",
      "        [ 5.2283e-01,  9.5335e-01],\n",
      "        [ 2.5932e-01,  3.4340e-01],\n",
      "        [ 9.8820e-01,  1.0164e+00],\n",
      "        [ 3.7322e-01, -2.7595e-01],\n",
      "        [ 1.6432e-01, -4.4770e-01],\n",
      "        [ 2.9608e-01, -1.4761e+00],\n",
      "        [ 5.3278e-01,  9.4067e-01],\n",
      "        [-1.0403e-01, -1.7635e+00],\n",
      "        [ 4.1868e-01,  2.1906e-01],\n",
      "        [ 5.9207e-01,  3.7729e-01],\n",
      "        [-8.9951e-01, -5.0542e-01],\n",
      "        [ 5.2991e-01,  1.5108e-01],\n",
      "        [ 1.0293e+00, -6.4343e-01],\n",
      "        [ 6.5579e-01, -7.2247e-01],\n",
      "        [-3.5062e-01,  4.9580e-01],\n",
      "        [ 5.7447e-01,  1.7868e-01],\n",
      "        [ 7.0313e-02,  3.2552e-02],\n",
      "        [-2.3803e-02, -8.2341e-01],\n",
      "        [-1.3198e+00,  1.1186e+00],\n",
      "        [ 5.4761e-01,  8.3444e-01],\n",
      "        [ 4.5690e-01, -9.3105e-01],\n",
      "        [-3.2047e+00,  1.5133e+00],\n",
      "        [ 6.3769e-02,  1.5576e-01]], device='cuda:0')\n",
      "Action space size: 1195\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 14/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -1.0472487212715484\n",
      "Size of input data: torch.Size([260, 2])\n",
      "Size of embeddings: torch.Size([260, 2])\n",
      "Embeddings: tensor([[-2.7313e+00,  4.4901e+00],\n",
      "        [-2.6311e+00,  4.5649e+00],\n",
      "        [-4.3008e+00,  4.6102e+00],\n",
      "        [-3.8659e+00,  4.4271e+00],\n",
      "        [ 2.5083e-02, -7.8805e-01],\n",
      "        [ 5.6413e-01,  3.0924e-01],\n",
      "        [ 2.4624e-01, -2.4834e-01],\n",
      "        [ 3.1697e-01, -9.2790e-02],\n",
      "        [ 1.8458e-01,  3.6181e-01],\n",
      "        [ 4.9987e-01,  7.3735e-02],\n",
      "        [ 8.0470e-01, -5.1630e-02],\n",
      "        [-3.6539e-01,  1.6098e+00],\n",
      "        [-1.3457e+00, -1.0157e+00],\n",
      "        [ 3.0172e-01, -2.6493e-01],\n",
      "        [ 4.9151e-01,  3.8813e-01],\n",
      "        [-2.5924e-01, -5.0305e-02],\n",
      "        [-1.5621e+00, -4.5561e-02],\n",
      "        [ 1.1312e+00,  4.3610e-01],\n",
      "        [-2.2900e+00,  1.7319e+00],\n",
      "        [-3.0192e-01,  3.3098e-02],\n",
      "        [ 2.5813e-01,  3.4343e-01],\n",
      "        [ 5.3451e-01,  6.3946e-01],\n",
      "        [-6.0981e-01,  5.0296e-01],\n",
      "        [-1.3125e+00, -6.7795e-01],\n",
      "        [-4.2055e+00, -5.0718e-01],\n",
      "        [-9.9445e-01, -3.9804e-02],\n",
      "        [-4.0817e-01,  9.8075e-01],\n",
      "        [-3.0984e+00,  6.4381e-01],\n",
      "        [ 9.9174e-01,  2.2018e-01],\n",
      "        [ 2.0802e-01, -3.1813e-01],\n",
      "        [ 3.0715e-01,  7.4038e-01],\n",
      "        [-1.2077e+00,  1.1383e+00],\n",
      "        [ 1.0885e+00, -4.8248e-01],\n",
      "        [-1.1966e-01,  3.1759e-02],\n",
      "        [-2.0868e-02, -1.0321e-01],\n",
      "        [-1.0324e-01, -6.2475e-01],\n",
      "        [-1.4289e+00,  1.6562e+00],\n",
      "        [ 4.1651e-02, -1.2251e+00],\n",
      "        [-1.9202e+00,  1.2982e+00],\n",
      "        [ 9.1211e-01, -1.0230e+00],\n",
      "        [ 1.1650e-01, -3.2434e-01],\n",
      "        [-1.8942e+00,  1.1860e+00],\n",
      "        [ 9.0983e-01, -2.5561e-01],\n",
      "        [ 6.5362e-01,  1.2007e+00],\n",
      "        [ 8.7629e-02,  2.0734e-01],\n",
      "        [ 9.1467e-01,  1.1252e-01],\n",
      "        [ 6.1388e-01, -6.0214e-01],\n",
      "        [ 1.7568e-01, -4.0994e-02],\n",
      "        [ 1.1949e+00, -5.2519e-01],\n",
      "        [-2.0217e-01, -2.3514e-01],\n",
      "        [-9.0887e-01,  6.7926e-01],\n",
      "        [-2.5875e+00, -1.2541e+00],\n",
      "        [ 1.3263e+00, -8.6783e-01],\n",
      "        [ 2.0139e-01, -1.7533e-01],\n",
      "        [ 9.2407e-01, -7.5495e-01],\n",
      "        [ 9.7286e-01, -9.0121e-01],\n",
      "        [ 1.8624e-01, -6.5846e-01],\n",
      "        [ 2.3953e-01, -3.0871e-01],\n",
      "        [ 2.8565e-01,  1.7445e-01],\n",
      "        [-2.4065e-01, -4.6207e-01],\n",
      "        [-1.0423e-01, -5.3650e-01],\n",
      "        [ 9.0229e-01,  1.0611e+00],\n",
      "        [-7.8063e-02,  2.2500e-01],\n",
      "        [ 4.8700e-01,  6.6800e-01],\n",
      "        [-3.1495e-01,  5.0709e-01],\n",
      "        [-8.6734e-02, -2.0045e-01],\n",
      "        [-5.3222e-01, -4.1560e-01],\n",
      "        [ 7.8345e-01,  4.3133e-01],\n",
      "        [ 5.2767e-01,  5.2391e-01],\n",
      "        [ 3.4426e-01, -2.9003e-01],\n",
      "        [ 8.9154e-01, -5.4414e-01],\n",
      "        [-4.2143e-01, -9.0011e-01],\n",
      "        [ 2.4469e-01, -2.3548e-01],\n",
      "        [-7.5216e-01, -1.5806e-02],\n",
      "        [-2.7740e-01,  9.5795e-03],\n",
      "        [ 3.3503e-01,  7.1493e-01],\n",
      "        [-2.1246e-01, -1.8251e+00],\n",
      "        [-7.1065e-01,  2.1070e-01],\n",
      "        [-3.2235e+00,  1.0662e+00],\n",
      "        [ 2.2091e-01, -9.9408e-01],\n",
      "        [ 3.2604e-01,  7.6484e-02],\n",
      "        [-4.6626e-03,  3.1869e-01],\n",
      "        [ 5.6579e-01,  1.2414e-01],\n",
      "        [ 1.3595e+00,  3.5503e-01],\n",
      "        [-2.1875e+00,  5.8063e-02],\n",
      "        [-1.0755e-01,  1.2517e+00],\n",
      "        [ 8.1768e-01, -5.2611e-01],\n",
      "        [-8.4650e-01, -6.2544e-01],\n",
      "        [ 8.9108e-02, -1.9650e-02],\n",
      "        [ 6.8450e-01,  4.3674e-01],\n",
      "        [ 1.1504e+00, -8.0924e-01],\n",
      "        [ 1.3564e+00, -2.4189e-01],\n",
      "        [ 2.7009e-01,  8.1000e-01],\n",
      "        [ 4.3906e-01, -4.7534e-01],\n",
      "        [-6.1499e-01,  1.1028e+00],\n",
      "        [ 1.5418e-01,  4.5416e-01],\n",
      "        [-3.0875e-01, -3.0635e-02],\n",
      "        [ 2.4740e-01,  2.3622e-01],\n",
      "        [-1.6857e-01,  6.4628e-01],\n",
      "        [ 9.9289e-01, -7.0788e-01],\n",
      "        [-6.3498e-01, -5.1748e-01],\n",
      "        [ 1.3776e+00, -8.9449e-01],\n",
      "        [ 7.6113e-01, -8.9390e-01],\n",
      "        [-8.4822e-01, -1.2878e+00],\n",
      "        [-1.1893e+00,  9.2159e-01],\n",
      "        [-5.6538e-01, -9.7761e-01],\n",
      "        [-1.3135e-01, -7.3072e-01],\n",
      "        [ 4.7180e-01, -1.6202e+00],\n",
      "        [-4.8725e-01,  3.2380e-01],\n",
      "        [ 5.4555e-01, -2.1071e-01],\n",
      "        [ 3.4146e-01,  2.5093e-01],\n",
      "        [-5.2049e-02, -1.1122e+00],\n",
      "        [ 1.5185e-01, -3.0349e-01],\n",
      "        [-2.1115e-01, -6.6534e-01],\n",
      "        [-2.1703e-01,  4.1136e-01],\n",
      "        [-1.9608e+00,  9.2274e-01],\n",
      "        [-7.6894e-01, -1.3735e+00],\n",
      "        [ 4.0925e-01, -2.1415e-01],\n",
      "        [ 4.3805e-01,  1.5011e-01],\n",
      "        [-2.3497e-01, -1.7355e+00],\n",
      "        [-5.6902e-01,  2.3608e-01],\n",
      "        [ 3.6863e-01,  1.2032e-01],\n",
      "        [-7.8433e-01,  6.5953e-01],\n",
      "        [ 6.4769e-01, -2.3401e+00],\n",
      "        [-1.9350e+00, -4.0107e-01],\n",
      "        [ 3.4540e-01,  1.9189e-01],\n",
      "        [ 1.8876e-01, -2.3828e-01],\n",
      "        [-1.2743e+00,  1.2191e+00],\n",
      "        [-1.5752e+00, -1.0201e-01],\n",
      "        [-1.2221e-01, -1.8269e+00],\n",
      "        [ 1.5837e-01, -2.4151e-01],\n",
      "        [-5.4683e-01, -3.3043e-01],\n",
      "        [ 3.0124e-01,  1.2855e-01],\n",
      "        [-8.9690e-01,  3.6370e-01],\n",
      "        [ 5.8203e-01, -1.9033e-01],\n",
      "        [-3.3767e-01,  4.4211e-01],\n",
      "        [-3.6399e-01,  1.2422e+00],\n",
      "        [ 8.2138e-02,  6.1737e-01],\n",
      "        [-1.7400e-02, -1.5024e+00],\n",
      "        [ 2.1740e-01, -3.6930e-01],\n",
      "        [ 7.6100e-01,  2.5299e-01],\n",
      "        [ 6.4914e-01,  2.3656e-01],\n",
      "        [-4.8776e-01, -3.9886e-02],\n",
      "        [ 1.0612e+00,  1.1313e+00],\n",
      "        [-1.4488e+00,  1.4596e+00],\n",
      "        [ 3.6901e-01,  8.4521e-01],\n",
      "        [ 7.6855e-01, -6.5692e-01],\n",
      "        [ 3.1091e+00,  3.0882e+00],\n",
      "        [ 5.9061e-01, -8.5036e-01],\n",
      "        [ 1.1571e+00, -4.3028e-01],\n",
      "        [ 4.2875e-02, -8.7710e-02],\n",
      "        [ 1.4733e-01, -4.9363e-01],\n",
      "        [-9.0327e-01, -6.9435e-01],\n",
      "        [ 1.5697e-01, -8.9590e-01],\n",
      "        [ 1.0785e+00,  1.0055e-01],\n",
      "        [ 8.6312e-01,  3.6143e-02],\n",
      "        [ 1.6646e-01,  5.8927e-01],\n",
      "        [-5.2044e-02, -2.5848e-02],\n",
      "        [ 9.3363e-01,  3.2979e-01],\n",
      "        [-1.5084e+00,  2.2517e+00],\n",
      "        [ 5.2568e-01, -5.5096e-01],\n",
      "        [-6.5964e-02, -1.8254e-01],\n",
      "        [-1.8089e+00,  4.5463e-01],\n",
      "        [ 1.4495e+00,  3.0990e-02],\n",
      "        [ 3.5001e-01, -1.7665e-01],\n",
      "        [ 1.0222e+00,  3.7034e-01],\n",
      "        [ 6.9732e-01, -1.9665e+00],\n",
      "        [-1.2853e-01, -5.1451e-01],\n",
      "        [ 4.8450e-01, -6.8106e-01],\n",
      "        [-1.7325e-01, -1.8310e-01],\n",
      "        [ 8.6176e-01, -5.8719e-01],\n",
      "        [-4.2382e-01, -8.8663e-01],\n",
      "        [ 1.0108e+00,  3.7231e-01],\n",
      "        [-1.6573e-01, -1.3275e+00],\n",
      "        [ 4.7096e-01, -1.2532e+00],\n",
      "        [-1.0501e+00, -9.6035e-01],\n",
      "        [ 8.4928e-01,  7.8360e-01],\n",
      "        [-1.5650e-02, -3.4975e-01],\n",
      "        [ 2.2007e-01,  1.3188e-01],\n",
      "        [-8.3235e-01, -1.7062e-01],\n",
      "        [ 1.2944e-01,  9.0247e-01],\n",
      "        [-3.4762e-01, -5.6126e-01],\n",
      "        [-1.4002e+00, -8.7596e-01],\n",
      "        [-3.2096e-01, -4.6108e-01],\n",
      "        [ 7.2877e-01,  1.1868e+00],\n",
      "        [ 9.6309e-01,  4.3947e-01],\n",
      "        [-5.4674e-01, -5.4106e-01],\n",
      "        [ 3.3349e-02, -1.2948e+00],\n",
      "        [ 1.0366e+00, -4.2861e-01],\n",
      "        [ 7.3009e-01,  5.3450e-01],\n",
      "        [ 4.2281e-01,  6.6703e-01],\n",
      "        [-1.9538e+00,  1.6763e+00],\n",
      "        [ 2.8924e-01, -1.3009e+00],\n",
      "        [ 7.7441e-01,  4.2182e-01],\n",
      "        [ 7.3596e-01,  3.1140e-01],\n",
      "        [ 8.3130e-01, -3.0878e-03],\n",
      "        [ 7.2471e-01, -2.7630e-01],\n",
      "        [ 1.4623e+00, -1.9549e+00],\n",
      "        [-7.2782e-01, -1.2624e+00],\n",
      "        [ 3.6602e-01,  2.6882e-01],\n",
      "        [ 5.1957e-01, -8.1604e-01],\n",
      "        [ 7.7351e-01, -1.4360e-01],\n",
      "        [ 2.7316e-01, -1.2076e+00],\n",
      "        [-1.1024e-01, -2.1011e+00],\n",
      "        [ 7.4993e-02, -1.5258e+00],\n",
      "        [-2.4718e-01, -1.0298e+00],\n",
      "        [-1.9390e-01, -6.4583e-01],\n",
      "        [ 4.2064e-01, -1.5748e+00],\n",
      "        [ 8.2866e-01, -4.7701e-02],\n",
      "        [ 4.9227e-01, -1.7778e+00],\n",
      "        [ 7.6473e-01, -3.3944e-01],\n",
      "        [ 7.1309e-01,  9.6151e-01],\n",
      "        [-3.6145e-02,  4.5317e-01],\n",
      "        [ 7.5659e-01,  1.3123e+00],\n",
      "        [ 9.5539e-01,  7.3770e-01],\n",
      "        [-9.6166e-02,  4.5069e-01],\n",
      "        [-1.3888e-01, -6.0706e-02],\n",
      "        [-5.3607e-01, -3.6887e-01],\n",
      "        [ 8.3434e-01,  9.6348e-01],\n",
      "        [ 5.2024e-01, -1.0404e+00],\n",
      "        [ 5.9705e-01,  1.1987e+00],\n",
      "        [ 2.6190e-01,  5.3720e-01],\n",
      "        [ 5.2392e-01,  8.2023e-01],\n",
      "        [ 2.3899e-01, -1.1772e-01],\n",
      "        [ 6.5542e-01, -1.2621e-01],\n",
      "        [ 7.7586e-01, -1.1663e+00],\n",
      "        [ 7.5002e-01,  9.4558e-01],\n",
      "        [ 4.2976e-01, -4.7382e-01],\n",
      "        [ 5.4017e-01,  4.1270e-01],\n",
      "        [ 1.1418e+00,  5.0312e-01],\n",
      "        [ 4.3746e-01, -1.6387e-01],\n",
      "        [ 4.4001e-01,  5.3750e-02],\n",
      "        [ 1.4223e-01, -1.7317e+00],\n",
      "        [ 1.0011e+00, -4.3410e-01],\n",
      "        [-6.8103e-02,  5.6555e-01],\n",
      "        [ 8.0553e-01,  5.2371e-01],\n",
      "        [-2.2270e-01, -5.0236e-01],\n",
      "        [-2.2605e-01, -1.7849e-01],\n",
      "        [-1.1894e+00,  1.3906e+00],\n",
      "        [ 9.6384e-01,  9.9483e-01],\n",
      "        [ 1.1736e+00, -7.0821e-01],\n",
      "        [-3.3301e+00,  1.2105e+00],\n",
      "        [ 2.9436e-01,  7.7524e-01],\n",
      "        [ 9.6668e-01, -1.6398e-01],\n",
      "        [ 1.3004e-02, -8.3160e-01],\n",
      "        [ 3.0212e-01, -1.8930e-01],\n",
      "        [ 9.0964e-01, -8.0482e-01],\n",
      "        [ 5.3926e-01,  5.4197e-01],\n",
      "        [ 4.6361e-01, -2.2101e+00],\n",
      "        [ 5.8858e-02, -9.4549e-01],\n",
      "        [-5.5379e-01,  3.1973e-01],\n",
      "        [ 1.5498e-01, -1.3274e+00],\n",
      "        [-9.7189e-01,  6.7491e-01],\n",
      "        [ 1.0688e-01,  2.7326e-01],\n",
      "        [ 4.1391e-01,  1.3328e-01],\n",
      "        [-1.3781e-01,  2.0552e-01],\n",
      "        [ 1.2411e+00, -4.6959e-01],\n",
      "        [-2.2146e+00,  9.1211e-01],\n",
      "        [ 4.6643e-01,  9.1454e-01],\n",
      "        [ 1.7765e-01,  6.0749e-01]], device='cuda:0')\n",
      "Action space size: 1280\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 15/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -0.9425238491443936\n",
      "Size of input data: torch.Size([279, 2])\n",
      "Size of embeddings: torch.Size([279, 2])\n",
      "Embeddings: tensor([[-4.3105,  2.6887],\n",
      "        [-3.8425,  3.0381],\n",
      "        [-4.4223,  3.5421],\n",
      "        [-3.6439,  3.9150],\n",
      "        [ 0.8407, -0.3539],\n",
      "        [ 0.4417,  0.0280],\n",
      "        [-0.5903, -0.1025],\n",
      "        [ 0.8358,  0.6603],\n",
      "        [-0.8867,  0.5635],\n",
      "        [ 1.1598, -1.0644],\n",
      "        [ 0.9364, -0.8135],\n",
      "        [-0.6199,  1.8701],\n",
      "        [-1.1343, -1.0619],\n",
      "        [-0.1300,  0.3921],\n",
      "        [ 0.3809,  1.1931],\n",
      "        [-1.0586, -1.2210],\n",
      "        [ 0.1995,  0.8397],\n",
      "        [ 0.1070,  0.3947],\n",
      "        [-0.4875,  2.2689],\n",
      "        [-0.7423,  0.3165],\n",
      "        [ 1.3319,  0.9767],\n",
      "        [-0.6433,  0.1132],\n",
      "        [-0.3507,  1.2821],\n",
      "        [-1.8458, -0.8616],\n",
      "        [-0.8923,  1.7214],\n",
      "        [-1.4643,  0.1357],\n",
      "        [-1.3342,  0.7368],\n",
      "        [-1.4377,  1.4365],\n",
      "        [ 0.9606, -0.0317],\n",
      "        [-0.8634, -0.7075],\n",
      "        [ 0.0696,  0.7998],\n",
      "        [-1.9238,  0.8486],\n",
      "        [ 0.6272, -1.1391],\n",
      "        [ 0.3388, -0.0698],\n",
      "        [ 0.6557,  0.9800],\n",
      "        [-1.9987, -1.6116],\n",
      "        [-0.6525,  2.3407],\n",
      "        [ 0.4349, -0.6268],\n",
      "        [-2.7976,  1.3553],\n",
      "        [ 1.1419, -0.6286],\n",
      "        [ 0.9524,  0.3130],\n",
      "        [-0.4573,  1.4183],\n",
      "        [ 0.7070,  0.8103],\n",
      "        [-0.7259,  0.7820],\n",
      "        [ 0.7017, -0.0586],\n",
      "        [-0.0276,  0.4821],\n",
      "        [ 0.7158, -0.9197],\n",
      "        [-0.7125, -0.1364],\n",
      "        [ 0.1275, -0.2034],\n",
      "        [ 0.7099,  0.1507],\n",
      "        [-1.3700,  1.2712],\n",
      "        [ 1.1634,  1.3677],\n",
      "        [ 0.5781,  0.2596],\n",
      "        [ 0.4235, -0.3813],\n",
      "        [ 0.4899, -1.3913],\n",
      "        [ 0.9635,  0.1742],\n",
      "        [-1.1145, -1.2900],\n",
      "        [-0.3531, -0.2744],\n",
      "        [-0.0177,  0.0288],\n",
      "        [ 0.4383,  0.4464],\n",
      "        [-0.1790, -0.4366],\n",
      "        [ 0.1206,  1.0620],\n",
      "        [-0.5728,  0.3255],\n",
      "        [ 0.3507,  0.4207],\n",
      "        [ 0.1935, -0.5027],\n",
      "        [ 0.2892, -0.3048],\n",
      "        [-0.6465, -1.1390],\n",
      "        [ 0.6471, -0.1002],\n",
      "        [ 0.1351, -0.2890],\n",
      "        [-0.3060, -0.5906],\n",
      "        [ 0.5503, -1.1121],\n",
      "        [ 0.0966, -0.4283],\n",
      "        [-0.0055, -0.9292],\n",
      "        [-0.6894,  0.3660],\n",
      "        [-0.9346, -0.3621],\n",
      "        [ 0.6829,  0.5296],\n",
      "        [ 0.7174, -1.3377],\n",
      "        [-1.2623,  0.0602],\n",
      "        [-2.3380,  1.8245],\n",
      "        [ 0.9942, -0.0426],\n",
      "        [ 0.3488,  0.1928],\n",
      "        [-0.1009, -0.0440],\n",
      "        [ 0.7586,  0.7077],\n",
      "        [ 0.3281,  0.3052],\n",
      "        [ 0.6597,  1.7613],\n",
      "        [-1.5944,  1.4306],\n",
      "        [ 0.4595, -1.3209],\n",
      "        [-1.4258, -0.8392],\n",
      "        [ 0.6378, -0.2751],\n",
      "        [ 0.4084,  0.7056],\n",
      "        [ 1.3859, -1.0904],\n",
      "        [ 1.2015, -0.8403],\n",
      "        [-1.1642,  1.3609],\n",
      "        [ 0.2639, -1.5488],\n",
      "        [-1.1351,  0.6368],\n",
      "        [-0.2186,  1.1143],\n",
      "        [-0.0425, -0.3513],\n",
      "        [ 0.1256, -0.5519],\n",
      "        [-0.6469,  1.9608],\n",
      "        [ 0.7298, -1.1198],\n",
      "        [-0.3524, -0.1393],\n",
      "        [ 0.8719, -0.8504],\n",
      "        [ 1.2016, -0.7037],\n",
      "        [ 1.1967, -0.4501],\n",
      "        [-0.2617,  0.0538],\n",
      "        [ 0.0126, -0.5325],\n",
      "        [ 0.6722,  0.2973],\n",
      "        [ 0.1408, -1.3839],\n",
      "        [ 0.3651,  0.5491],\n",
      "        [ 0.1893, -0.1445],\n",
      "        [ 0.0230, -0.2782],\n",
      "        [-0.1286,  0.0805],\n",
      "        [-0.6274, -0.2323],\n",
      "        [-0.4464, -1.1016],\n",
      "        [-0.6197,  0.2178],\n",
      "        [-1.6490,  1.3192],\n",
      "        [ 0.3560, -1.1581],\n",
      "        [ 0.1588,  0.2611],\n",
      "        [ 0.6917, -0.3770],\n",
      "        [ 0.6617, -1.8778],\n",
      "        [-1.6599,  0.0528],\n",
      "        [-0.5598, -0.8613],\n",
      "        [-0.9602,  0.6570],\n",
      "        [ 0.2314, -3.0506],\n",
      "        [-1.7720, -1.7406],\n",
      "        [ 0.3575, -0.4506],\n",
      "        [-0.7172, -0.1619],\n",
      "        [-0.7866,  1.1422],\n",
      "        [-0.8959, -1.4488],\n",
      "        [-0.6382, -0.0731],\n",
      "        [-0.5518, -0.2834],\n",
      "        [ 0.7444, -0.2929],\n",
      "        [ 0.8601,  1.1000],\n",
      "        [-1.3668, -0.1263],\n",
      "        [ 0.4619,  0.5337],\n",
      "        [-1.1359,  1.7601],\n",
      "        [-1.3683,  0.4255],\n",
      "        [ 0.0947,  0.9381],\n",
      "        [ 0.5585, -1.7186],\n",
      "        [-0.0959, -1.2819],\n",
      "        [ 0.8348,  0.4268],\n",
      "        [ 0.5098, -0.1422],\n",
      "        [-0.1890, -0.7217],\n",
      "        [ 0.8053,  0.6137],\n",
      "        [-1.0463,  1.4317],\n",
      "        [-0.0570,  1.1535],\n",
      "        [ 0.7071, -0.3995],\n",
      "        [ 3.8499,  0.2548],\n",
      "        [-0.9742, -1.6870],\n",
      "        [ 1.0807, -1.1973],\n",
      "        [-0.9255, -0.8981],\n",
      "        [ 0.5757, -0.6449],\n",
      "        [-0.3305, -0.3550],\n",
      "        [ 0.9200,  0.0166],\n",
      "        [ 1.1012, -0.4534],\n",
      "        [ 0.4052, -1.2600],\n",
      "        [ 0.7244,  0.0271],\n",
      "        [ 0.3034, -0.1532],\n",
      "        [ 0.6679,  0.0885],\n",
      "        [-0.9714,  1.2582],\n",
      "        [-0.2445, -0.0093],\n",
      "        [-0.4305, -0.4150],\n",
      "        [-1.2586,  0.6579],\n",
      "        [ 0.9446, -0.3829],\n",
      "        [ 0.4283, -1.4141],\n",
      "        [ 0.9432,  0.6972],\n",
      "        [-0.1421, -1.4215],\n",
      "        [-0.6510,  0.6826],\n",
      "        [ 0.9630, -0.9858],\n",
      "        [-0.2232, -0.3146],\n",
      "        [-0.8963, -1.6553],\n",
      "        [ 0.7315, -0.4761],\n",
      "        [-0.0207,  0.3687],\n",
      "        [ 0.6005, -0.3569],\n",
      "        [ 1.3349, -0.2183],\n",
      "        [ 0.3840, -0.2458],\n",
      "        [ 1.0062,  0.8619],\n",
      "        [-0.4915, -0.0685],\n",
      "        [ 0.2322, -0.4477],\n",
      "        [-1.9046,  0.0506],\n",
      "        [ 0.4239,  0.8467],\n",
      "        [ 0.1169,  0.0051],\n",
      "        [ 0.7545, -0.0535],\n",
      "        [-0.1207,  1.0718],\n",
      "        [-0.2926,  1.2798],\n",
      "        [ 0.9462,  0.1107],\n",
      "        [-0.1888, -0.3032],\n",
      "        [-0.5915, -0.0438],\n",
      "        [ 0.9247, -0.9101],\n",
      "        [ 0.7301,  0.4631],\n",
      "        [ 0.2488,  0.0167],\n",
      "        [-1.8976,  2.2348],\n",
      "        [-0.4600, -1.6011],\n",
      "        [ 0.8680,  0.5189],\n",
      "        [ 0.8636,  0.4298],\n",
      "        [ 0.9414, -0.3078],\n",
      "        [ 0.6166,  0.6438],\n",
      "        [-1.9481, -3.8203],\n",
      "        [-0.1154, -0.6747],\n",
      "        [ 0.8096,  0.7419],\n",
      "        [ 0.6524, -0.7006],\n",
      "        [ 0.9060, -0.5050],\n",
      "        [ 0.4210, -0.9271],\n",
      "        [ 0.6753, -1.9067],\n",
      "        [ 1.2518, -1.0014],\n",
      "        [ 0.0935, -0.5254],\n",
      "        [ 0.2563, -1.2145],\n",
      "        [ 0.8988, -1.1345],\n",
      "        [ 1.4489,  1.2002],\n",
      "        [ 0.5091, -1.1242],\n",
      "        [ 0.3555, -0.5151],\n",
      "        [ 0.0728,  0.7424],\n",
      "        [-0.3280, -0.0817],\n",
      "        [ 0.4351,  1.0980],\n",
      "        [ 0.8320,  0.8568],\n",
      "        [ 0.7446,  0.7652],\n",
      "        [-0.3586,  0.1627],\n",
      "        [ 0.4235, -0.2981],\n",
      "        [ 0.4593,  0.6692],\n",
      "        [ 0.2706, -0.1379],\n",
      "        [ 0.2823,  1.3231],\n",
      "        [ 0.6346,  0.5001],\n",
      "        [ 0.8091,  0.8300],\n",
      "        [ 1.2645,  0.2266],\n",
      "        [ 0.5632, -1.2054],\n",
      "        [ 1.1140, -0.8368],\n",
      "        [ 0.6324,  0.6752],\n",
      "        [ 0.4520, -1.3384],\n",
      "        [ 0.3864,  0.6704],\n",
      "        [ 0.1363,  0.1058],\n",
      "        [ 0.6111, -0.6556],\n",
      "        [-0.1036,  0.3833],\n",
      "        [ 0.5936, -0.5435],\n",
      "        [ 0.3913, -0.5519],\n",
      "        [ 0.5900,  0.4412],\n",
      "        [ 0.0347,  0.4085],\n",
      "        [ 0.0519,  0.1140],\n",
      "        [-1.7644, -1.0379],\n",
      "        [-0.7425,  0.6476],\n",
      "        [ 0.7451,  0.8418],\n",
      "        [ 1.0072, -0.3366],\n",
      "        [-2.6935,  1.7208],\n",
      "        [-0.0655,  0.2748],\n",
      "        [ 1.2999,  0.0687],\n",
      "        [-1.2307, -1.6689],\n",
      "        [-1.4685, -0.8788],\n",
      "        [ 0.7282, -1.2966],\n",
      "        [-0.1895,  0.1387],\n",
      "        [ 0.4707, -1.4269],\n",
      "        [ 0.5855,  0.1729],\n",
      "        [-0.8971, -0.1162],\n",
      "        [ 0.1567, -2.2645],\n",
      "        [-2.5903,  0.5918],\n",
      "        [ 0.9562, -0.8041],\n",
      "        [-0.0561,  0.1517],\n",
      "        [ 0.8625,  0.9206],\n",
      "        [ 1.1757, -0.3882],\n",
      "        [-1.9356,  1.0199],\n",
      "        [ 0.2682,  0.7259],\n",
      "        [ 0.3079,  1.2990],\n",
      "        [ 0.3375, -0.3929],\n",
      "        [-0.5393, -0.9209],\n",
      "        [ 0.4264, -0.0280],\n",
      "        [ 0.4595, -0.5902],\n",
      "        [ 0.4276, -0.1937],\n",
      "        [-0.0115, -0.2545],\n",
      "        [-0.0876,  0.8691],\n",
      "        [ 0.5797, -0.6863],\n",
      "        [ 0.5639,  0.5366],\n",
      "        [ 0.0761, -0.1378],\n",
      "        [-0.0143,  0.2976],\n",
      "        [ 0.8738,  0.7609],\n",
      "        [ 1.2628, -0.4111],\n",
      "        [-0.0680,  0.3099],\n",
      "        [ 0.1148, -0.5539],\n",
      "        [ 0.8150,  0.7967],\n",
      "        [ 0.6495,  0.3889],\n",
      "        [ 0.3313, -0.8069],\n",
      "        [ 0.8216, -1.0914]], device='cuda:0')\n",
      "Action space size: 1375\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 16/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -0.8482714642299541\n",
      "Size of input data: torch.Size([295, 2])\n",
      "Size of embeddings: torch.Size([295, 2])\n",
      "Embeddings: tensor([[-2.9555e+00,  4.2550e+00],\n",
      "        [-3.0315e+00,  4.7841e+00],\n",
      "        [-4.6512e+00,  5.2052e+00],\n",
      "        [-4.1744e+00,  4.9924e+00],\n",
      "        [ 8.4558e-01, -3.9091e-01],\n",
      "        [ 3.1003e-01, -7.5046e-01],\n",
      "        [ 8.1410e-02, -2.5452e-01],\n",
      "        [ 2.2201e-01,  1.8456e-01],\n",
      "        [ 2.6451e-01,  1.6078e+00],\n",
      "        [-1.4674e-01, -6.6531e-01],\n",
      "        [ 9.3952e-01,  4.8600e-01],\n",
      "        [-9.0231e-01,  1.8682e+00],\n",
      "        [-2.1315e+00, -6.0505e-01],\n",
      "        [-2.6227e-01, -2.3063e-01],\n",
      "        [ 4.2543e-01,  3.7193e-01],\n",
      "        [ 2.2754e-01,  9.2457e-02],\n",
      "        [-3.2860e-01, -3.7006e-01],\n",
      "        [-2.6795e-01,  1.7692e-01],\n",
      "        [-7.3037e-01,  1.4326e+00],\n",
      "        [-1.3758e+00, -3.9543e-01],\n",
      "        [ 2.3269e-01,  2.2433e-01],\n",
      "        [-4.8680e-01,  1.5240e-02],\n",
      "        [-4.2463e-01,  4.3639e-01],\n",
      "        [-2.2607e+00, -8.6785e-01],\n",
      "        [-3.6838e+00,  1.5124e+00],\n",
      "        [-1.6473e+00, -1.7711e-02],\n",
      "        [-2.0086e-01,  4.3724e-01],\n",
      "        [-3.6470e+00,  1.0187e+00],\n",
      "        [ 6.4521e-01, -1.7979e-02],\n",
      "        [-4.2157e-01, -7.1617e-01],\n",
      "        [-1.6203e-01,  6.8805e-01],\n",
      "        [-1.2861e+00,  1.2357e+00],\n",
      "        [-7.8591e-01, -6.0412e-01],\n",
      "        [-2.3470e-01,  2.6332e-01],\n",
      "        [ 9.9009e-02,  2.9772e-01],\n",
      "        [-1.8857e+00, -1.4388e+00],\n",
      "        [-6.2738e-01,  2.0118e+00],\n",
      "        [ 5.8232e-01, -6.2375e-01],\n",
      "        [-2.2121e+00,  9.5897e-01],\n",
      "        [ 1.1479e+00,  1.0405e-01],\n",
      "        [ 8.7412e-01, -1.5947e-01],\n",
      "        [-1.9017e+00,  1.7349e+00],\n",
      "        [ 6.8266e-01, -4.0652e-02],\n",
      "        [-3.5726e-01,  1.1392e+00],\n",
      "        [ 6.5183e-02, -2.1794e-01],\n",
      "        [-4.2185e-01, -2.1183e-01],\n",
      "        [-9.5757e-02, -9.7771e-02],\n",
      "        [ 4.0793e-01,  6.8616e-01],\n",
      "        [ 1.0507e-01, -1.9605e-01],\n",
      "        [-2.3753e-03, -8.2953e-01],\n",
      "        [-7.4616e-02,  1.0982e+00],\n",
      "        [-2.6568e+00, -4.7056e-02],\n",
      "        [ 4.4703e-01, -5.8209e-01],\n",
      "        [ 1.6993e-01, -3.6765e-01],\n",
      "        [ 1.1072e+00, -7.2600e-01],\n",
      "        [-1.9101e-01, -9.2320e-01],\n",
      "        [ 4.9489e-01,  2.3440e-01],\n",
      "        [ 6.2299e-01, -6.7027e-01],\n",
      "        [-2.4302e-02,  3.8695e-01],\n",
      "        [-2.0246e-01, -2.7999e-02],\n",
      "        [ 2.1466e-01, -6.5748e-01],\n",
      "        [-1.1458e-02,  7.5135e-01],\n",
      "        [-3.1669e-01,  4.1740e-01],\n",
      "        [ 3.4684e-01,  6.2437e-01],\n",
      "        [ 7.8767e-02,  8.1797e-02],\n",
      "        [-3.3760e-01, -4.3356e-01],\n",
      "        [ 4.3181e-02,  2.9963e-01],\n",
      "        [ 4.3653e-01, -2.6545e-01],\n",
      "        [ 7.5018e-01,  7.9997e-01],\n",
      "        [ 1.2077e+00,  1.5536e-01],\n",
      "        [ 1.1724e+00, -8.0307e-01],\n",
      "        [-1.0548e-01, -3.9849e-01],\n",
      "        [ 3.3433e-01, -4.6842e-01],\n",
      "        [-1.2090e+00, -1.4916e-01],\n",
      "        [ 1.9419e-01,  8.4337e-01],\n",
      "        [ 9.2698e-02,  1.5241e-01],\n",
      "        [ 4.4950e-01, -1.8999e+00],\n",
      "        [-8.1357e-01, -1.2529e-01],\n",
      "        [-3.8919e+00,  1.2461e+00],\n",
      "        [ 7.8214e-01, -7.3942e-01],\n",
      "        [-3.6917e-02, -1.5354e-01],\n",
      "        [ 2.5757e-01, -2.9606e-01],\n",
      "        [-1.5400e-01,  4.0118e-03],\n",
      "        [ 8.3648e-01, -1.9344e-01],\n",
      "        [-2.9300e+00,  2.5741e-02],\n",
      "        [-9.6082e-01,  1.4217e+00],\n",
      "        [ 3.1641e-01, -1.0739e+00],\n",
      "        [-8.9282e-01, -7.4586e-01],\n",
      "        [-6.3711e-01,  1.3997e-01],\n",
      "        [ 4.8510e-01,  3.6248e-02],\n",
      "        [ 1.2737e+00, -5.9372e-01],\n",
      "        [ 7.4094e-01, -1.0167e+00],\n",
      "        [-5.9332e-01,  1.0893e+00],\n",
      "        [-5.0671e-02, -6.9292e-01],\n",
      "        [-3.4405e-01,  9.2846e-01],\n",
      "        [ 3.8180e-01,  8.0365e-01],\n",
      "        [ 1.5554e-01, -2.7126e-01],\n",
      "        [ 1.6046e-02, -2.0014e-01],\n",
      "        [-3.1619e-01,  1.7638e+00],\n",
      "        [ 7.4796e-01, -1.0220e+00],\n",
      "        [ 7.7839e-02, -6.0310e-02],\n",
      "        [ 3.6038e-01, -4.0948e-01],\n",
      "        [ 6.5039e-01, -3.3656e-01],\n",
      "        [ 1.7454e-01, -1.3891e+00],\n",
      "        [-7.3228e-01,  5.8192e-01],\n",
      "        [-5.8609e-01, -2.6391e-01],\n",
      "        [ 8.1764e-02, -2.6438e-01],\n",
      "        [ 8.6779e-01, -1.1672e+00],\n",
      "        [-1.9974e-02, -2.8313e-02],\n",
      "        [ 4.1627e-03, -1.4195e-01],\n",
      "        [ 3.6799e-01, -2.7158e-01],\n",
      "        [ 5.5682e-01,  2.4533e-01],\n",
      "        [-8.8155e-01, -1.4527e-01],\n",
      "        [ 2.3021e-01,  7.0567e-02],\n",
      "        [-5.7684e-01,  6.7599e-01],\n",
      "        [-1.9028e+00,  1.7885e+00],\n",
      "        [ 2.4143e-01, -1.3022e+00],\n",
      "        [ 2.0882e+00,  3.7778e-01],\n",
      "        [-2.6726e-01,  2.8135e-01],\n",
      "        [ 8.5611e-01, -1.8334e+00],\n",
      "        [-7.6732e-01,  5.0792e-02],\n",
      "        [-6.4067e-01,  4.7723e-01],\n",
      "        [-4.5144e-01,  7.9863e-01],\n",
      "        [ 9.7003e-01, -1.6279e+00],\n",
      "        [-6.8779e-01, -2.1455e-02],\n",
      "        [ 7.1493e-01, -4.7642e-01],\n",
      "        [ 6.8305e-03, -2.9237e-01],\n",
      "        [-1.0606e+00,  2.2061e+00],\n",
      "        [-1.0990e+00, -1.5789e-01],\n",
      "        [ 5.0385e-01,  7.5909e-01],\n",
      "        [ 2.1149e-01, -3.8690e-01],\n",
      "        [ 5.4293e-01, -8.1708e-01],\n",
      "        [ 4.2914e-01, -1.7231e-02],\n",
      "        [-4.7215e-01,  7.3527e-01],\n",
      "        [ 6.4183e-01, -1.7758e-01],\n",
      "        [-3.1903e-01,  9.4342e-01],\n",
      "        [-1.2103e+00,  1.7845e+00],\n",
      "        [ 2.0894e-01,  7.4886e-01],\n",
      "        [ 9.4222e-01, -1.2888e+00],\n",
      "        [-4.8550e-01, -7.7594e-01],\n",
      "        [ 1.0260e+00,  8.4026e-03],\n",
      "        [ 3.5231e-01, -5.2043e-01],\n",
      "        [ 9.3738e-02, -4.9536e-01],\n",
      "        [ 3.5846e-02,  3.2314e-01],\n",
      "        [-9.7643e-01,  2.0017e+00],\n",
      "        [ 1.3169e-01,  2.2618e-01],\n",
      "        [ 7.9113e-01, -7.4159e-01],\n",
      "        [ 1.5945e+00, -4.0181e+00],\n",
      "        [-4.0058e-01, -1.5062e+00],\n",
      "        [ 1.2574e+00, -5.3214e-01],\n",
      "        [-1.3594e-01, -6.6303e-01],\n",
      "        [ 6.4686e-01, -1.0287e+00],\n",
      "        [ 5.6771e-01,  1.1181e-01],\n",
      "        [ 6.4957e-01, -6.8605e-01],\n",
      "        [ 1.1692e+00, -1.0021e-01],\n",
      "        [ 3.8961e-01, -1.0304e+00],\n",
      "        [-4.3732e-02, -3.5847e-01],\n",
      "        [ 1.2695e-02, -1.5315e-01],\n",
      "        [ 7.7671e-01,  3.7529e-02],\n",
      "        [-1.5273e+00,  1.5888e+00],\n",
      "        [ 9.0837e-01, -8.6249e-01],\n",
      "        [ 1.8093e-02, -1.7703e-01],\n",
      "        [-1.8866e+00,  9.7933e-02],\n",
      "        [ 6.6404e-01,  1.3896e-02],\n",
      "        [ 6.0260e-01, -4.9411e-01],\n",
      "        [ 7.7668e-01,  4.3562e-01],\n",
      "        [ 1.3229e+00, -1.5798e+00],\n",
      "        [-7.2703e-01,  4.0521e-01],\n",
      "        [ 9.1088e-01, -1.0267e-01],\n",
      "        [ 9.9787e-01,  6.6377e-01],\n",
      "        [-3.6101e-01, -9.1746e-01],\n",
      "        [-1.2776e-01, -1.1889e+00],\n",
      "        [ 5.7185e-01, -2.6929e-02],\n",
      "        [ 5.9120e-01,  6.2611e-02],\n",
      "        [ 6.6863e-01, -7.1494e-01],\n",
      "        [ 2.1211e-01, -1.1882e+00],\n",
      "        [ 9.0055e-01,  2.7855e-01],\n",
      "        [-1.0597e+00, -1.3501e-01],\n",
      "        [-1.8793e-01, -5.4765e-01],\n",
      "        [-1.1148e+00,  2.6408e-01],\n",
      "        [ 5.5481e-01,  1.5322e-01],\n",
      "        [ 4.3419e-01, -8.7497e-01],\n",
      "        [ 5.4077e-02, -8.6817e-01],\n",
      "        [-2.1404e-01,  1.1058e+00],\n",
      "        [-1.1121e-01,  7.5387e-01],\n",
      "        [ 7.2177e-01,  2.5436e-01],\n",
      "        [ 1.1527e+00, -5.3720e-01],\n",
      "        [ 1.1256e-01,  6.4134e-01],\n",
      "        [ 5.8537e-01, -7.4472e-01],\n",
      "        [ 7.9763e-01,  1.4568e-01],\n",
      "        [ 3.9080e-01, -4.9744e-02],\n",
      "        [-2.2993e+00,  2.3979e+00],\n",
      "        [ 4.3665e-01, -6.9121e-01],\n",
      "        [ 3.9750e-02,  1.9937e-01],\n",
      "        [ 1.0086e+00,  1.3569e-01],\n",
      "        [ 6.0302e-01, -2.6126e-02],\n",
      "        [ 6.7632e-01, -9.3448e-02],\n",
      "        [ 9.3513e-01, -2.9940e+00],\n",
      "        [-1.0734e+00, -1.3269e+00],\n",
      "        [ 7.2460e-02,  4.1225e-01],\n",
      "        [ 3.3768e-01, -8.0134e-01],\n",
      "        [ 2.4137e-01, -5.8354e-01],\n",
      "        [ 4.6889e-01, -1.2133e+00],\n",
      "        [ 8.4255e-01, -1.6980e+00],\n",
      "        [ 6.3767e-01, -6.0525e-01],\n",
      "        [ 5.7028e-01, -6.0950e-01],\n",
      "        [ 2.7785e-01, -1.1207e+00],\n",
      "        [ 1.0674e+00, -1.2534e+00],\n",
      "        [ 3.8958e-01,  1.3500e-01],\n",
      "        [ 6.2086e-01, -1.2903e+00],\n",
      "        [ 4.9301e-01, -8.5928e-01],\n",
      "        [ 3.7263e-01,  1.0726e+00],\n",
      "        [ 8.4771e-02,  1.6772e-01],\n",
      "        [ 3.8042e-01,  4.4679e-01],\n",
      "        [ 4.9206e-01,  5.9647e-01],\n",
      "        [ 3.9855e-01, -1.1184e-01],\n",
      "        [ 2.7057e-02,  1.1163e-02],\n",
      "        [ 5.3179e-01, -9.0079e-01],\n",
      "        [ 2.2817e-01,  2.1693e-01],\n",
      "        [ 4.3527e-01, -6.7288e-01],\n",
      "        [-9.5450e-02,  9.9300e-01],\n",
      "        [-1.1126e-01,  2.1074e-01],\n",
      "        [ 3.0144e-01,  5.3971e-01],\n",
      "        [ 1.2016e-01, -2.0233e-01],\n",
      "        [ 8.8078e-01, -5.8440e-01],\n",
      "        [ 1.3350e+00, -2.8687e-01],\n",
      "        [ 4.1278e-01,  2.9275e-01],\n",
      "        [-3.1085e-01, -9.5801e-01],\n",
      "        [ 4.8915e-01,  2.1021e-02],\n",
      "        [ 6.4031e-01, -1.6152e-01],\n",
      "        [ 1.2758e-02, -1.3160e-01],\n",
      "        [ 2.9085e-01,  7.5873e-02],\n",
      "        [-1.7806e-02, -5.8258e-01],\n",
      "        [ 7.7812e-01, -2.1321e-01],\n",
      "        [-2.6091e-01,  3.2358e-01],\n",
      "        [ 8.8130e-01,  8.0538e-01],\n",
      "        [-4.0475e-01,  6.1910e-02],\n",
      "        [ 3.7201e-01,  4.7519e-01],\n",
      "        [-4.2199e-01,  7.8128e-01],\n",
      "        [ 5.4499e-01,  4.5454e-01],\n",
      "        [ 1.3876e+00, -9.0386e-02],\n",
      "        [-3.6879e+00,  1.7806e+00],\n",
      "        [ 2.1682e-01,  5.4865e-01],\n",
      "        [ 8.3311e-01,  8.5270e-02],\n",
      "        [-1.6825e+00, -1.3208e+00],\n",
      "        [-3.0305e-01, -4.3660e-01],\n",
      "        [ 1.3428e+00, -6.1975e-01],\n",
      "        [ 2.1400e-01,  2.5925e-01],\n",
      "        [ 9.1104e-01, -1.6325e+00],\n",
      "        [ 5.2676e-01, -3.3079e-01],\n",
      "        [-2.2507e-01,  1.3523e+00],\n",
      "        [ 7.8833e-01, -8.5587e-01],\n",
      "        [-1.0437e+00,  5.6355e-01],\n",
      "        [-2.3464e-01, -3.3874e-01],\n",
      "        [ 3.8445e-01,  2.5266e-01],\n",
      "        [ 4.9333e-01,  5.2861e-01],\n",
      "        [ 9.7989e-01,  3.0206e-01],\n",
      "        [-1.5453e+00,  8.0395e-01],\n",
      "        [ 5.4365e-01,  1.7245e-01],\n",
      "        [ 5.8008e-02,  6.7922e-01],\n",
      "        [ 6.6451e-01, -6.7640e-01],\n",
      "        [ 7.6306e-01, -1.4424e+00],\n",
      "        [ 4.8951e-01,  2.9201e-01],\n",
      "        [ 5.4984e-01, -7.0813e-01],\n",
      "        [ 9.6268e-01, -4.6212e-01],\n",
      "        [ 2.3864e-02, -1.3280e+00],\n",
      "        [-1.2309e-01,  4.6817e-01],\n",
      "        [ 4.4617e-01, -9.8295e-01],\n",
      "        [ 5.3132e-01, -1.7535e-02],\n",
      "        [-1.1607e+00,  1.1054e+00],\n",
      "        [ 2.8861e-01,  3.9475e-01],\n",
      "        [ 1.4033e-01,  3.1425e-01],\n",
      "        [ 1.0707e+00,  2.0454e-01],\n",
      "        [ 6.5564e-02,  2.8244e-01],\n",
      "        [ 2.3705e-01, -7.9842e-01],\n",
      "        [ 7.1119e-02,  7.5535e-01],\n",
      "        [ 3.0292e-01, -2.2571e-01],\n",
      "        [ 8.7983e-01,  2.1935e-01],\n",
      "        [ 2.7713e-01, -9.9048e-01],\n",
      "        [ 7.1745e-01, -2.3140e-01],\n",
      "        [ 5.0262e-01,  5.0680e-01],\n",
      "        [ 1.9968e-03, -9.8565e-01],\n",
      "        [ 5.9574e-01, -4.9686e-01],\n",
      "        [-3.5007e+00,  1.9838e+00],\n",
      "        [ 9.9271e-02, -2.1236e-01],\n",
      "        [ 1.6940e-01,  4.1210e-02],\n",
      "        [ 1.7910e-01,  1.3253e-01],\n",
      "        [ 1.3465e+00, -1.0333e+00],\n",
      "        [-2.1067e-01,  6.7709e-01],\n",
      "        [ 2.0410e-01, -3.1490e-01],\n",
      "        [ 5.6572e-01, -7.6137e-01],\n",
      "        [-6.6828e-01,  1.3278e+00],\n",
      "        [ 1.1827e+00, -5.7626e-01],\n",
      "        [ 4.0630e-01, -4.0105e-01],\n",
      "        [ 1.2370e+00, -4.9945e-01]], device='cuda:0')\n",
      "Action space size: 1455\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 17/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -0.7634443178069588\n",
      "Size of input data: torch.Size([305, 2])\n",
      "Size of embeddings: torch.Size([305, 2])\n",
      "Embeddings: tensor([[-3.5121,  3.9043],\n",
      "        [-3.2227,  4.7874],\n",
      "        [-4.9120,  4.5611],\n",
      "        [-4.4926,  4.7345],\n",
      "        [ 0.7608, -0.1396],\n",
      "        [ 0.5588,  0.0692],\n",
      "        [ 0.1245,  0.1265],\n",
      "        [ 0.2993,  0.6035],\n",
      "        [-0.9617, -0.1114],\n",
      "        [ 0.5267, -0.4100],\n",
      "        [ 0.3188, -1.3550],\n",
      "        [-1.2360,  1.7441],\n",
      "        [-2.1662,  0.0451],\n",
      "        [-0.1563, -0.4048],\n",
      "        [ 0.3096,  0.5204],\n",
      "        [-0.6289, -0.7718],\n",
      "        [-0.0269,  0.0758],\n",
      "        [ 0.0185, -0.1944],\n",
      "        [-1.2411,  1.7447],\n",
      "        [-1.1339,  0.1671],\n",
      "        [ 0.4871,  0.5469],\n",
      "        [-0.3178,  0.0891],\n",
      "        [-0.5761,  1.2833],\n",
      "        [-1.9369, -0.1720],\n",
      "        [-2.6145,  0.4979],\n",
      "        [-0.6380, -0.0738],\n",
      "        [-0.9740, -0.2194],\n",
      "        [-3.9770,  0.8541],\n",
      "        [ 0.5869,  0.5583],\n",
      "        [-0.0795, -0.4740],\n",
      "        [ 0.4451,  0.8603],\n",
      "        [-0.8703,  0.7242],\n",
      "        [-0.3801, -0.6935],\n",
      "        [ 0.0619,  0.1097],\n",
      "        [-0.0848,  0.9978],\n",
      "        [-1.5695, -0.6903],\n",
      "        [-0.5068,  1.6042],\n",
      "        [ 0.4387, -0.7360],\n",
      "        [-1.3301,  0.8999],\n",
      "        [ 0.9314, -0.6451],\n",
      "        [ 0.9000, -0.2150],\n",
      "        [ 0.0267,  1.0756],\n",
      "        [ 0.6560,  0.5368],\n",
      "        [-0.3073,  0.9101],\n",
      "        [ 0.1691, -0.0124],\n",
      "        [-0.7294, -0.3315],\n",
      "        [ 0.4730, -0.4536],\n",
      "        [-0.9240, -0.4753],\n",
      "        [ 0.3806, -0.4730],\n",
      "        [ 0.1278,  0.0346],\n",
      "        [ 0.1276,  0.2384],\n",
      "        [-1.8303, -0.0458],\n",
      "        [ 0.5901, -0.6927],\n",
      "        [ 0.7779, -0.8985],\n",
      "        [ 0.1839, -1.6755],\n",
      "        [ 0.0415, -1.3702],\n",
      "        [-0.9716, -0.9533],\n",
      "        [ 0.6857,  0.1265],\n",
      "        [ 0.1982,  0.1869],\n",
      "        [-0.0582,  1.1931],\n",
      "        [ 0.6607, -1.0321],\n",
      "        [-0.1210,  0.4922],\n",
      "        [ 0.0618,  0.0853],\n",
      "        [ 0.3443,  0.7703],\n",
      "        [-0.3825,  0.4734],\n",
      "        [ 0.5576, -0.2914],\n",
      "        [-1.0837, -1.6025],\n",
      "        [ 0.1791, -0.0280],\n",
      "        [ 0.6088, -0.5527],\n",
      "        [-0.3689, -0.6624],\n",
      "        [ 1.1804, -1.2213],\n",
      "        [-0.5242,  0.1882],\n",
      "        [-0.7708, -1.2855],\n",
      "        [-0.4332,  0.4402],\n",
      "        [-1.1038, -0.4891],\n",
      "        [ 0.5649,  0.4201],\n",
      "        [ 0.0360, -1.1713],\n",
      "        [-0.5091, -0.5649],\n",
      "        [-2.6419,  1.1559],\n",
      "        [ 0.5705, -0.1479],\n",
      "        [ 0.8172, -0.2140],\n",
      "        [-0.5726, -0.6903],\n",
      "        [ 0.5592, -0.6971],\n",
      "        [ 0.1139, -0.6337],\n",
      "        [-3.4738,  0.3345],\n",
      "        [-0.3945,  1.7478],\n",
      "        [ 0.7295, -0.9801],\n",
      "        [-0.8572, -1.5518],\n",
      "        [-0.4398,  0.2476],\n",
      "        [ 0.8070,  0.6967],\n",
      "        [ 1.2368, -1.3808],\n",
      "        [ 0.9064, -1.0759],\n",
      "        [-0.6102,  0.9145],\n",
      "        [ 0.4001, -1.2506],\n",
      "        [-0.6831,  0.2992],\n",
      "        [-0.2903,  1.2296],\n",
      "        [ 0.3065, -0.5651],\n",
      "        [ 0.8780, -0.3433],\n",
      "        [-0.3008,  1.5285],\n",
      "        [ 0.1603, -0.5997],\n",
      "        [-0.9384,  0.4402],\n",
      "        [ 0.5873, -1.0382],\n",
      "        [ 0.4618, -0.9200],\n",
      "        [ 0.5282, -0.9328],\n",
      "        [-0.5852,  0.6017],\n",
      "        [-0.4722,  0.4446],\n",
      "        [-0.1677,  0.6868],\n",
      "        [ 0.8211, -0.8059],\n",
      "        [ 0.2240, -0.2952],\n",
      "        [ 0.5488,  0.0066],\n",
      "        [ 0.1610, -0.3184],\n",
      "        [-0.1193, -0.0059],\n",
      "        [ 0.3433,  0.3438],\n",
      "        [-0.6332, -1.1415],\n",
      "        [-0.1117,  0.2266],\n",
      "        [-2.0730,  1.4078],\n",
      "        [-0.2128, -1.0254],\n",
      "        [-0.6323, -0.4483],\n",
      "        [-0.0907,  0.0461],\n",
      "        [ 0.6959, -1.6345],\n",
      "        [-0.0210, -0.0534],\n",
      "        [-1.2207, -1.5810],\n",
      "        [-0.8330,  0.2752],\n",
      "        [ 0.6915, -2.2290],\n",
      "        [ 0.2475, -0.2992],\n",
      "        [ 0.3759,  0.2282],\n",
      "        [ 0.3508,  0.0643],\n",
      "        [-1.0900,  2.0379],\n",
      "        [ 0.4890,  0.0450],\n",
      "        [-0.0689,  0.8806],\n",
      "        [ 0.1708, -0.0643],\n",
      "        [ 0.4181, -1.0246],\n",
      "        [ 0.0679,  1.0914],\n",
      "        [-0.5661,  0.6400],\n",
      "        [ 0.3988,  0.6365],\n",
      "        [-0.2536,  1.8142],\n",
      "        [-0.6724,  0.6722],\n",
      "        [ 0.2145,  1.5637],\n",
      "        [ 0.8355, -0.7046],\n",
      "        [ 0.1059, -0.8549],\n",
      "        [ 0.8342,  0.2703],\n",
      "        [ 0.9701, -0.1167],\n",
      "        [ 0.3297, -0.2938],\n",
      "        [ 0.9207,  0.2553],\n",
      "        [-0.6644,  1.9442],\n",
      "        [ 0.2083,  0.9400],\n",
      "        [ 1.0293,  0.1505],\n",
      "        [ 3.3407, -3.0861],\n",
      "        [-0.3311, -0.8039],\n",
      "        [ 1.2397, -1.1306],\n",
      "        [-0.0066, -0.6257],\n",
      "        [ 0.8550, -1.1129],\n",
      "        [ 0.1337,  0.1429],\n",
      "        [ 1.0093, -0.1119],\n",
      "        [ 1.1004, -0.3935],\n",
      "        [ 0.0735, -0.6899],\n",
      "        [ 0.2997,  0.2959],\n",
      "        [ 0.6339, -0.0677],\n",
      "        [ 0.9989, -0.1488],\n",
      "        [-0.9764,  2.2231],\n",
      "        [ 1.0524,  0.2087],\n",
      "        [ 0.3580, -0.4877],\n",
      "        [-2.6598,  0.2211],\n",
      "        [ 0.4116, -0.4553],\n",
      "        [ 1.0232, -0.5752],\n",
      "        [ 0.7647,  0.3904],\n",
      "        [ 1.1157, -1.1583],\n",
      "        [-0.5141,  0.4891],\n",
      "        [ 0.2894, -1.7222],\n",
      "        [-0.4435, -0.6966],\n",
      "        [ 0.2355, -0.5632],\n",
      "        [ 0.6650, -1.2638],\n",
      "        [-0.1357, -0.4502],\n",
      "        [ 0.2471, -0.3064],\n",
      "        [ 0.8517, -0.2139],\n",
      "        [ 0.7187, -0.5519],\n",
      "        [ 0.8208,  0.6628],\n",
      "        [-1.0652,  0.1746],\n",
      "        [ 0.4792, -0.0587],\n",
      "        [-0.2496,  0.0421],\n",
      "        [ 0.4418,  0.7201],\n",
      "        [ 0.1022,  0.0521],\n",
      "        [-0.2678, -0.9100],\n",
      "        [-1.0331,  1.6775],\n",
      "        [-0.1558,  1.0030],\n",
      "        [ 0.6850, -0.0993],\n",
      "        [ 1.0087, -0.3510],\n",
      "        [-0.3776,  0.9223],\n",
      "        [ 0.7142, -1.0940],\n",
      "        [ 0.2182,  0.9399],\n",
      "        [ 0.7306,  0.2817],\n",
      "        [-2.8775,  1.9483],\n",
      "        [-0.4349, -1.4184],\n",
      "        [ 0.4291,  0.4396],\n",
      "        [ 1.1939,  0.4578],\n",
      "        [ 0.7667, -0.3713],\n",
      "        [ 0.6596,  0.7164],\n",
      "        [ 2.9338, -1.9551],\n",
      "        [-0.6106, -0.4452],\n",
      "        [ 0.4801,  1.0758],\n",
      "        [ 0.7899, -0.5993],\n",
      "        [ 1.1245, -1.1761],\n",
      "        [ 0.7184, -1.1417],\n",
      "        [ 0.3283, -1.2140],\n",
      "        [ 0.2841, -0.8444],\n",
      "        [ 0.4756, -0.6365],\n",
      "        [ 0.0126, -1.8849],\n",
      "        [ 0.7633, -0.9077],\n",
      "        [ 0.4431,  0.7340],\n",
      "        [ 0.5232, -1.2529],\n",
      "        [ 0.6022, -1.3061],\n",
      "        [-0.0305,  0.0924],\n",
      "        [ 0.8105,  0.1960],\n",
      "        [ 0.7287,  1.2198],\n",
      "        [ 0.9092,  0.4896],\n",
      "        [-0.0442,  0.5376],\n",
      "        [ 0.4506, -0.3548],\n",
      "        [ 0.2653, -1.2639],\n",
      "        [ 0.3441,  0.7750],\n",
      "        [ 0.7505, -0.1946],\n",
      "        [-0.3448,  0.7783],\n",
      "        [ 0.4042,  0.5172],\n",
      "        [ 0.1657,  0.7272],\n",
      "        [ 0.3444,  0.5039],\n",
      "        [ 0.8983, -0.4974],\n",
      "        [ 0.8731, -0.7406],\n",
      "        [ 0.4813,  0.8435],\n",
      "        [-0.2924, -1.5405],\n",
      "        [ 0.5775,  0.4511],\n",
      "        [ 0.3738, -0.4009],\n",
      "        [-0.2065, -0.2716],\n",
      "        [ 0.1624,  0.5788],\n",
      "        [-0.3687,  0.2760],\n",
      "        [-0.0605, -0.9756],\n",
      "        [ 0.5733,  0.7633],\n",
      "        [ 0.8999, -0.0338],\n",
      "        [-0.4293,  0.8908],\n",
      "        [-1.5545, -0.7522],\n",
      "        [ 0.2933,  0.9470],\n",
      "        [ 0.9480,  0.6908],\n",
      "        [ 0.8072, -0.8153],\n",
      "        [-3.1964,  1.3279],\n",
      "        [ 0.5081,  0.3694],\n",
      "        [ 1.1094, -0.0074],\n",
      "        [-1.4816, -0.9206],\n",
      "        [ 0.7730,  0.0199],\n",
      "        [ 0.8918, -1.2132],\n",
      "        [ 0.0091,  0.5770],\n",
      "        [ 0.4648, -1.5183],\n",
      "        [ 1.0611, -0.0875],\n",
      "        [-0.9985, -0.1462],\n",
      "        [-0.5570, -2.0312],\n",
      "        [-1.1335,  0.3290],\n",
      "        [ 0.6176, -0.1774],\n",
      "        [-0.6132, -0.0915],\n",
      "        [ 0.3165,  0.7398],\n",
      "        [ 0.7363, -0.4726],\n",
      "        [-1.0934,  0.1689],\n",
      "        [ 0.3515,  0.4814],\n",
      "        [ 0.1686,  1.0430],\n",
      "        [-0.0246, -0.1736],\n",
      "        [ 1.0888, -0.3534],\n",
      "        [ 0.0136,  0.3105],\n",
      "        [ 0.7093, -0.7654],\n",
      "        [ 1.0009,  0.0310],\n",
      "        [-0.0817, -0.7668],\n",
      "        [ 0.7919,  0.6406],\n",
      "        [ 0.5186, -0.8195],\n",
      "        [ 0.4499,  0.6628],\n",
      "        [-0.8784, -0.1073],\n",
      "        [ 0.5772, -0.2291],\n",
      "        [ 0.5299,  0.5891],\n",
      "        [ 0.7345, -0.4348],\n",
      "        [ 0.4016,  0.9218],\n",
      "        [-0.2131, -0.1097],\n",
      "        [-0.6387,  1.4108],\n",
      "        [-0.0478,  0.8329],\n",
      "        [ 0.0712, -1.1031],\n",
      "        [ 1.1512, -0.8527],\n",
      "        [ 0.3419, -1.4064],\n",
      "        [ 0.3489,  0.8487],\n",
      "        [ 0.4022, -0.7952],\n",
      "        [ 0.9844, -0.2899],\n",
      "        [-3.0223,  1.2343],\n",
      "        [ 0.1093, -0.3549],\n",
      "        [ 0.1468, -0.8214],\n",
      "        [ 0.4396, -0.4552],\n",
      "        [ 0.8551, -0.6205],\n",
      "        [-0.0858,  0.8477],\n",
      "        [ 0.1229,  0.7110],\n",
      "        [ 0.3895, -1.1399],\n",
      "        [-0.6232,  1.4621],\n",
      "        [ 0.8269, -0.2282],\n",
      "        [ 0.9551, -0.3513],\n",
      "        [ 0.4586, -0.3982],\n",
      "        [-0.3222,  0.4593],\n",
      "        [-2.1545,  0.6531],\n",
      "        [-1.3455,  1.2848],\n",
      "        [-0.0586,  0.9162],\n",
      "        [ 0.5394,  1.0407],\n",
      "        [ 0.6844,  0.7067],\n",
      "        [ 0.8289, -0.0176],\n",
      "        [-1.3819, -0.5192],\n",
      "        [ 0.3981, -1.8527],\n",
      "        [-0.2255,  0.3952]], device='cuda:0')\n",
      "Action space size: 1505\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 18/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -0.6870998860262629\n",
      "Size of input data: torch.Size([320, 2])\n",
      "Size of embeddings: torch.Size([320, 2])\n",
      "Embeddings: tensor([[-3.9175e+00,  3.7039e+00],\n",
      "        [-4.1166e+00,  5.0314e+00],\n",
      "        [-5.2786e+00,  4.7212e+00],\n",
      "        [-4.5014e+00,  4.5795e+00],\n",
      "        [ 1.4228e+00, -2.2950e-01],\n",
      "        [-5.3804e-02, -9.9682e-02],\n",
      "        [ 1.1993e-01, -2.4164e-01],\n",
      "        [ 9.3872e-03,  4.8508e-01],\n",
      "        [-6.3138e-01,  6.4897e-01],\n",
      "        [ 9.1683e-01, -4.5337e-01],\n",
      "        [ 4.0428e-01, -7.3583e-01],\n",
      "        [-1.3847e+00,  2.0397e+00],\n",
      "        [-1.0299e+00, -5.6293e-01],\n",
      "        [ 4.6130e-01, -9.1328e-03],\n",
      "        [ 4.6621e-01,  1.0478e+00],\n",
      "        [-3.8442e-01, -2.2575e-02],\n",
      "        [-3.9851e-02, -1.4883e-01],\n",
      "        [ 8.9009e-01, -8.9382e-02],\n",
      "        [-1.0541e+00,  1.9191e+00],\n",
      "        [-5.0498e-01, -3.2592e-01],\n",
      "        [ 3.4611e-01,  9.5471e-01],\n",
      "        [ 1.7479e-02,  9.5461e-02],\n",
      "        [-6.8737e-01,  1.0364e+00],\n",
      "        [-1.2013e+00, -3.5867e-01],\n",
      "        [-2.1409e+00, -1.0721e+00],\n",
      "        [-4.9051e-01, -1.2042e-01],\n",
      "        [-6.2959e-01, -1.5449e-02],\n",
      "        [-3.0886e+00,  3.0958e-02],\n",
      "        [ 5.5183e-01,  5.4049e-02],\n",
      "        [-1.5706e-01, -2.7319e-01],\n",
      "        [ 2.8535e-01,  8.3016e-01],\n",
      "        [-1.2723e+00,  3.3726e-01],\n",
      "        [-7.5464e-01, -9.7282e-01],\n",
      "        [-4.4319e-01,  1.5301e-01],\n",
      "        [-7.4321e-01,  5.2773e-01],\n",
      "        [-5.2867e-01, -5.5564e-01],\n",
      "        [-1.4305e+00,  2.3701e+00],\n",
      "        [ 7.6481e-01, -7.3916e-01],\n",
      "        [-1.3921e+00,  4.5139e-01],\n",
      "        [ 1.1426e+00, -6.2427e-01],\n",
      "        [ 5.1555e-01, -1.1998e-02],\n",
      "        [-2.2352e+00,  1.4449e+00],\n",
      "        [ 3.9596e-01,  2.3553e-01],\n",
      "        [ 1.4812e-01,  1.2822e+00],\n",
      "        [ 3.2300e-01, -3.3875e-02],\n",
      "        [ 7.9780e-01, -2.7881e-01],\n",
      "        [-5.6032e-01, -4.5654e-01],\n",
      "        [ 5.9207e-01,  4.1961e-01],\n",
      "        [ 1.1052e+00, -4.7149e-01],\n",
      "        [ 8.1102e-01,  4.5572e-01],\n",
      "        [ 4.2627e-01,  7.9861e-01],\n",
      "        [-1.1723e+00, -1.2271e+00],\n",
      "        [ 3.0750e-01, -6.4871e-01],\n",
      "        [ 2.0168e-01, -6.7267e-01],\n",
      "        [ 2.1075e+00, -1.3511e+00],\n",
      "        [ 1.3914e+00, -4.2721e-01],\n",
      "        [-8.7684e-01, -3.8793e-01],\n",
      "        [-2.8021e-01,  1.9158e-02],\n",
      "        [-8.3583e-02,  4.2293e-01],\n",
      "        [ 1.6492e-01,  9.3903e-01],\n",
      "        [-2.2348e-01, -6.7246e-01],\n",
      "        [ 7.4114e-02,  5.9087e-01],\n",
      "        [-3.4760e-01,  1.6483e-01],\n",
      "        [ 3.9035e-01,  3.0419e-01],\n",
      "        [ 5.5647e-01,  2.9666e-01],\n",
      "        [ 1.1017e+00, -2.8988e-01],\n",
      "        [-7.5185e-01, -3.9957e-01],\n",
      "        [-2.2554e-01, -4.2808e-01],\n",
      "        [ 4.5874e-01, -2.6184e-02],\n",
      "        [ 8.0121e-01, -8.9292e-02],\n",
      "        [ 1.1322e+00, -1.5554e+00],\n",
      "        [-3.5334e-01,  2.7326e-01],\n",
      "        [-7.7060e-01, -1.4698e+00],\n",
      "        [ 6.7907e-03,  2.8216e-01],\n",
      "        [-1.9877e-02,  7.2368e-01],\n",
      "        [-3.6365e-02,  8.8134e-01],\n",
      "        [-5.4693e-01, -1.1958e+00],\n",
      "        [-1.4310e+00, -4.1775e-01],\n",
      "        [-2.4845e+00,  3.6215e-01],\n",
      "        [ 3.7454e-01, -3.7495e-01],\n",
      "        [ 4.3878e-01, -1.8320e-02],\n",
      "        [-8.9213e-01, -9.7807e-01],\n",
      "        [ 2.3113e-01, -5.4993e-02],\n",
      "        [ 6.0281e-01, -3.2365e-01],\n",
      "        [-2.0519e+00, -1.1178e-02],\n",
      "        [-1.9469e-03,  1.2746e+00],\n",
      "        [-2.8952e-01, -1.3533e+00],\n",
      "        [-1.8015e+00, -9.6581e-01],\n",
      "        [-5.3046e-01, -8.7540e-02],\n",
      "        [ 4.2690e-01,  8.4540e-01],\n",
      "        [ 7.7051e-01, -9.9491e-01],\n",
      "        [ 6.9216e-01, -1.1311e+00],\n",
      "        [-7.2643e-01,  6.4407e-01],\n",
      "        [ 1.1554e+00, -1.0085e+00],\n",
      "        [-7.4657e-01,  6.1573e-01],\n",
      "        [ 4.9796e-01,  6.0711e-01],\n",
      "        [ 2.9211e-01, -7.0816e-01],\n",
      "        [ 4.4933e-01, -1.4263e-01],\n",
      "        [-3.9832e-01,  1.5687e+00],\n",
      "        [ 5.9225e-01, -7.2569e-01],\n",
      "        [-1.2526e+00,  6.5733e-01],\n",
      "        [ 2.6734e-01, -7.8766e-01],\n",
      "        [ 4.1762e-01, -9.5671e-01],\n",
      "        [-5.9489e-01, -1.2561e+00],\n",
      "        [ 1.8197e-01,  6.3644e-01],\n",
      "        [-8.5413e-01,  5.6090e-01],\n",
      "        [-6.4071e-01,  9.4520e-01],\n",
      "        [ 5.5845e-01, -1.1959e+00],\n",
      "        [ 3.3581e-02, -2.6725e-01],\n",
      "        [ 2.9256e-01,  3.7698e-01],\n",
      "        [ 6.5512e-01,  1.3797e-01],\n",
      "        [-1.1120e+00,  3.8800e-01],\n",
      "        [ 2.9980e-01, -2.6664e-01],\n",
      "        [ 6.5012e-01, -2.2824e-01],\n",
      "        [-5.8008e-01,  2.2439e-01],\n",
      "        [-1.0497e+00,  1.2975e+00],\n",
      "        [-6.1976e-01, -1.0131e+00],\n",
      "        [ 1.0268e+00,  9.4817e-02],\n",
      "        [-2.6388e-01, -1.5321e-01],\n",
      "        [ 8.2089e-02, -1.8350e+00],\n",
      "        [-1.5450e+00, -1.0891e-01],\n",
      "        [-1.9570e+00, -1.0676e+00],\n",
      "        [-1.2293e+00,  1.4512e-01],\n",
      "        [ 9.6810e-01, -2.1001e+00],\n",
      "        [ 7.9379e-01, -1.4385e+00],\n",
      "        [ 2.9981e-01, -6.8442e-02],\n",
      "        [-2.8778e-01,  7.1174e-02],\n",
      "        [-2.1341e+00,  2.8443e+00],\n",
      "        [ 1.6506e-01, -1.0193e+00],\n",
      "        [-9.7231e-01,  7.2855e-01],\n",
      "        [-1.5098e-01, -8.5759e-04],\n",
      "        [ 2.8635e-01, -7.1615e-01],\n",
      "        [-1.2852e-01,  1.2137e+00],\n",
      "        [-9.7251e-01,  4.4028e-01],\n",
      "        [ 1.4619e-02,  7.1763e-01],\n",
      "        [ 6.5329e-01,  1.0956e+00],\n",
      "        [-1.9570e+00,  7.0481e-01],\n",
      "        [ 2.7190e-03,  7.6786e-01],\n",
      "        [ 1.4608e+00, -8.8848e-01],\n",
      "        [-1.3884e-01, -7.6773e-01],\n",
      "        [ 2.7769e-01,  3.5686e-01],\n",
      "        [ 6.1707e-01,  4.8278e-02],\n",
      "        [ 2.8950e-01, -8.9349e-01],\n",
      "        [ 7.9240e-01,  5.1331e-01],\n",
      "        [-1.7122e+00,  2.6130e+00],\n",
      "        [ 6.3963e-01,  1.3261e+00],\n",
      "        [ 9.8980e-01, -5.9708e-01],\n",
      "        [ 2.0900e+00, -4.2126e+00],\n",
      "        [-3.7957e-01, -9.6413e-01],\n",
      "        [ 1.3473e+00, -1.6254e+00],\n",
      "        [ 3.8459e-01, -1.1677e-01],\n",
      "        [ 1.6114e-01, -7.1932e-01],\n",
      "        [ 8.6448e-01, -2.6725e-01],\n",
      "        [ 6.5997e-01, -1.6839e-01],\n",
      "        [ 1.0726e+00, -3.9360e-01],\n",
      "        [-8.0197e-01, -7.4502e-01],\n",
      "        [ 4.0709e-01,  1.7904e-01],\n",
      "        [ 1.3691e+00, -3.6318e-01],\n",
      "        [ 6.0455e-01, -1.7710e-01],\n",
      "        [-8.0549e-01,  1.6709e+00],\n",
      "        [ 1.0295e+00,  9.2582e-02],\n",
      "        [ 4.7501e-01, -4.9377e-01],\n",
      "        [-2.2700e+00,  3.6867e-02],\n",
      "        [ 1.2488e+00, -1.9377e-01],\n",
      "        [ 3.9591e-01, -1.2701e+00],\n",
      "        [ 1.0143e+00, -4.6218e-03],\n",
      "        [ 9.3444e-01, -1.0779e+00],\n",
      "        [-6.6768e-01,  8.3197e-01],\n",
      "        [ 1.2178e+00, -1.3782e+00],\n",
      "        [ 3.1570e-01,  1.4325e-01],\n",
      "        [ 9.9589e-03,  5.5117e-02],\n",
      "        [-6.6110e-02, -1.2210e+00],\n",
      "        [ 3.2915e-01, -2.9864e-01],\n",
      "        [-5.6032e-01, -3.7900e-01],\n",
      "        [ 9.5566e-01, -5.9445e-01],\n",
      "        [ 3.4452e-01, -6.7337e-01],\n",
      "        [ 7.0591e-01,  6.7228e-01],\n",
      "        [-3.2729e-01, -1.9278e-01],\n",
      "        [ 4.8135e-01, -1.5241e-01],\n",
      "        [-1.6319e-01, -8.6634e-01],\n",
      "        [ 4.2218e-01,  7.4604e-01],\n",
      "        [-3.3609e-01, -2.6847e-01],\n",
      "        [-8.8809e-01, -9.0060e-01],\n",
      "        [-1.8225e+00,  1.8575e+00],\n",
      "        [ 3.4246e-01,  1.1210e+00],\n",
      "        [ 6.5666e-01,  2.2937e-01],\n",
      "        [ 9.2321e-01, -7.2575e-01],\n",
      "        [-1.8129e-01,  4.0601e-01],\n",
      "        [ 3.8261e-01, -7.2578e-01],\n",
      "        [ 3.2748e-01,  4.3605e-01],\n",
      "        [ 6.0900e-02, -4.3613e-02],\n",
      "        [-1.7476e+00,  2.0125e+00],\n",
      "        [ 7.5856e-01, -8.8920e-01],\n",
      "        [ 5.0001e-01,  7.3333e-01],\n",
      "        [ 6.1829e-01,  5.2492e-01],\n",
      "        [ 5.3345e-01,  3.2901e-02],\n",
      "        [ 2.3741e-01,  3.5685e-01],\n",
      "        [-2.1767e+00, -2.5301e+00],\n",
      "        [ 1.3924e-01, -6.5985e-01],\n",
      "        [-3.2583e-01,  8.4154e-01],\n",
      "        [ 8.3314e-01, -7.7254e-01],\n",
      "        [ 2.0855e-01, -1.0868e+00],\n",
      "        [ 7.6989e-01, -9.7792e-01],\n",
      "        [-1.1479e-01, -8.8636e-01],\n",
      "        [ 3.2752e-01, -1.0694e+00],\n",
      "        [ 1.8054e-01, -1.1316e+00],\n",
      "        [-2.5440e-01, -1.2706e+00],\n",
      "        [ 5.1458e-01, -1.1028e+00],\n",
      "        [ 7.2676e-01,  9.6205e-01],\n",
      "        [ 7.1230e-01, -1.2016e+00],\n",
      "        [ 8.6832e-02, -8.1087e-01],\n",
      "        [ 7.9673e-01,  2.7219e-01],\n",
      "        [ 8.1099e-01, -2.1446e-01],\n",
      "        [ 4.5385e-01,  1.3288e+00],\n",
      "        [ 9.6005e-01,  9.4019e-01],\n",
      "        [ 6.1409e-01,  7.9310e-01],\n",
      "        [-2.3660e-01, -1.3829e-01],\n",
      "        [ 8.0096e-02, -8.7169e-01],\n",
      "        [ 2.3437e-01,  1.0359e+00],\n",
      "        [ 1.0391e+00, -3.8995e-01],\n",
      "        [-2.8160e-01,  8.6004e-01],\n",
      "        [ 5.7370e-01,  1.3724e-01],\n",
      "        [ 5.6645e-01,  1.2199e+00],\n",
      "        [-4.7554e-01,  4.2730e-01],\n",
      "        [ 7.2332e-01, -1.0626e+00],\n",
      "        [ 1.2038e+00, -7.9459e-01],\n",
      "        [ 5.5192e-01,  9.1039e-01],\n",
      "        [-9.1925e-01, -1.3217e+00],\n",
      "        [ 2.6020e-01,  8.1648e-01],\n",
      "        [ 4.9827e-01, -4.8169e-01],\n",
      "        [-2.2782e-01,  2.1204e-01],\n",
      "        [ 4.5946e-01,  6.5688e-01],\n",
      "        [-1.2968e+00,  1.0205e+00],\n",
      "        [ 1.6716e+00, -5.1743e-01],\n",
      "        [-1.7985e-01,  7.4855e-01],\n",
      "        [ 1.1000e+00,  2.3277e-01],\n",
      "        [-4.4266e-01,  9.9705e-01],\n",
      "        [-8.2099e-01,  1.3800e-02],\n",
      "        [-8.4832e-01,  8.9232e-01],\n",
      "        [ 7.7450e-01,  8.6829e-01],\n",
      "        [ 1.1297e+00, -7.9851e-01],\n",
      "        [-2.9609e+00,  1.8370e-01],\n",
      "        [ 3.4885e-01,  4.6807e-01],\n",
      "        [ 8.6445e-01, -1.9466e-01],\n",
      "        [-7.5727e-01, -7.2666e-01],\n",
      "        [-1.1445e+00, -2.5182e-01],\n",
      "        [ 7.4372e-01, -1.3440e+00],\n",
      "        [ 4.6585e-02,  5.1685e-01],\n",
      "        [ 2.4886e-01, -1.9427e+00],\n",
      "        [ 6.1445e-01, -6.1565e-01],\n",
      "        [-5.2128e-01,  4.9715e-01],\n",
      "        [ 1.9726e+00, -1.5141e+00],\n",
      "        [-1.1812e+00, -2.4020e-01],\n",
      "        [ 8.5615e-01, -1.4596e-01],\n",
      "        [ 9.1458e-01,  9.8290e-02],\n",
      "        [ 1.9428e-01,  6.5497e-01],\n",
      "        [ 1.0915e+00, -4.6293e-01],\n",
      "        [-1.9032e+00, -7.0800e-02],\n",
      "        [ 4.2812e-01,  8.3489e-01],\n",
      "        [ 2.1624e-01,  7.9808e-01],\n",
      "        [ 5.4486e-01, -6.7880e-02],\n",
      "        [ 2.9510e-01, -1.1500e+00],\n",
      "        [ 3.3495e-01,  8.1985e-01],\n",
      "        [ 8.0585e-01, -8.6682e-01],\n",
      "        [ 7.5025e-01, -6.2516e-01],\n",
      "        [ 3.2338e-01, -8.7333e-01],\n",
      "        [ 2.3570e-01,  5.7519e-01],\n",
      "        [ 6.9548e-01, -9.6723e-01],\n",
      "        [ 5.9829e-01,  8.6342e-01],\n",
      "        [-6.0035e-01, -2.8560e-01],\n",
      "        [ 1.4529e-01, -3.6717e-02],\n",
      "        [ 4.5813e-01,  8.9106e-01],\n",
      "        [ 1.1623e+00, -6.2765e-01],\n",
      "        [ 2.2295e-01,  6.4463e-01],\n",
      "        [ 1.1664e-01, -5.1345e-01],\n",
      "        [-2.0145e-01,  1.4753e+00],\n",
      "        [-2.3093e-01,  3.7005e-01],\n",
      "        [ 9.1565e-01, -3.1690e-01],\n",
      "        [ 7.1275e-01, -8.1692e-01],\n",
      "        [ 8.9983e-01, -1.1321e+00],\n",
      "        [ 1.9789e-01,  7.8584e-01],\n",
      "        [-2.1293e-01, -6.8285e-01],\n",
      "        [ 8.4954e-01, -2.6688e-01],\n",
      "        [-2.7146e+00,  3.6949e-01],\n",
      "        [-3.9691e-01, -1.7541e-01],\n",
      "        [-7.0091e-02, -5.9350e-01],\n",
      "        [-7.5280e-02, -5.0865e-01],\n",
      "        [ 3.6832e-01, -5.8953e-01],\n",
      "        [-7.2214e-01,  9.3947e-01],\n",
      "        [-2.9845e-01,  6.2590e-01],\n",
      "        [ 3.7647e-01, -1.3950e+00],\n",
      "        [-5.8893e-01,  9.8450e-01],\n",
      "        [ 8.0372e-01, -1.7602e-01],\n",
      "        [ 8.2969e-01, -3.4665e-01],\n",
      "        [ 8.2251e-01, -1.7277e-01],\n",
      "        [-5.7636e-01,  2.8297e-01],\n",
      "        [-1.9432e+00,  1.5466e-01],\n",
      "        [-3.7729e-01,  1.1992e+00],\n",
      "        [-2.1119e-01,  1.1824e-01],\n",
      "        [ 4.3472e-01,  5.9135e-01],\n",
      "        [ 3.3342e-01,  1.1451e+00],\n",
      "        [ 1.1045e+00, -2.7373e-01],\n",
      "        [-1.0371e+00,  4.8843e-01],\n",
      "        [ 4.7480e-01, -1.2854e+00],\n",
      "        [ 3.8984e-01, -2.7753e-01],\n",
      "        [ 3.3499e-01,  9.5856e-02],\n",
      "        [ 1.1704e+00, -7.1388e-01],\n",
      "        [ 5.4720e-01, -1.2347e+00],\n",
      "        [ 2.4890e-01,  4.1786e-01],\n",
      "        [ 5.9478e-01,  1.1183e+00],\n",
      "        [ 6.9979e-01,  1.8641e-01],\n",
      "        [ 9.4888e-01, -5.3403e-01],\n",
      "        [-9.5433e-02, -4.8112e-01],\n",
      "        [ 2.7816e-01,  3.0746e-01],\n",
      "        [ 6.2503e-01, -1.6187e-01],\n",
      "        [-1.0883e+00,  2.1722e+00],\n",
      "        [ 9.7028e-01,  3.6741e-01],\n",
      "        [ 4.5919e-01, -2.0056e-01],\n",
      "        [ 8.8073e-01, -1.1681e+00],\n",
      "        [ 8.4290e-01,  1.4427e-01]], device='cuda:0')\n",
      "Action space size: 1580\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 19/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -0.6183898974236366\n",
      "Size of input data: torch.Size([337, 2])\n",
      "Size of embeddings: torch.Size([337, 2])\n",
      "Embeddings: tensor([[-3.1617e+00,  4.1329e+00],\n",
      "        [-3.7375e+00,  4.7001e+00],\n",
      "        [-4.5931e+00,  4.2985e+00],\n",
      "        [-4.9895e+00,  4.7055e+00],\n",
      "        [ 1.7702e-01, -5.4470e-01],\n",
      "        [-2.1114e-01,  3.7801e-01],\n",
      "        [-2.8101e-01,  2.6985e-01],\n",
      "        [ 3.4884e-01,  3.0828e-01],\n",
      "        [ 1.1050e+00,  3.4296e-01],\n",
      "        [ 1.6484e-01, -2.5038e-01],\n",
      "        [ 1.3068e+00, -3.5747e-01],\n",
      "        [-1.1657e+00,  1.9827e+00],\n",
      "        [-8.4680e-01, -1.4346e+00],\n",
      "        [-2.6443e-01, -3.9280e-01],\n",
      "        [ 9.3613e-01,  9.1082e-01],\n",
      "        [ 7.1493e-01, -8.3149e-01],\n",
      "        [-2.7638e-01,  4.5797e-01],\n",
      "        [ 2.3374e-01,  2.8351e-01],\n",
      "        [-3.6683e+00,  2.2830e+00],\n",
      "        [-4.6319e-01, -1.4329e-01],\n",
      "        [ 9.3551e-01,  8.2140e-01],\n",
      "        [-1.0052e+00, -2.5770e-01],\n",
      "        [-8.5730e-02,  9.4531e-01],\n",
      "        [-1.4395e+00, -1.4905e+00],\n",
      "        [-3.2978e+00,  2.3326e-01],\n",
      "        [-1.5894e+00, -3.9449e-01],\n",
      "        [-8.2975e-01,  9.4655e-01],\n",
      "        [-2.2906e+00,  9.1861e-01],\n",
      "        [ 9.5274e-01,  1.0375e-01],\n",
      "        [-5.5746e-01,  5.9859e-02],\n",
      "        [ 5.3008e-01,  7.5790e-01],\n",
      "        [-1.7920e+00,  1.1392e+00],\n",
      "        [ 5.1000e-02, -1.7498e+00],\n",
      "        [-4.3307e-02, -2.4915e-01],\n",
      "        [-1.9208e-02,  2.1889e-01],\n",
      "        [-6.1176e-01, -2.1069e+00],\n",
      "        [-3.3632e+00,  1.9461e+00],\n",
      "        [ 5.6305e-01, -2.9382e-01],\n",
      "        [-2.1045e+00,  8.7670e-01],\n",
      "        [ 1.1285e+00, -7.4515e-01],\n",
      "        [ 1.1332e+00,  6.2696e-01],\n",
      "        [-1.6690e+00,  1.9595e+00],\n",
      "        [ 5.1725e-01,  6.2571e-01],\n",
      "        [ 1.4282e-01,  1.0067e+00],\n",
      "        [ 8.8966e-02,  1.8469e-02],\n",
      "        [-1.1370e-01,  7.6711e-02],\n",
      "        [-4.0051e-01, -9.6316e-01],\n",
      "        [ 5.5138e-01, -1.0046e+00],\n",
      "        [ 2.8985e-02, -1.4025e-01],\n",
      "        [ 1.9795e-01,  5.1515e-01],\n",
      "        [-1.0603e+00,  9.7644e-01],\n",
      "        [-1.4004e+00,  7.8955e-01],\n",
      "        [ 6.8653e-01, -7.5353e-01],\n",
      "        [ 5.7306e-01, -2.1530e-01],\n",
      "        [ 8.9801e-01, -1.5909e+00],\n",
      "        [ 6.1199e-01, -7.7031e-01],\n",
      "        [ 9.9273e-01, -9.0291e-01],\n",
      "        [ 8.5332e-01,  4.7345e-01],\n",
      "        [ 9.7949e-02, -2.8035e-02],\n",
      "        [-5.2996e-01,  7.8788e-01],\n",
      "        [ 1.5618e-02, -7.2527e-01],\n",
      "        [ 3.8819e-01,  4.8903e-01],\n",
      "        [-2.0185e-01, -1.0263e-02],\n",
      "        [ 3.0276e-01,  4.3447e-01],\n",
      "        [-6.4929e-01,  3.3869e-01],\n",
      "        [ 3.7501e-01,  2.2413e-01],\n",
      "        [ 7.4710e-01, -7.4845e-01],\n",
      "        [ 3.9079e-01, -2.1007e-02],\n",
      "        [ 8.6917e-01, -8.2431e-02],\n",
      "        [ 7.9489e-01, -8.6321e-01],\n",
      "        [ 4.3730e-01, -1.7911e+00],\n",
      "        [-8.7597e-01, -1.6444e-01],\n",
      "        [ 5.8958e-01, -4.2828e-01],\n",
      "        [-1.0942e+00,  3.0902e-01],\n",
      "        [ 6.8582e-03, -6.0315e-01],\n",
      "        [ 1.6755e-02,  9.1091e-02],\n",
      "        [ 2.3593e-01, -1.3613e+00],\n",
      "        [-2.2615e-01,  1.0406e-01],\n",
      "        [-2.8895e+00,  1.0320e+00],\n",
      "        [ 6.7917e-01, -8.1334e-01],\n",
      "        [ 1.9690e-01,  4.3246e-01],\n",
      "        [ 3.9542e-01,  5.5432e-01],\n",
      "        [ 5.2904e-01, -3.9737e-01],\n",
      "        [ 1.3083e-01, -4.4328e-01],\n",
      "        [-6.7370e-01, -9.2407e-01],\n",
      "        [-4.5848e-01,  1.2513e+00],\n",
      "        [-2.1749e-01, -1.0645e+00],\n",
      "        [-5.3925e-02, -8.9932e-01],\n",
      "        [-4.2404e-01, -6.5064e-01],\n",
      "        [ 9.9149e-01,  8.2026e-01],\n",
      "        [ 1.1063e+00, -5.9030e-01],\n",
      "        [ 9.7092e-01, -1.2025e+00],\n",
      "        [-1.2839e+00,  4.8039e-01],\n",
      "        [ 2.0013e-01, -1.7100e+00],\n",
      "        [ 3.5174e-02,  9.0466e-01],\n",
      "        [ 2.7435e-01,  1.3046e+00],\n",
      "        [ 1.8061e-01, -7.3592e-01],\n",
      "        [ 2.8865e-01, -1.8670e-01],\n",
      "        [-7.8876e-01,  1.4842e+00],\n",
      "        [ 8.3653e-01, -4.0513e-02],\n",
      "        [-4.2202e-01,  4.1430e-01],\n",
      "        [ 1.2968e+00, -9.3929e-01],\n",
      "        [ 1.1012e+00, -7.8771e-01],\n",
      "        [-6.3894e-01, -3.7500e-01],\n",
      "        [-7.9633e-01,  3.5297e-01],\n",
      "        [-9.4324e-01,  1.5847e-01],\n",
      "        [-3.4132e-01,  6.1404e-02],\n",
      "        [ 6.9351e-01, -1.1209e+00],\n",
      "        [-2.5052e-01,  4.3857e-01],\n",
      "        [ 1.5678e-01, -5.4250e-02],\n",
      "        [ 3.5449e-01,  5.2850e-01],\n",
      "        [-7.4411e-01, -2.5356e-01],\n",
      "        [-4.1429e-01,  5.9326e-01],\n",
      "        [-1.1363e-01, -8.9699e-01],\n",
      "        [-2.3890e-01, -7.4693e-02],\n",
      "        [-2.0080e+00,  5.7602e-01],\n",
      "        [ 1.8906e-01, -1.0772e+00],\n",
      "        [ 9.6109e-01, -1.0116e+00],\n",
      "        [ 1.3622e-01, -7.5588e-01],\n",
      "        [ 6.9694e-01, -1.8666e+00],\n",
      "        [-6.7232e-01, -1.1948e-01],\n",
      "        [ 1.2550e+00,  1.9361e-01],\n",
      "        [-2.0178e-01,  6.0557e-01],\n",
      "        [ 6.4883e-01, -2.4719e+00],\n",
      "        [-3.1543e-01, -1.1419e+00],\n",
      "        [ 5.7851e-02,  5.2867e-02],\n",
      "        [-2.4779e-01,  5.8680e-01],\n",
      "        [-2.6791e+00,  1.9845e+00],\n",
      "        [-1.6186e-01, -1.0233e+00],\n",
      "        [-2.0387e+00,  8.0727e-01],\n",
      "        [-6.6194e-02,  5.3852e-01],\n",
      "        [ 3.0002e-01, -2.7513e-01],\n",
      "        [ 3.6634e-01,  7.2685e-01],\n",
      "        [ 4.2269e-02,  3.8930e-01],\n",
      "        [ 5.9982e-01,  7.2536e-01],\n",
      "        [-6.1918e-01,  1.2879e+00],\n",
      "        [-3.4217e-01,  9.0163e-01],\n",
      "        [ 4.4389e-01,  1.1095e+00],\n",
      "        [ 4.5613e-02, -1.5061e+00],\n",
      "        [-2.4324e-01, -1.6179e+00],\n",
      "        [ 6.7022e-01,  5.2773e-01],\n",
      "        [ 5.5069e-01,  2.6481e-01],\n",
      "        [-3.1308e-01,  2.6111e-01],\n",
      "        [ 9.2000e-01,  3.8092e-01],\n",
      "        [-2.6880e+00,  1.9787e+00],\n",
      "        [ 4.4966e-01,  1.2880e+00],\n",
      "        [ 5.6638e-01, -3.2757e-02],\n",
      "        [ 1.3290e+00, -2.8909e+00],\n",
      "        [-6.9118e-01, -6.4167e-01],\n",
      "        [ 4.2043e-01, -2.0712e+00],\n",
      "        [-2.6367e-01, -3.8460e-02],\n",
      "        [ 4.5037e-01, -3.9667e-01],\n",
      "        [-5.4509e-01, -4.7960e-01],\n",
      "        [ 6.1673e-01, -3.7307e-01],\n",
      "        [ 1.1196e+00, -3.9061e-01],\n",
      "        [-2.4293e-01, -5.0096e-01],\n",
      "        [-7.4460e-02,  2.5016e-01],\n",
      "        [ 4.2749e-01,  9.1288e-02],\n",
      "        [ 8.5035e-01,  3.0867e-01],\n",
      "        [-1.5757e+00,  1.8173e+00],\n",
      "        [ 8.9646e-01,  7.3298e-01],\n",
      "        [ 4.4436e-01, -4.1380e-01],\n",
      "        [-1.3175e+00,  3.3700e-01],\n",
      "        [ 9.3578e-01, -9.5461e-01],\n",
      "        [ 3.6974e-01, -6.0598e-01],\n",
      "        [ 1.0071e+00, -7.5610e-02],\n",
      "        [-1.6657e-01, -1.2542e+00],\n",
      "        [-6.6762e-01,  4.9440e-01],\n",
      "        [ 1.0985e+00, -9.7989e-01],\n",
      "        [ 5.3013e-01, -9.3352e-01],\n",
      "        [-5.5845e-01, -3.1628e-01],\n",
      "        [-2.2306e-01, -5.8196e-01],\n",
      "        [ 9.8272e-02, -3.4480e-01],\n",
      "        [-4.7996e-01, -8.6107e-01],\n",
      "        [ 5.3447e-01, -5.9918e-01],\n",
      "        [ 8.0746e-01, -3.2824e-01],\n",
      "        [ 8.2117e-01,  4.1710e-01],\n",
      "        [-3.4765e-01, -4.7169e-01],\n",
      "        [-5.7326e-01, -2.7665e-01],\n",
      "        [-1.6196e+00,  2.5999e-01],\n",
      "        [ 2.9966e-01,  1.0913e+00],\n",
      "        [ 4.4716e-01, -1.1536e-01],\n",
      "        [-9.9586e-01, -6.2917e-01],\n",
      "        [-1.2870e+00,  1.2047e+00],\n",
      "        [ 1.9433e-01,  8.7392e-01],\n",
      "        [ 9.7891e-01,  6.6444e-01],\n",
      "        [-1.5564e-01, -7.8163e-01],\n",
      "        [-1.8404e+00,  6.0348e-01],\n",
      "        [ 6.3416e-01, -9.9320e-01],\n",
      "        [ 8.9071e-01,  9.6264e-01],\n",
      "        [ 3.4699e-01,  2.4204e-01],\n",
      "        [-2.4392e+00,  1.4389e+00],\n",
      "        [ 2.7779e-01, -1.1891e+00],\n",
      "        [ 5.3517e-01,  2.6652e-01],\n",
      "        [ 5.3820e-01,  3.1934e-01],\n",
      "        [ 9.1650e-01,  4.6519e-02],\n",
      "        [ 5.4865e-01,  4.2759e-01],\n",
      "        [-4.2561e-01, -2.6738e+00],\n",
      "        [-1.1187e+00, -9.4049e-01],\n",
      "        [ 3.3563e-01,  9.0508e-01],\n",
      "        [ 7.2667e-01, -3.6017e-01],\n",
      "        [ 8.7437e-01, -7.8334e-01],\n",
      "        [ 1.2423e+00, -5.9039e-01],\n",
      "        [ 2.4898e-01, -1.0759e+00],\n",
      "        [ 5.0587e-01, -1.3946e+00],\n",
      "        [ 7.9453e-01, -9.1864e-01],\n",
      "        [ 4.9054e-01, -9.3118e-01],\n",
      "        [ 2.1625e-01, -1.5294e+00],\n",
      "        [ 6.2229e-01,  9.6989e-01],\n",
      "        [ 1.2220e+00, -6.1033e-01],\n",
      "        [-1.9695e-02, -1.7603e+00],\n",
      "        [ 9.0781e-01,  6.2583e-01],\n",
      "        [ 3.5679e-01, -1.7803e-01],\n",
      "        [ 8.4290e-01,  1.2932e+00],\n",
      "        [ 8.9166e-01,  6.1571e-01],\n",
      "        [ 4.4550e-01,  9.7760e-01],\n",
      "        [-1.9390e-01, -6.8469e-01],\n",
      "        [ 2.1732e-01, -4.3838e-01],\n",
      "        [ 7.0563e-01,  8.4026e-01],\n",
      "        [ 8.1854e-01, -1.6216e-01],\n",
      "        [ 2.7187e-01,  5.1089e-01],\n",
      "        [ 2.5936e-01,  3.6841e-01],\n",
      "        [ 8.9042e-01,  1.1255e+00],\n",
      "        [ 7.7065e-02,  1.8758e-01],\n",
      "        [ 1.3558e-01, -1.0891e+00],\n",
      "        [ 1.2056e+00, -9.8951e-01],\n",
      "        [ 7.9753e-01,  9.6202e-01],\n",
      "        [ 1.5086e-01, -1.5527e+00],\n",
      "        [ 7.0959e-01,  6.3927e-01],\n",
      "        [-1.3229e-01, -4.2491e-01],\n",
      "        [-1.6356e-01, -8.9800e-01],\n",
      "        [ 3.3356e-01,  1.0229e+00],\n",
      "        [-8.3104e-01,  3.0037e-01],\n",
      "        [ 8.5543e-01, -8.6220e-01],\n",
      "        [-1.2546e-01,  9.7011e-01],\n",
      "        [ 1.0082e+00,  6.5204e-02],\n",
      "        [-8.6139e-01,  5.3045e-01],\n",
      "        [ 3.2260e-01, -4.0950e-01],\n",
      "        [-1.3397e+00,  9.0360e-01],\n",
      "        [ 8.8204e-01,  4.2684e-01],\n",
      "        [ 8.9174e-01, -1.0760e+00],\n",
      "        [-2.9312e+00,  9.0071e-01],\n",
      "        [ 8.6674e-02, -1.7629e-02],\n",
      "        [ 8.9870e-01, -4.7923e-01],\n",
      "        [-2.0163e-01, -1.7048e+00],\n",
      "        [-1.1893e+00, -7.9695e-01],\n",
      "        [ 7.2371e-01, -1.3076e+00],\n",
      "        [ 5.8445e-01,  4.6461e-01],\n",
      "        [ 4.8437e-01, -1.7715e+00],\n",
      "        [ 2.5345e-01, -6.6111e-02],\n",
      "        [-2.6903e-01, -6.0500e-01],\n",
      "        [ 1.1534e-01, -7.6389e-01],\n",
      "        [-1.3907e+00,  9.1960e-01],\n",
      "        [ 1.7553e-01,  8.1591e-02],\n",
      "        [-5.9600e-01, -2.6761e-01],\n",
      "        [ 2.5198e-01,  9.9858e-01],\n",
      "        [ 1.0843e+00, -6.9503e-01],\n",
      "        [-1.3541e+00,  8.4177e-01],\n",
      "        [ 1.6914e-01,  8.4539e-01],\n",
      "        [ 5.5823e-01,  1.2050e+00],\n",
      "        [ 7.6134e-01,  4.0185e-01],\n",
      "        [ 7.6391e-01, -5.9686e-01],\n",
      "        [ 1.4165e-01,  5.2954e-01],\n",
      "        [ 1.3422e+00, -5.6033e-01],\n",
      "        [ 3.1799e-01, -3.1791e-01],\n",
      "        [-2.0902e-01, -3.2499e-01],\n",
      "        [ 4.4845e-01,  9.1284e-01],\n",
      "        [ 1.1703e+00, -5.1639e-01],\n",
      "        [ 8.1380e-01,  7.4003e-01],\n",
      "        [ 4.0045e-01, -3.1105e-01],\n",
      "        [ 8.0142e-01,  6.1617e-01],\n",
      "        [ 7.3993e-01,  7.6364e-01],\n",
      "        [ 1.1507e+00, -6.6902e-01],\n",
      "        [ 6.2766e-01,  3.6958e-01],\n",
      "        [ 2.3748e-01,  4.3028e-02],\n",
      "        [-4.1890e-01,  1.3214e+00],\n",
      "        [ 2.5733e-01,  2.6796e-01],\n",
      "        [ 6.2970e-01, -9.8570e-01],\n",
      "        [ 4.4612e-01, -9.0638e-01],\n",
      "        [ 6.2888e-01, -1.0282e+00],\n",
      "        [ 8.0881e-01,  1.0191e+00],\n",
      "        [-1.0446e-01, -3.1441e-01],\n",
      "        [ 3.8288e-01, -2.7068e-01],\n",
      "        [-2.7028e+00,  9.7642e-01],\n",
      "        [-4.9388e-01,  2.2043e-01],\n",
      "        [ 4.3704e-01, -7.1008e-01],\n",
      "        [ 1.0878e+00, -4.6875e-01],\n",
      "        [ 5.5736e-01, -4.3769e-01],\n",
      "        [ 3.0557e-01,  6.2124e-01],\n",
      "        [ 3.1923e-01,  3.4150e-01],\n",
      "        [ 6.2791e-01, -1.2617e+00],\n",
      "        [-4.6776e-01,  8.2514e-01],\n",
      "        [ 3.9907e-01,  2.0219e-01],\n",
      "        [ 8.4265e-02,  2.4336e-01],\n",
      "        [ 1.1305e-03, -2.7674e-01],\n",
      "        [-3.2401e-01,  2.0585e-02],\n",
      "        [-1.7353e+00,  7.7809e-01],\n",
      "        [-1.7935e+00,  9.8830e-01],\n",
      "        [-1.8011e-01,  5.9512e-01],\n",
      "        [ 6.1778e-01,  1.2693e+00],\n",
      "        [ 7.6806e-01,  8.8371e-01],\n",
      "        [ 9.8021e-01, -3.3650e-01],\n",
      "        [ 6.5470e-01, -8.4533e-01],\n",
      "        [ 6.8246e-01, -1.5339e+00],\n",
      "        [ 1.5548e-01, -1.2144e-01],\n",
      "        [-8.3225e-02,  3.1571e-01],\n",
      "        [ 2.8365e-01, -1.3345e+00],\n",
      "        [ 1.3321e+00, -7.0512e-01],\n",
      "        [-3.2588e-01, -4.3116e-02],\n",
      "        [ 4.8281e-01,  1.0792e+00],\n",
      "        [ 6.6114e-01,  2.9090e-01],\n",
      "        [ 3.5627e-01, -8.4991e-01],\n",
      "        [-3.4281e-01,  1.7823e-01],\n",
      "        [ 6.6063e-01,  3.3788e-01],\n",
      "        [ 8.2279e-01,  2.2857e-01],\n",
      "        [-2.0955e+00,  1.2597e+00],\n",
      "        [-2.6266e-02,  3.2872e-01],\n",
      "        [ 7.4449e-01,  7.9508e-01],\n",
      "        [ 1.1343e+00, -4.3895e-01],\n",
      "        [ 1.0179e+00,  3.9349e-01],\n",
      "        [ 8.5482e-01, -4.6445e-01],\n",
      "        [-1.5502e+00,  6.4003e-01],\n",
      "        [ 7.8407e-02, -8.3150e-01],\n",
      "        [ 1.3556e+00, -9.5826e-01],\n",
      "        [ 5.2917e-01,  7.3123e-01],\n",
      "        [-5.2748e-02, -4.5084e-01],\n",
      "        [-1.8474e+00,  9.5215e-01],\n",
      "        [ 3.1234e-01, -3.0372e+00],\n",
      "        [ 2.8434e-01, -2.0326e-01],\n",
      "        [ 3.3129e-01, -1.5622e+00],\n",
      "        [-3.8146e-01, -2.3411e-01],\n",
      "        [ 5.9897e-01, -4.8259e-01],\n",
      "        [-1.0493e+00,  3.8611e-01],\n",
      "        [-1.8317e-01, -1.3880e-01],\n",
      "        [ 7.1099e-01,  7.4466e-01],\n",
      "        [-3.9364e-01,  3.3642e-01],\n",
      "        [ 1.0489e+00,  1.3345e-01]], device='cuda:0')\n",
      "Action space size: 1665\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 4\n",
      "Episode 20/20, C2S Decisions: [(0, -1, 1)]\n",
      "C2S Reward: -0.556550907681273\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train():\n",
    "    env = Environment()\n",
    "    replay_buffer = ReplayBuffer(10000)  # Example replay buffer\n",
    "    node_features, adj_matrix = env.create_graph_matrices()\n",
    "    \n",
    "    gae_model, gae_data = train_gae_with_early_stopping(node_features, adj_matrix)\n",
    "    dqn_model = DQN(input_dim=19, output_dim=5).to(device)\n",
    "    \n",
    "    train_c2s_agent(env, gae_model, dqn_model, replay_buffer)\n",
    "    \n",
    "    return gae_model, dqn_model\n",
    "\n",
    "# Run the combined train function\n",
    "gae_model, dqn_model = train()\n",
    "\n",
    "    \n",
    "\n",
    "# Assuming the following classes and functions are already defined:\n",
    "# - Environment\n",
    "# - GAE\n",
    "# - DQN\n",
    "# - make_decisions\n",
    "# - Customer\n",
    "# - Warehouse\n",
    "# - Vehicle\n",
    "\n",
    "def run_simulation(env, gae_model, dqn_model):\n",
    "    env.time_lapsed = 0\n",
    "    env.reset()\n",
    "    episode_rewards = []\n",
    "\n",
    "    for episode in range(env.no_of_episodes):\n",
    "        # Generate new customers at the start of each episode\n",
    "        env.generate_customers()\n",
    "        feature_matrix, adjacency_matrix = env.create_graph_matrices()\n",
    "\n",
    "        # Call the make_decisions function\n",
    "        c2s_decisions = make_decisions(env, gae_model, dqn_model, feature_matrix, adjacency_matrix)\n",
    "        print(f'Episode {episode + 1}/{env.no_of_episodes}, C2S Decisions: {c2s_decisions}')\n",
    "\n",
    "        # Calculate the rewards before applying the actions\n",
    "        try:\n",
    "            c2s_reward = sum(env.calculate_c2s_reward(decision) for decision in c2s_decisions)\n",
    "            print(f'C2S Reward: {c2s_reward}')\n",
    "        except TypeError as e:\n",
    "            print(f\"Error calculating rewards: {e}. Ensure decisions are in (customer_id, warehouse_id, defer_flag) format.\")\n",
    "            continue\n",
    "\n",
    "        # Apply input actions to update the environment\n",
    "        env.input_actions(c2s_decisions, [])\n",
    "        \n",
    "        # Calculate total reward for the episode\n",
    "        total_reward = c2s_reward\n",
    "        episode_rewards.append(total_reward)\n",
    "        \n",
    "        env.time_lapsed += env.episode_time\n",
    "    \n",
    "    return episode_rewards\n",
    "\n",
    "# Example usage\n",
    "env = Environment()\n",
    "gae_model = GAE(in_channels=7, hidden_dim=64, dropout=0.4).to(device)\n",
    "dqn_model = DQN(input_dim=19, output_dim=5).to(device)\n",
    "\n",
    "# Run the simulation and get episode rewards\n",
    "episode_rewards = run_simulation(env, gae_model, dqn_model)\n",
    "\n",
    "# Plot the rewards vs number of episodes\n",
    "plt.plot(range(1, len(episode_rewards) + 1), episode_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Total Reward vs Episode')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 1.3227,  1.5706],\n",
      "        [ 0.4961, -0.7799],\n",
      "        [-0.4909, -0.9487],\n",
      "        [-1.3279,  0.1579]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 1, Loss: 1.1131303310394287\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[-0.3701, -1.2205],\n",
      "        [ 1.5316, -0.3055],\n",
      "        [-1.0959,  0.2561],\n",
      "        [ 0.0943,  1.4298]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 2, Loss: 1.1092489957809448\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.1845, -0.3663],\n",
      "        [ 1.2995, -1.1749],\n",
      "        [ 0.1069,  0.6214],\n",
      "        [-1.2935,  1.2352]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 3, Loss: 0.8666138648986816\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 1.2531, -0.8525],\n",
      "        [ 0.5952, -0.6621],\n",
      "        [-0.4335,  0.7362],\n",
      "        [-1.0216,  1.2463]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 4, Loss: 0.7361212372779846\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 1.3761, -0.6862],\n",
      "        [ 0.3885, -0.6976],\n",
      "        [-0.5885,  1.3192],\n",
      "        [-0.7414,  0.6839]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 5, Loss: 0.6692737936973572\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 1.2067, -0.5798],\n",
      "        [ 0.5288, -0.7340],\n",
      "        [-0.3774,  0.8400],\n",
      "        [-0.9336,  1.2446]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 6, Loss: 0.591632604598999\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8663, -0.6588],\n",
      "        [ 0.8810, -0.5865],\n",
      "        [-0.4430,  0.9893],\n",
      "        [-0.9298,  1.1794]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 7, Loss: 0.5327433943748474\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 1.0751, -0.6847],\n",
      "        [ 0.4501, -0.4188],\n",
      "        [-0.2025,  0.7805],\n",
      "        [-1.0262,  1.4009]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 8, Loss: 0.46020281314849854\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5270, -0.7174],\n",
      "        [ 0.9692, -0.3624],\n",
      "        [-0.2675,  1.2086],\n",
      "        [-1.0302,  1.1053]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 9, Loss: 0.42890965938568115\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 1.0788, -0.8573],\n",
      "        [ 0.2993, -0.0672],\n",
      "        [-0.3433,  0.9989],\n",
      "        [-0.9483,  1.3180]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 10, Loss: 0.3445979058742523\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8212, -0.5981],\n",
      "        [ 0.4690, -0.2069],\n",
      "        [-0.1889,  0.6926],\n",
      "        [-1.1372,  1.6649]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 11, Loss: 0.29624199867248535\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8378, -0.7545],\n",
      "        [ 0.2554,  0.0675],\n",
      "        [-0.0614,  0.7551],\n",
      "        [-1.1976,  1.6460]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 12, Loss: 0.24914123117923737\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9831, -0.6035],\n",
      "        [ 0.1256, -0.0874],\n",
      "        [-0.3601,  0.8358],\n",
      "        [-1.0495,  1.7323]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 13, Loss: 0.20111209154129028\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9230, -0.6229],\n",
      "        [ 0.1608, -0.0479],\n",
      "        [-0.4382,  1.0188],\n",
      "        [-1.0849,  1.6931]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 14, Loss: 0.161935955286026\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7943, -0.5421],\n",
      "        [ 0.2974, -0.0814],\n",
      "        [-0.5288,  1.0895],\n",
      "        [-1.1419,  1.7395]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 15, Loss: 0.1309175342321396\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9394, -0.6200],\n",
      "        [-0.0432,  0.0507],\n",
      "        [-0.4983,  1.4016],\n",
      "        [-1.1157,  1.5371]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 16, Loss: 0.10604172199964523\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8818, -0.5114],\n",
      "        [ 0.0312,  0.0294],\n",
      "        [-0.6309,  1.3038],\n",
      "        [-1.1360,  1.7099]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 17, Loss: 0.08220581710338593\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7708, -0.5470],\n",
      "        [-0.0092,  0.2931],\n",
      "        [-0.3993,  1.0833],\n",
      "        [-1.3462,  1.8619]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 18, Loss: 0.06471359729766846\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7229, -0.3714],\n",
      "        [ 0.1047,  0.1219],\n",
      "        [-0.6004,  1.2422],\n",
      "        [-1.3321,  1.8536]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 19, Loss: 0.05436810106039047\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7189, -0.2836],\n",
      "        [ 0.1308,  0.1635],\n",
      "        [-0.7991,  1.2046],\n",
      "        [-1.2632,  1.9097]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 20, Loss: 0.05180656537413597\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6236, -0.2336],\n",
      "        [ 0.0309,  0.3194],\n",
      "        [-0.4537,  1.0492],\n",
      "        [-1.5037,  1.9975]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 21, Loss: 0.050822559744119644\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7719, -0.2641],\n",
      "        [-0.1013,  0.3762],\n",
      "        [-0.6790,  1.3507],\n",
      "        [-1.3637,  1.7955]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 22, Loss: 0.04773619398474693\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7993, -0.1931],\n",
      "        [-0.1549,  0.4750],\n",
      "        [-0.7261,  1.2161],\n",
      "        [-1.3357,  1.8709]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 23, Loss: 0.049564462155103683\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8752, -0.2012],\n",
      "        [-0.4077,  0.6218],\n",
      "        [-0.6004,  1.2534],\n",
      "        [-1.3051,  1.7882]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 24, Loss: 0.05835083872079849\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7069, -0.0639],\n",
      "        [-0.1001,  0.5963],\n",
      "        [-0.5764,  1.1499],\n",
      "        [-1.4652,  1.8545]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 25, Loss: 0.04924838989973068\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8365,  0.0116],\n",
      "        [-0.1631,  0.5094],\n",
      "        [-0.8655,  1.3859],\n",
      "        [-1.2180,  1.6856]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 26, Loss: 0.05255202576518059\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8485,  0.0222],\n",
      "        [-0.1874,  0.6940],\n",
      "        [-0.7940,  1.1620],\n",
      "        [-1.2339,  1.7516]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 27, Loss: 0.04788757488131523\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7349,  0.2310],\n",
      "        [-0.1507,  0.5662],\n",
      "        [-0.4516,  1.0258],\n",
      "        [-1.4406,  1.8271]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 28, Loss: 0.04435339197516441\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7199,  0.1611],\n",
      "        [-0.0213,  0.6449],\n",
      "        [-0.5352,  1.1819],\n",
      "        [-1.4006,  1.6673]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 29, Loss: 0.0362936370074749\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8976,  0.1426],\n",
      "        [-0.2314,  0.7679],\n",
      "        [-0.6240,  1.1275],\n",
      "        [-1.1996,  1.6093]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 30, Loss: 0.03900575265288353\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6842,  0.2022],\n",
      "        [ 0.1621,  0.6889],\n",
      "        [-0.5897,  1.1895],\n",
      "        [-1.3285,  1.5478]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 31, Loss: 0.03173966333270073\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6303,  0.3954],\n",
      "        [ 0.1286,  0.5477],\n",
      "        [-0.3239,  1.0117],\n",
      "        [-1.4183,  1.6458]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 32, Loss: 0.036584772169589996\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7399,  0.3260],\n",
      "        [ 0.0417,  0.6093],\n",
      "        [-0.3360,  1.0684],\n",
      "        [-1.3404,  1.5623]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 33, Loss: 0.03015894442796707\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5957,  0.3409],\n",
      "        [ 0.1975,  0.6507],\n",
      "        [-0.2012,  0.9574],\n",
      "        [-1.4004,  1.5772]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 34, Loss: 0.03727959096431732\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6779,  0.4119],\n",
      "        [ 0.2435,  0.5124],\n",
      "        [-0.3438,  1.0188],\n",
      "        [-1.3046,  1.5398]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 35, Loss: 0.031120818108320236\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7381,  0.4108],\n",
      "        [ 0.2389,  0.5144],\n",
      "        [-0.3887,  0.9709],\n",
      "        [-1.2411,  1.5417]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 36, Loss: 0.028427015990018845\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6166,  0.5827],\n",
      "        [ 0.4676,  0.2648],\n",
      "        [-0.4727,  1.1449],\n",
      "        [-1.1988,  1.3994]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 37, Loss: 0.042975377291440964\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9148,  0.2183],\n",
      "        [ 0.1275,  0.5990],\n",
      "        [-0.5214,  1.1960],\n",
      "        [-1.0533,  1.3333]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 38, Loss: 0.024328505620360374\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7863,  0.2088],\n",
      "        [ 0.2681,  0.6418],\n",
      "        [-0.3594,  0.9970],\n",
      "        [-1.1842,  1.4553]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 39, Loss: 0.022369150072336197\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8288,  0.2047],\n",
      "        [ 0.2105,  0.5730],\n",
      "        [-0.3203,  1.0382],\n",
      "        [-1.1770,  1.4455]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 40, Loss: 0.02061457186937332\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9618,  0.2410],\n",
      "        [ 0.1701,  0.4360],\n",
      "        [-0.6461,  1.1395],\n",
      "        [-0.9248,  1.4065]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 41, Loss: 0.024056432768702507\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7124,  0.2259],\n",
      "        [ 0.3492,  0.4849],\n",
      "        [-0.2486,  0.9438],\n",
      "        [-1.2451,  1.5331]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 42, Loss: 0.023614071309566498\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6083,  0.1097],\n",
      "        [ 0.6115,  0.5153],\n",
      "        [-0.5566,  1.0884],\n",
      "        [-1.0991,  1.4427]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 43, Loss: 0.0288736280053854\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7566,  0.0998],\n",
      "        [ 0.3770,  0.4804],\n",
      "        [-0.3949,  1.0666],\n",
      "        [-1.1884,  1.4815]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 44, Loss: 0.016842583194375038\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9445,  0.0584],\n",
      "        [ 0.1725,  0.4540],\n",
      "        [-0.5449,  1.1457],\n",
      "        [-1.0438,  1.4462]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 45, Loss: 0.01435723714530468\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7292,  0.1286],\n",
      "        [ 0.3462,  0.3744],\n",
      "        [-0.3162,  0.9944],\n",
      "        [-1.2594,  1.5864]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 46, Loss: 0.017595462501049042\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9765, -0.0230],\n",
      "        [ 0.1373,  0.4379],\n",
      "        [-0.6862,  1.2682],\n",
      "        [-0.9612,  1.3837]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 47, Loss: 0.018892161548137665\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9328,  0.0033],\n",
      "        [ 0.0624,  0.4486],\n",
      "        [-0.3975,  0.9957],\n",
      "        [-1.1674,  1.6051]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 48, Loss: 0.012448709458112717\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9098, -0.0766],\n",
      "        [ 0.1833,  0.4301],\n",
      "        [-0.6097,  1.2454],\n",
      "        [-1.0900,  1.4424]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 49, Loss: 0.013317717239260674\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9301, -0.1647],\n",
      "        [ 0.0805,  0.5694],\n",
      "        [-0.5064,  1.1291],\n",
      "        [-1.1472,  1.4985]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 50, Loss: 0.012622719630599022\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9543, -0.1500],\n",
      "        [ 0.0313,  0.5349],\n",
      "        [-0.5404,  1.0749],\n",
      "        [-1.1219,  1.5656]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 51, Loss: 0.013256554491817951\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7489, -0.0735],\n",
      "        [ 0.2879,  0.4305],\n",
      "        [-0.4578,  1.0253],\n",
      "        [-1.2707,  1.6404]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 52, Loss: 0.012832476757466793\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8807, -0.0459],\n",
      "        [ 0.0961,  0.4070],\n",
      "        [-0.4721,  0.9819],\n",
      "        [-1.2094,  1.6778]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 53, Loss: 0.011455634608864784\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8403, -0.1026],\n",
      "        [ 0.0513,  0.5121],\n",
      "        [-0.3189,  0.9321],\n",
      "        [-1.2882,  1.6779]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 54, Loss: 0.015149314887821674\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9145, -0.0856],\n",
      "        [ 0.0629,  0.3826],\n",
      "        [-0.5521,  1.1315],\n",
      "        [-1.1492,  1.5903]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 55, Loss: 0.011419431306421757\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9488, -0.1527],\n",
      "        [ 0.0397,  0.4621],\n",
      "        [-0.6586,  1.1825],\n",
      "        [-1.0599,  1.5266]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 56, Loss: 0.015093114227056503\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8755, -0.0919],\n",
      "        [ 0.0207,  0.4436],\n",
      "        [-0.3945,  1.0143],\n",
      "        [-1.2355,  1.6526]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 57, Loss: 0.01222839392721653\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9237, -0.1830],\n",
      "        [ 0.0123,  0.5415],\n",
      "        [-0.5302,  1.1114],\n",
      "        [-1.1414,  1.5491]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 58, Loss: 0.012831798754632473\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8503, -0.0227],\n",
      "        [ 0.1540,  0.3016],\n",
      "        [-0.5839,  1.1377],\n",
      "        [-1.1557,  1.6031]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 59, Loss: 0.011081172153353691\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9090, -0.1465],\n",
      "        [-0.0074,  0.5298],\n",
      "        [-0.4665,  1.0294],\n",
      "        [-1.1682,  1.6082]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 60, Loss: 0.01219872571527958\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7769,  0.0901],\n",
      "        [ 0.1664,  0.2996],\n",
      "        [-0.4105,  0.8829],\n",
      "        [-1.2623,  1.7496]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 61, Loss: 0.013901387341320515\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9049, -0.0551],\n",
      "        [ 0.1164,  0.3146],\n",
      "        [-0.7694,  1.3349],\n",
      "        [-0.9762,  1.4293]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 62, Loss: 0.020358910784125328\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8997, -0.1230],\n",
      "        [ 0.0019,  0.4936],\n",
      "        [-0.4644,  1.0715],\n",
      "        [-1.1554,  1.5832]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 63, Loss: 0.01095809880644083\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 1.0226, -0.1978],\n",
      "        [-0.1683,  0.5804],\n",
      "        [-0.6343,  1.2051],\n",
      "        [-0.9311,  1.4395]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 64, Loss: 0.024354057386517525\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8690,  0.0149],\n",
      "        [ 0.0590,  0.3399],\n",
      "        [-0.4728,  1.0252],\n",
      "        [-1.1588,  1.6492]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 65, Loss: 0.0096959937363863\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7656, -0.0794],\n",
      "        [ 0.0922,  0.5495],\n",
      "        [-0.2732,  0.9028],\n",
      "        [-1.2803,  1.6583]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 66, Loss: 0.014492127113044262\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8352, -0.1104],\n",
      "        [ 0.1615,  0.4742],\n",
      "        [-0.5676,  1.1616],\n",
      "        [-1.1169,  1.5081]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 67, Loss: 0.010290390811860561\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7993, -0.0158],\n",
      "        [ 0.1180,  0.4480],\n",
      "        [-0.3792,  0.9420],\n",
      "        [-1.2182,  1.6616]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 68, Loss: 0.010806149803102016\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8156, -0.0185],\n",
      "        [ 0.0539,  0.4732],\n",
      "        [-0.3170,  0.9195],\n",
      "        [-1.2253,  1.6640]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 69, Loss: 0.012320772744715214\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8548, -0.0206],\n",
      "        [ 0.0574,  0.4319],\n",
      "        [-0.4136,  1.0099],\n",
      "        [-1.1648,  1.6194]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 70, Loss: 0.009671220555901527\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6818,  0.0385],\n",
      "        [ 0.2814,  0.4117],\n",
      "        [-0.3676,  0.9159],\n",
      "        [-1.2558,  1.6768]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 71, Loss: 0.014451093971729279\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7787,  0.0287],\n",
      "        [ 0.1565,  0.3844],\n",
      "        [-0.3727,  0.9982],\n",
      "        [-1.2176,  1.6339]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 72, Loss: 0.010486111976206303\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9380, -0.0957],\n",
      "        [ 0.0598,  0.4775],\n",
      "        [-0.7590,  1.2342],\n",
      "        [-0.8896,  1.4314]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 73, Loss: 0.021086446940898895\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8835, -0.0366],\n",
      "        [ 0.0999,  0.4460],\n",
      "        [-0.5624,  1.0758],\n",
      "        [-1.0686,  1.5646]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 74, Loss: 0.010178630240261555\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9413, -0.0779],\n",
      "        [-0.0667,  0.5612],\n",
      "        [-0.4405,  0.9813],\n",
      "        [-1.0791,  1.5872]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 75, Loss: 0.013295966200530529\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6300,  0.1187],\n",
      "        [ 0.4241,  0.2623],\n",
      "        [-0.5076,  1.0651],\n",
      "        [-1.1901,  1.6078]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 76, Loss: 0.018746454268693924\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9272, -0.1154],\n",
      "        [ 0.0654,  0.5446],\n",
      "        [-0.6587,  1.1673],\n",
      "        [-0.9770,  1.4593]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 77, Loss: 0.015323636122047901\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9243, -0.0498],\n",
      "        [ 0.0338,  0.4852],\n",
      "        [-0.5585,  1.0593],\n",
      "        [-1.0427,  1.5630]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 78, Loss: 0.011243314482271671\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7426,  0.0740],\n",
      "        [ 0.3077,  0.2949],\n",
      "        [-0.5497,  1.1288],\n",
      "        [-1.1446,  1.5615]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 79, Loss: 0.012808887287974358\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9007, -0.0686],\n",
      "        [ 0.0694,  0.4785],\n",
      "        [-0.5409,  1.1509],\n",
      "        [-1.0746,  1.4999]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 80, Loss: 0.010443742386996746\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7748,  0.0297],\n",
      "        [ 0.2018,  0.3870],\n",
      "        [-0.4182,  1.0377],\n",
      "        [-1.2057,  1.6076]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 81, Loss: 0.009852875024080276\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7828,  0.0876],\n",
      "        [ 0.1492,  0.3472],\n",
      "        [-0.3485,  0.9721],\n",
      "        [-1.2331,  1.6563]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 82, Loss: 0.011316510848701\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8238, -0.0430],\n",
      "        [ 0.1449,  0.4839],\n",
      "        [-0.4417,  1.0426],\n",
      "        [-1.1792,  1.5806]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 83, Loss: 0.008946235291659832\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8262, -0.0249],\n",
      "        [ 0.0868,  0.4896],\n",
      "        [-0.3510,  0.9792],\n",
      "        [-1.2168,  1.6210]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 84, Loss: 0.010413913056254387\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9673, -0.0506],\n",
      "        [ 0.0103,  0.4152],\n",
      "        [-0.6939,  1.2792],\n",
      "        [-0.9410,  1.4216]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 85, Loss: 0.01819803938269615\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9835, -0.0972],\n",
      "        [-0.0596,  0.5290],\n",
      "        [-0.5861,  1.1180],\n",
      "        [-0.9976,  1.5159]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 86, Loss: 0.01503675989806652\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 9.0435e-01, -1.7680e-02],\n",
      "        [-8.3484e-04,  4.2645e-01],\n",
      "        [-4.1445e-01,  1.0734e+00],\n",
      "        [-1.1511e+00,  1.5836e+00]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 87, Loss: 0.00965682603418827\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8356,  0.0065],\n",
      "        [ 0.1644,  0.3837],\n",
      "        [-0.5080,  1.0917],\n",
      "        [-1.1559,  1.5838]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 88, Loss: 0.008778765797615051\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9178, -0.0565],\n",
      "        [ 0.0369,  0.4475],\n",
      "        [-0.5202,  1.1463],\n",
      "        [-1.1000,  1.5282]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 89, Loss: 0.009865641593933105\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8265, -0.0623],\n",
      "        [ 0.1749,  0.4617],\n",
      "        [-0.4995,  1.1230],\n",
      "        [-1.1685,  1.5427]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 90, Loss: 0.008757061325013638\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6849,  0.0624],\n",
      "        [ 0.3589,  0.3112],\n",
      "        [-0.4879,  1.0797],\n",
      "        [-1.2233,  1.6113]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 91, Loss: 0.014092890545725822\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.5976,  0.1603],\n",
      "        [ 0.4407,  0.2010],\n",
      "        [-0.4477,  1.0790],\n",
      "        [-1.2581,  1.6236]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 92, Loss: 0.021437738090753555\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8077, -0.0188],\n",
      "        [ 0.1690,  0.4369],\n",
      "        [-0.4344,  1.0236],\n",
      "        [-1.2097,  1.6215]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 93, Loss: 0.009145333431661129\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 7.4782e-01,  3.6991e-04],\n",
      "        [ 2.3106e-01,  4.1252e-01],\n",
      "        [-3.9552e-01,  1.0167e+00],\n",
      "        [-1.2501e+00,  1.6327e+00]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 94, Loss: 0.010714714415371418\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9505, -0.0049],\n",
      "        [ 0.0022,  0.3743],\n",
      "        [-0.5677,  1.1149],\n",
      "        [-1.0508,  1.5770]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 95, Loss: 0.010961550287902355\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6924,  0.0625],\n",
      "        [ 0.2940,  0.3090],\n",
      "        [-0.3790,  1.0643],\n",
      "        [-1.2719,  1.6244]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 96, Loss: 0.013227938674390316\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8069, -0.0561],\n",
      "        [ 0.1846,  0.4328],\n",
      "        [-0.4599,  1.1380],\n",
      "        [-1.1947,  1.5444]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 97, Loss: 0.008624454960227013\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7823, -0.0420],\n",
      "        [ 0.1881,  0.4538],\n",
      "        [-0.4023,  1.0387],\n",
      "        [-1.2296,  1.6075]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 98, Loss: 0.009524798952043056\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6944, -0.0286],\n",
      "        [ 0.2107,  0.4583],\n",
      "        [-0.2497,  0.9911],\n",
      "        [-1.3152,  1.6362]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 99, Loss: 0.014495993964374065\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9429, -0.1022],\n",
      "        [ 0.0192,  0.4662],\n",
      "        [-0.5726,  1.2494],\n",
      "        [-1.0476,  1.4425]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 100, Loss: 0.012599152512848377\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7305,  0.0279],\n",
      "        [ 0.1559,  0.4282],\n",
      "        [-0.2409,  0.9075],\n",
      "        [-1.3019,  1.6913]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 101, Loss: 0.015368581749498844\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8611, -0.0128],\n",
      "        [ 0.1564,  0.3563],\n",
      "        [-0.5688,  1.1746],\n",
      "        [-1.1042,  1.5364]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 102, Loss: 0.009531612507998943\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9313, -0.1654],\n",
      "        [ 0.0867,  0.5677],\n",
      "        [-0.7076,  1.3416],\n",
      "        [-0.9651,  1.3103]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 103, Loss: 0.020527852699160576\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8185, -0.0517],\n",
      "        [ 0.1887,  0.4132],\n",
      "        [-0.4997,  1.1639],\n",
      "        [-1.1616,  1.5284]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 104, Loss: 0.008739141747355461\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8897, -0.0886],\n",
      "        [ 0.0613,  0.4965],\n",
      "        [-0.4702,  1.0902],\n",
      "        [-1.1342,  1.5553]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 105, Loss: 0.009239563718438148\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8261, -0.0324],\n",
      "        [ 0.1072,  0.4324],\n",
      "        [-0.3747,  1.0503],\n",
      "        [-1.2113,  1.6029]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 106, Loss: 0.009062451310455799\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8493, -0.1077],\n",
      "        [ 0.1379,  0.5375],\n",
      "        [-0.4907,  1.0689],\n",
      "        [-1.1488,  1.5543]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 107, Loss: 0.00920302327722311\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8670, -0.0339],\n",
      "        [ 0.1519,  0.3759],\n",
      "        [-0.5800,  1.2127],\n",
      "        [-1.0906,  1.4983]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 108, Loss: 0.01006567943841219\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8281, -0.0452],\n",
      "        [ 0.0992,  0.4910],\n",
      "        [-0.3656,  0.9754],\n",
      "        [-1.2130,  1.6316]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 109, Loss: 0.010141072794795036\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.6784,  0.1638],\n",
      "        [ 0.2278,  0.2766],\n",
      "        [-0.2417,  0.8938],\n",
      "        [-1.3155,  1.7186]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 110, Loss: 0.019041799008846283\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7925, -0.0149],\n",
      "        [ 0.1530,  0.4709],\n",
      "        [-0.3648,  0.9375],\n",
      "        [-1.2314,  1.6593]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 111, Loss: 0.01084695104509592\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8717, -0.0209],\n",
      "        [-0.0082,  0.5274],\n",
      "        [-0.3125,  0.8657],\n",
      "        [-1.2015,  1.6806]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 112, Loss: 0.013853820972144604\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9641, -0.0270],\n",
      "        [-0.0409,  0.4404],\n",
      "        [-0.5296,  1.0261],\n",
      "        [-1.0438,  1.6133]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 113, Loss: 0.011738631874322891\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.8357, -0.0124],\n",
      "        [ 0.0963,  0.4665],\n",
      "        [-0.3777,  0.9430],\n",
      "        [-1.2046,  1.6560]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 114, Loss: 0.010255551896989346\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9121, -0.0488],\n",
      "        [-0.0112,  0.4757],\n",
      "        [-0.4101,  1.0210],\n",
      "        [-1.1409,  1.6053]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 115, Loss: 0.010228961706161499\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.7990,  0.0148],\n",
      "        [ 0.1534,  0.4073],\n",
      "        [-0.3790,  0.9844],\n",
      "        [-1.2235,  1.6470]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 116, Loss: 0.009900393895804882\n",
      "Size of input data: torch.Size([4, 2])\n",
      "Size of embeddings: torch.Size([4, 2])\n",
      "Embeddings: tensor([[ 0.9016, -0.0509],\n",
      "        [ 0.0212,  0.4425],\n",
      "        [-0.4306,  1.1016],\n",
      "        [-1.1423,  1.5606]], device='cuda:0',\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "Epoch 117, Loss: 0.009026738815009594\n",
      "Early stopping triggered.\n",
      "Feature Matrix Shape: torch.Size([38, 7]), Adjacency Matrix Shape: torch.Size([38, 38])\n",
      "Size of input data: torch.Size([38, 2])\n",
      "Size of embeddings: torch.Size([38, 2])\n",
      "Embeddings: tensor([[ 0.8864,  0.0034],\n",
      "        [ 0.7095, -0.2116],\n",
      "        [ 0.6770,  0.1611],\n",
      "        [ 0.9143,  0.0239],\n",
      "        [ 0.8908, -0.2055],\n",
      "        [ 0.4176,  0.2259],\n",
      "        [ 1.1252, -0.1115],\n",
      "        [ 0.4265,  0.2507],\n",
      "        [ 0.7071,  0.1209],\n",
      "        [ 0.6217,  0.1100],\n",
      "        [ 0.4946,  0.2559],\n",
      "        [ 0.3618,  0.2584],\n",
      "        [ 0.3912,  0.2350],\n",
      "        [ 0.3048,  0.3146],\n",
      "        [ 0.2393,  0.3403],\n",
      "        [ 0.1411,  0.5087],\n",
      "        [-0.0402,  0.6257],\n",
      "        [-0.0090,  0.6539],\n",
      "        [-0.1243,  0.7143],\n",
      "        [-0.2372,  0.8194],\n",
      "        [-0.2743,  0.8872],\n",
      "        [-0.3345,  0.8523],\n",
      "        [-0.3831,  0.9963],\n",
      "        [-0.5591,  1.1041],\n",
      "        [-0.6780,  1.2479],\n",
      "        [-0.6850,  1.1765],\n",
      "        [-0.5765,  1.0630],\n",
      "        [-0.9095,  1.3635],\n",
      "        [-0.6076,  1.0916],\n",
      "        [-0.5502,  1.0536],\n",
      "        [-0.9708,  1.5452],\n",
      "        [-0.8010,  1.3626],\n",
      "        [-1.3493,  1.6470],\n",
      "        [-1.6680,  1.9094],\n",
      "        [-1.0317,  1.4263],\n",
      "        [-1.2908,  1.8168],\n",
      "        [-1.0968,  1.5701],\n",
      "        [-1.3076,  1.8066]], device='cuda:0')\n",
      "Action space size: 170\n",
      "Q-values output size: torch.Size([1, 5])\n",
      "Action index: 0\n",
      "Episode 1/20, C2S Decisions: [(0, 0, 0)]\n",
      "Size of input data: torch.Size([38, 2])\n",
      "Size of embeddings: torch.Size([38, 2])\n",
      "Embeddings: tensor([[ 0.5521,  0.1526],\n",
      "        [ 1.1193, -0.1105],\n",
      "        [ 0.9158, -0.1074],\n",
      "        [ 0.5596,  0.2163],\n",
      "        [ 0.7637, -0.1100],\n",
      "        [ 1.1767, -0.2424],\n",
      "        [ 0.7670, -0.0345],\n",
      "        [ 0.5237,  0.1608],\n",
      "        [ 0.6554,  0.1091],\n",
      "        [ 0.4651,  0.1914],\n",
      "        [ 0.5648,  0.2027],\n",
      "        [ 0.3781,  0.2719],\n",
      "        [ 0.2331,  0.3734],\n",
      "        [ 0.1410,  0.3975],\n",
      "        [ 0.2203,  0.4199],\n",
      "        [ 0.0790,  0.5060],\n",
      "        [ 0.0485,  0.5794],\n",
      "        [ 0.0505,  0.6227],\n",
      "        [-0.1688,  0.7230],\n",
      "        [-0.1485,  0.7623],\n",
      "        [-0.2442,  0.7968],\n",
      "        [-0.4689,  1.0375],\n",
      "        [-0.4738,  0.9915],\n",
      "        [-0.3997,  0.9077],\n",
      "        [-0.4943,  1.0117],\n",
      "        [-0.6903,  1.1952],\n",
      "        [-0.7325,  1.2798],\n",
      "        [-0.7286,  1.3165],\n",
      "        [-1.0970,  1.5619],\n",
      "        [-0.6787,  1.1433],\n",
      "        [-0.9174,  1.3554],\n",
      "        [-0.7615,  1.2647],\n",
      "        [-1.1691,  1.6245],\n",
      "        [-0.9473,  1.4162],\n",
      "        [-1.5329,  1.8895],\n",
      "        [-1.5586,  1.9173],\n",
      "        [-1.3252,  1.7534],\n",
      "        [-0.8522,  1.4666]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    env = Environment()\n",
    "    replay_buffer_c2s = ReplayBuffer(10000)  # Example replay buffer for C2S\n",
    "    replay_buffer_vrp = ReplayBuffer(100000)  # Example replay buffer for VRP\n",
    "    node_features, adj_matrix = env.create_graph_matrices()\n",
    "    \n",
    "    gae_model, gae_data = train_gae_with_early_stopping(node_features, adj_matrix)\n",
    "    dqn_model_c2s = DQN(input_dim=19, output_dim=5).to(device)\n",
    "    \n",
    "    # Assuming the GAE model always reduces to 2 dimensions\n",
    "    input_dim_vrp = 2\n",
    "    action_space_size = len(get_vrp_action_space(env.customers))\n",
    "    dqn_model_vrp = VRPLNetwork(input_dim=input_dim_vrp, output_dim=action_space_size).to(device)\n",
    "    \n",
    "    # Train C2S and VRP agents\n",
    "    train_c2s_agent(env, gae_model, dqn_model_c2s, replay_buffer_c2s, epochs=1000, batch_size=512)\n",
    "    train_vrpl_agent(env, gae_model, dqn_model_vrp, replay_buffer_vrp, epochs=1000, batch_size=64)\n",
    "    \n",
    "    return env, gae_model, dqn_model_c2s, dqn_model_vrp\n",
    "\n",
    "\n",
    "def run_simulation(env, gae_model, dqn_model_c2s, dqn_model_vrp):\n",
    "    env.time_lapsed = 0\n",
    "    env.reset()\n",
    "    episode_rewards = []\n",
    "\n",
    "    for episode in range(env.no_of_episodes):\n",
    "        # Generate new customers at the start of each episode\n",
    "        env.generate_customers()\n",
    "        feature_matrix, adjacency_matrix = env.create_graph_matrices()\n",
    "\n",
    "        # Ensure feature_matrix and adjacency_matrix are consistent and correctly sized\n",
    "        feature_matrix = torch.tensor(feature_matrix, dtype=torch.float).to(device)\n",
    "        adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.long).to(device)\n",
    "        print(f\"Feature Matrix Shape: {feature_matrix.shape}, Adjacency Matrix Shape: {adjacency_matrix.shape}\")\n",
    "\n",
    "        # Call the make_decisions function for C2S\n",
    "        c2s_decisions = make_decisions(env, gae_model, dqn_model_c2s, feature_matrix.cpu().numpy(), adjacency_matrix.cpu().numpy())\n",
    "        print(f'Episode {episode + 1}/{env.no_of_episodes}, C2S Decisions: {c2s_decisions}')\n",
    "\n",
    "        # Generate VRP decisions using the VRP model's make_decisions method\n",
    "        vrp_decisions = dqn_model_vrp.make_decisions(env, gae_model, feature_matrix.cpu().numpy(), adjacency_matrix.cpu().numpy())\n",
    "\n",
    "        # Apply actions to update the environment\n",
    "        env.input_actions(c2s_decisions, vrp_decisions)\n",
    "        \n",
    "        # Calculate the rewards after applying the actions\n",
    "        c2s_reward = sum(env.calculate_c2s_reward(decision) for decision in c2s_decisions)\n",
    "        vrp_reward = env.calculate_vrp_reward(vrp_decisions)\n",
    "        total_reward = c2s_reward + vrp_reward\n",
    "\n",
    "        print(f'C2S Reward: {c2s_reward}, VRP Reward: {vrp_reward}, Total Reward: {total_reward}')\n",
    "\n",
    "        episode_rewards.append(total_reward)\n",
    "        env.time_lapsed += env.episode_time\n",
    "    \n",
    "    return episode_rewards\n",
    "\n",
    "# Main execution\n",
    "env, gae_model, dqn_model_c2s, dqn_model_vrp = train()\n",
    "\n",
    "# Run the simulation and get episode rewards\n",
    "episode_rewards = run_simulation(env, gae_model, dqn_model_c2s, dqn_model_vrp)\n",
    "\n",
    "# Plot the rewards vs number of episodes\n",
    "plt.plot(range(1, len(episode_rewards) + 1), episode_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Total Reward vs Episode')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taorse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
